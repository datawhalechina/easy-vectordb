import logging
import pickle
import os
import time
from typing import List, Dict, Any, Optional
import numpy as np

from annoy import AnnoyIndex  # éœ€è¦å®‰è£…: pip install annoy
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings

logger = logging.getLogger(__name__)

class AnnoyIndexConstructionModule:
    """Annoyç´¢å¼•æ„å»ºæ¨¡å— - è´Ÿè´£å‘é‡åŒ–å’ŒAnnoyç´¢å¼•æ„å»º"""

    def __init__(self, 
                 index_path: str = "./annoy_index",
                 dimension: int = 512,
                 model_name: str = "BAAI/bge-small-zh-v1.5",
                 metric: str = "angular",  # é»˜è®¤å€¼
                 n_trees: int = 100,
                 embedding_api_key: str = None,
                 embedding_base_url: str = None
    ):
        # 1. è·¯å¾„é˜²å¾¡
        self.index_path = str(index_path) if index_path else "./annoy_index"
        
        # 2. ç»´åº¦é˜²å¾¡
        try:
            self.dimension = int(dimension) if dimension is not None else 512
        except:
            self.dimension = 512
            
        # 3. åº¦é‡æ–¹å¼é˜²å¾¡ (è§£å†³ä½ æŠ¥é”™çš„æ ¸å¿ƒç‚¹)
        # å¦‚æœä¼ å…¥çš„æ˜¯ Noneï¼Œå¼ºåˆ¶è½¬ä¸º "angular"
        self.metric = str(metric) if metric else "angular"
        
        # 4. æ ‘æ•°é‡é˜²å¾¡
        try:
            self.n_trees = int(n_trees) if n_trees is not None else 100
        except:
            self.n_trees = 100

        self.model_name = model_name
        self.embedding_api_key = embedding_api_key
        self.embedding_base_url = embedding_base_url
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.index_path, exist_ok=True)
        
        # æ–‡ä»¶è·¯å¾„æ‹¼æ¥
        self.index_file = os.path.join(self.index_path, "annoy.index")
        self.metadata_file = os.path.join(self.index_path, "metadata.pkl")
        self.config_file = os.path.join(self.index_path, "config.pkl")
        
        self.embeddings = None
        self.index = None
        self.metadata = []
        self.index_ready = False
        
        self._setup_embeddings()
    def _setup_embeddings(self):
        """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
        use_cloud_api = all([self.embedding_api_key, self.embedding_base_url])
        if use_cloud_api:
            try:
                self.embeddings = OpenAIEmbeddings(
                    model=self.model_name,
                    openai_api_key=self.embedding_api_key,
                    openai_api_base=self.embedding_base_url,
                    
                    # --- æ ¸å¿ƒæ–°å¢å‚æ•° ---
                    
                    # 1. å‡å° Batch Size: 
                    # é»˜è®¤é€šå¸¸æ˜¯ 1000ã€‚å¯¹äº BGE-M3 è¿™ç§ç§æœ‰éƒ¨ç½²æ¨¡å‹ï¼Œ
                    # å»ºè®®å‡å°åˆ° 20-50ï¼Œé˜²æ­¢å•ä¸ªè¯·æ±‚å¤„ç†æ—¶é—´è¿‡é•¿å¯¼è‡´ 502ã€‚
                    chunk_size=20, 
                    
                    # 2. å¢åŠ è¶…æ—¶æ—¶é—´ (å•ä½: ç§’):
                    # é˜²æ­¢æ¨¡å‹æ¨ç†å¤ªæ…¢å¯¼è‡´è¿æ¥è¢« Nginx ä¸»åŠ¨åˆ‡æ–­ã€‚
                    request_timeout=120,
                    
                    # 3. æœ€å¤§é‡è¯•æ¬¡æ•°:
                    max_retries=5
                )
                logger.info("äº‘ç«¯ Embedding API åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                logger.error(f"äº‘ç«¯æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°æœ¬åœ°æ¨¡å‹")
                self._setup_local_embeddings()
        else:
            self._setup_local_embeddings()

    def _setup_local_embeddings(self):
        logger.info(f"æ­£åœ¨åˆå§‹åŒ–æœ¬åœ°åµŒå…¥æ¨¡å‹: {self.model_name}")
        self.embeddings = HuggingFaceEmbeddings(
            model_name=self.model_name,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
    import time
    import os

    def build_vector_index(self, chunks: List[Document]) -> bool:
        """æ„å»ºAnnoyå‘é‡ç´¢å¼•ï¼ˆå·²å¢åŠ åˆ†æ‰¹å¤„ç†ä¸é”™è¯¯æ£€æŸ¥ï¼‰"""
        logger.info(f"æ­£åœ¨æ„å»ºAnnoyç´¢å¼•ï¼Œæ–‡æ¡£æ•°é‡: {len(chunks)}...")
        if not chunks: 
            logger.warning("æ²¡æœ‰å¯ç”¨çš„æ–‡æ¡£åˆ†å—")
            return False
        
        try:
            # --- 1. åˆ†æ‰¹ç”Ÿæˆå‘é‡ (è§£å†³ 502 æŠ¥é”™) ---
            texts = [chunk.page_content for chunk in chunks]
            vectors = []
            batch_size = 50  # ğŸ’¡ å‡å°æ¯æ‰¹æ•°é‡
            
            logger.info(f"å¼€å§‹å‘é‡åŒ–ï¼Œæ¯æ‰¹å¤§å°: {batch_size}")
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i : i + batch_size]
                # è·å–å½“å‰æ‰¹æ¬¡çš„å‘é‡
                batch_vectors = self.embeddings.embed_documents(batch_texts)
                vectors.extend(batch_vectors)
                
                # ğŸ’¡ å¢åŠ  0.2 ç§’å»¶è¿Ÿï¼Œé˜²æ­¢å‹å®æœåŠ¡å™¨ç½‘å…³
                time.sleep(0.2)
                if (i // batch_size) % 5 == 0:
                    logger.info(f"è¿›åº¦: {min(i + batch_size, len(texts))}/{len(texts)}")

            # --- 2. åˆå§‹åŒ–Annoyç´¢å¼• ---
            if not hasattr(self, 'dimension') or self.dimension is None:
                raise ValueError("ç»´åº¦(dimension)æœªå®šä¹‰ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®")
                
            annoy_index = AnnoyIndex(self.dimension, self.metric)
            
            # --- 3. æ·»åŠ å‘é‡å¹¶å‡†å¤‡å…ƒæ•°æ® ---
            self.metadata = []
            for i, (vec, chunk) in enumerate(zip(vectors, chunks)):
                annoy_index.add_item(i, vec)
                
                # ç¡®ä¿ id ä¸æ˜¯ None
                chunk_id = chunk.metadata.get("chunk_id") or f"chunk_{i}"
                self.metadata.append({
                    "id": chunk_id,
                    "text": chunk.page_content,
                    **chunk.metadata 
                })
            
            # --- 4. æ„å»ºæ ‘ ---
            logger.info(f"å¼€å§‹æ„å»ºAnnoyæ ‘ (n_trees={self.n_trees})...")
            annoy_index.build(self.n_trees)
            
            # --- 5. ä¿å­˜ (æ£€æŸ¥è·¯å¾„æ˜¯å¦ä¸º None) ---
            self.index = annoy_index
            
            # ğŸ›¡ï¸ é˜²å¾¡æ€§æ£€æŸ¥ï¼šé˜²æ­¢å‡ºç° argument 2 must be str, not None
            if not hasattr(self, 'index_path') or self.index_path is None:
                logger.error("æ£€æµ‹åˆ° index_path ä¸ºç©ºï¼Œå°†ä½¿ç”¨é»˜è®¤è·¯å¾„ './annoy_index.idx'")
                self.index_path = "./annoy_index.idx"
                
            self.save_index()
            
            self.index_ready = True
            return True
            
        except Exception as e:
            import traceback
            logger.error(f"æ„å»ºAnnoyç´¢å¼•å¤±è´¥: {str(e)}")
            logger.error(traceback.format_exc()) # æ‰“å°å®Œæ•´å †æ ˆï¼Œæ–¹ä¾¿å®šä½ None å‡ºç°åœ¨å“ªä¸€è¡Œ
            return False

    def save_index(self):
        """ä¿å­˜åˆ°ç£ç›˜"""
        self.index.save(self.index_file)
        with open(self.metadata_file, 'wb') as f:
            pickle.dump(self.metadata, f)
        
        config = {
            'dimension': self.dimension,
            'metric': self.metric,
            'n_trees': self.n_trees,
            'model_name': self.model_name
        }
        with open(self.config_file, 'wb') as f:
            pickle.dump(config, f)
        logger.info(f"Annoyç´¢å¼•å·²ä¿å­˜")

    def load_index(self) -> bool:
        """åŠ è½½Annoyç´¢å¼•"""
        try:
            if not os.path.exists(self.index_file): return False
            
            # å¿…é¡»å…ˆçŸ¥é“ç»´åº¦å’Œåº¦é‡æ‰èƒ½åŠ è½½
            if os.path.exists(self.config_file):
                with open(self.config_file, 'rb') as f:
                    config = pickle.load(f)
                    self.dimension = config.get('dimension', self.dimension)
                    self.metric = config.get('metric', self.metric)

            self.index = AnnoyIndex(self.dimension, self.metric)
            self.index.load(self.index_file) # ä½¿ç”¨ mmap åŠ è½½
            
            if os.path.exists(self.metadata_file):
                with open(self.metadata_file, 'rb') as f:
                    self.metadata = pickle.load(f)
            
            self.index_ready = True
            logger.info(f"Annoyç´¢å¼•åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(self.metadata)} ä¸ªèŠ‚ç‚¹")
            return True
        except Exception as e:
            logger.error(f"åŠ è½½å¤±è´¥: {e}")
            return False

    def similarity_search(self, query: str, k: int = 5, search_k: int = -1) -> List[Dict[str, Any]]:
        """
        ç›¸ä¼¼åº¦æœç´¢
        search_k: æœç´¢æ—¶çš„éå†èŠ‚ç‚¹æ•°ï¼Œ-1 è¡¨ç¤ºä½¿ç”¨é»˜è®¤å€¼ (n_trees * k)
        """
        if not self.index_ready: return []
        
        try:
            query_vector = self.embeddings.embed_query(query)
            
            # Annoy è¿”å› (indices, distances)
            indices, distances = self.index.get_nns_by_vector(
                query_vector, k, search_k=search_k, include_distances=True
            )
            
            results = []
            for idx, dist in zip(indices, distances):
                if idx >= len(self.metadata): continue
                
                # è½¬æ¢åˆ†æ•°ï¼šAnnoy angular è·ç¦»è¶Šå°è¶Šç›¸ä¼¼
                # è½¬æ¢å…¬å¼å–å†³äºå…·ä½“ä¸šåŠ¡éœ€æ±‚ï¼Œè¿™é‡Œä¿ç•™åŸå§‹è·ç¦»æˆ–åšç®€å•æ˜ å°„
                score = 1 - dist if self.metric == "angular" else dist
                
                meta = self.metadata[idx]
                results.append({
                    "id": meta.get("id"),
                    "score": float(score),
                    "text": meta.get("text"),
                    "metadata": meta
                })
            return results
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []

    def delete_collection(self) -> bool:
        """åˆ é™¤ç´¢å¼•æ–‡ä»¶"""
        for f in [self.index_file, self.metadata_file, self.config_file]:
            if os.path.exists(f): os.remove(f)
        self.index = None
        self.index_ready = False
        return True

    def close(self):
        # Annoy ä¸éœ€è¦æ˜¾å¼å…³é—­ï¼Œä½†åœ¨å¤„ç†å¤šè¿›ç¨‹æ˜ å°„æ—¶å¯ä»¥æ‰‹åŠ¨é‡Šæ”¾
        if self.index:
            self.index.unmap()
        logger.info("Annoyç´¢å¼•å·²å¸è½½")
    def has_collection(self) -> bool:
        """
        æ£€æŸ¥ Annoy ç´¢å¼•æ–‡ä»¶å’Œå…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        """
        # åŒæ—¶å­˜åœ¨ç´¢å¼•æ–‡ä»¶å’Œå…ƒæ•°æ®æ–‡ä»¶æ‰è®¤ä¸ºçŸ¥è¯†åº“å­˜åœ¨
        return os.path.exists(self.index_file) and os.path.exists(self.metadata_file)

    def load_collection(self) -> bool:
        """
        åŠ è½½é›†åˆçš„å…¼å®¹æ¥å£ï¼Œå†…éƒ¨è°ƒç”¨ç°æœ‰çš„ load_index
        """
        return self.load_index()

    def get_collection_stats(self) -> Dict[str, Any]:
        """
        è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯çš„å…¼å®¹æ¥å£
        """
        try:
            return {
                "row_count": len(self.metadata) if self.metadata else 0,
                "index_type": f"Annoy (Trees: {self.n_trees})",
                "dimension": self.dimension,
                "metric": self.metric
            }
        except Exception:
            return {"row_count": 0, "error": "æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯"}