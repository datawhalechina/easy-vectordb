"""
Milvus ç´¢å¼•æ„å»ºæ¨¡å—
"""

import logging
import time
from typing import List, Dict, Any, Optional
import numpy as np
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

import os
os.environ["TK_DATA_PATH"] = "./tiktoken_cache" # æŸäº›ç‰ˆæœ¬æœ‰æ•ˆ
os.environ["TIKTOKEN_CACHE_DIR"] = "./tiktoken_cache"
from pymilvus import (
    connections, 
    FieldSchema, 
    CollectionSchema, 
    DataType, 
    Collection, 
    utility
)
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings

logger = logging.getLogger(__name__)

class MilvusIndexConstructionModule:
    """Milvus ç´¢å¼•æ„å»ºæ¨¡å— - è´Ÿè´£å‘é‡åŒ–å’Œ Milvus é›†åˆç®¡ç†"""

    def __init__(self, 
                 host: str = "localhost",
                 port: str = "19530",
                 collection_name: str = "recipe_knowledge_base",
                 dimension: int = 512,
                 model_name: str = "BAAI/bge-small-zh-v1.5",
                 index_type: str = "IVF_FLAT",  # Milvus å¸¸ç”¨: IVF_FLAT, HNSW, IVFSQ8
                 metric_type: str = "IP",      # IP (å†…ç§¯) æˆ– L2 (æ¬§æ°è·ç¦»)
                 embedding_api_key: str = None,
                 embedding_base_url: str = None
    ):
        self.host = host
        self.port = port
        self.collection_name = collection_name
        self.dimension = dimension
        self.model_name = model_name
        self.index_type = index_type
        self.metric_type = metric_type
        self.embedding_api_key = embedding_api_key
        self.embedding_base_url = embedding_base_url
        
        self.embeddings = None
        self.collection = None
        
        # 1. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self._setup_embeddings()
        
        # 2. è¿æ¥ Milvus æœåŠ¡
        self._connect_milvus()

    def _connect_milvus(self):
        """å»ºç«‹ä¸ Milvus æœåŠ¡å™¨çš„è¿æ¥"""
        try:
            connections.connect("default", host=self.host, port=self.port,timeout=30 )
            logger.info(f"æˆåŠŸè¿æ¥è‡³ Milvus: {self.host}:{self.port}")
        except Exception as e:
            logger.error(f"Milvus è¿æ¥å¤±è´¥: {e}")
            raise

    def _setup_embeddings(self):
        """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆé€»è¾‘ä¿ç•™åŸæ ·ï¼‰"""
        use_cloud_api = all([self.embedding_api_key, self.embedding_base_url])
        if use_cloud_api:
            try:
                self.embeddings = OpenAIEmbeddings(
                    model=self.model_name,
                    openai_api_key=self.embedding_api_key,
                    openai_api_base=self.embedding_base_url,
                    
                    # --- æ ¸å¿ƒæ–°å¢å‚æ•° ---
                    
                    # 1. å‡å° Batch Size: 
                    # é»˜è®¤é€šå¸¸æ˜¯ 1000ã€‚å¯¹äº BGE-M3 è¿™ç§ç§æœ‰éƒ¨ç½²æ¨¡å‹ï¼Œ
                    # å»ºè®®å‡å°åˆ° 20-50ï¼Œé˜²æ­¢å•ä¸ªè¯·æ±‚å¤„ç†æ—¶é—´è¿‡é•¿å¯¼è‡´ 502ã€‚
                    chunk_size=20, 
                    
                    # 2. å¢åŠ è¶…æ—¶æ—¶é—´ (å•ä½: ç§’):
                    # é˜²æ­¢æ¨¡å‹æ¨ç†å¤ªæ…¢å¯¼è‡´è¿æ¥è¢« Nginx ä¸»åŠ¨åˆ‡æ–­ã€‚
                    request_timeout=120,
                    
                    # 3. æœ€å¤§é‡è¯•æ¬¡æ•°:
                    max_retries=5
                )
                logger.info("äº‘ç«¯ Embedding API åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                logger.error(f"äº‘ç«¯æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°æœ¬åœ°æ¨¡å‹")
                self._setup_local_embeddings()
        else:
            self._setup_local_embeddings()

    def _setup_local_embeddings(self):
        logger.info(f"æ­£åœ¨åˆå§‹åŒ–æœ¬åœ°åµŒå…¥æ¨¡å‹: {self.model_name}")
        self.embeddings = HuggingFaceEmbeddings(
            model_name=self.model_name,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )

    def _get_or_create_collection(self):
        """å®šä¹‰ Schema å¹¶åˆ›å»º/è·å– Collection"""
        if utility.has_collection(self.collection_name):
            # å¦‚æœå·²ç»å­˜åœ¨æ—§çš„ä½†é…ç½®é”™è¯¯çš„é›†åˆï¼Œå»ºè®®å…ˆåˆ é™¤æˆ–ç›´æ¥åŠ è½½
            self.collection = Collection(self.collection_name)
            logger.info(f"æˆåŠŸè¿æ¥åˆ°ç°æœ‰é›†åˆ: {self.collection_name}")
            return

        logger.info(f"æ­£åœ¨åˆ›å»ºé›†åˆ: {self.collection_name}ï¼Œç»´åº¦: {self.dimension}")
        
        # å®šä¹‰å­—æ®µ
        fields = [
            FieldSchema(name="pk", dtype=DataType.INT64, is_primary=True, auto_id=True),
            # æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šæ˜¾å¼ä½¿ç”¨ dim å…³é”®å­—
            FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=int(self.dimension)),
            FieldSchema(name="chunk_id", dtype=DataType.VARCHAR, max_length=500), # ç¨å¾®è°ƒå¤§é•¿åº¦ä¸Šé™
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=30000),
            FieldSchema(name="metadata", dtype=DataType.JSON)
        ]
        
        schema = CollectionSchema(fields, description="Recipe Knowledge Base")
        self.collection = Collection(self.collection_name, schema)
        logger.info(f"é›†åˆ {self.collection_name} åˆ›å»ºæˆåŠŸ")
    def has_collection(self) -> bool:
        """æ£€æŸ¥æŒ‡å®šçš„é›†åˆæ˜¯å¦å­˜åœ¨"""
        try:
            return utility.has_collection(self.collection_name)
        except Exception as e:
            logger.error(f"æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: {e}")
            return False
    def build_vector_index(self, chunks: List[Document], batch_size: int = 50) -> bool:
        """
        æ„å»º Milvus ç´¢å¼• (å¢å¼ºç‰ˆï¼šåˆ†æ‰¹åµŒå…¥ã€åˆ†æ‰¹æ’å…¥ã€å»¶æ—¶ä¿æŠ¤)
        """
        try:
            # 1. ç¡®ä¿é›†åˆå­˜åœ¨å¹¶æ¸…ç©ºæ—§ç´¢å¼•ï¼ˆå¦‚æœéœ€è¦é‡æ–°æ„å»ºï¼‰
            self._get_or_create_collection()
            
            total_chunks = len(chunks)
            logger.info(f"ğŸš€ å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•ï¼Œæ€»è®¡: {total_chunks} æ¡æ•°æ®ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")

            # 2. åˆ†æ‰¹å¤„ç†æµç¨‹
            for i in range(0, total_chunks, batch_size):
                batch_end = min(i + batch_size, total_chunks)
                batch_chunk_slice = chunks[i:batch_end]
                batch_texts = [chunk.page_content for chunk in batch_chunk_slice]
                
                # --- A. è·å–å½“å‰æ‰¹æ¬¡çš„å‘é‡ ---
                logger.info(f"æ­£åœ¨ç”Ÿæˆç¬¬ {i} åˆ° {batch_end} æ¡æ•°æ®çš„å‘é‡...")
                batch_vectors = self.embeddings.embed_documents(batch_texts)
                
                # --- B. å‡†å¤‡å½“å‰æ‰¹æ¬¡çš„æ•°æ®æ’å…¥ ---
                # å¯¹åº”å­—æ®µ: vector, chunk_id, text, metadata
                batch_ids = [c.metadata.get("chunk_id", str(j)) for j, c in enumerate(batch_chunk_slice, start=i)]
                batch_metadatas = [chunk.metadata for chunk in batch_chunk_slice]
                
                insert_data = [
                    batch_vectors, 
                    batch_ids, 
                    batch_texts, 
                    batch_metadatas
                ]
                
                # --- C. æ’å…¥ Milvus ---
                self.collection.insert(insert_data)
                
                # --- D. å»¶æ—¶ç­–ç•¥ (é˜²æ­¢å‹å®æœåŠ¡å™¨æˆ–è§¦å‘ API é¢‘æ§) ---
                logger.info(f"âœ… æ‰¹æ¬¡ {batch_end}/{total_chunks} å†™å…¥æˆåŠŸï¼Œç­‰å¾… 0.2s...")
                time.sleep(0.2)

            # 3. ç¡®ä¿æ•°æ®æŒä¹…åŒ–
            logger.info("æ­£åœ¨æ‰§è¡Œæ•°æ®è½ç›˜ (Flush)...")
            self.collection.flush()
            
            # 4. åˆ›å»ºç´¢å¼• (IVF_FLAT/HNSW)
            logger.info(f"æ­£åœ¨åˆ›å»ºç´¢å¼•: {self.index_type}...")
            index_params = {
                "metric_type": self.metric_type,
                "index_type": self.index_type,
                "params": {"nlist": 1024}
            }
            self.collection.create_index(field_name="vector", index_params=index_params)
            
            # 5. åŠ è½½é›†åˆåˆ°å†…å­˜
            self.collection.load()
            
            # ä¿®æ­£ä¹‹å‰çš„ f-string æ—¥å¿—
            logger.info(f"âœ¨ ç´¢å¼•æ„å»ºå®Œæˆï¼å½“å‰é›†åˆå®ä½“æ€»æ•°: {self.collection.num_entities}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
            return False
        
    def load_collection(self) -> bool:
        """å°†é›†åˆåŠ è½½åˆ°å†…å­˜ä¸­ï¼Œä»¥ä¾¿è¿›è¡Œæœç´¢"""
        try:
            if not self.collection:
                self.collection = Collection(self.collection_name)
            
            self.collection.load()
            logger.info(f"é›†åˆ {self.collection_name} åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"åŠ è½½é›†åˆå¤±è´¥: {e}")
            return False

    def similarity_search(self, query: str, k: int = 5, expr: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        ç›¸ä¼¼åº¦æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: ç»“æœæ•°
            expr: Milvus çš„æ ‡é‡è¿‡æ»¤è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ 'difficulty > 1'
        """
        try:
            if self.collection is None:
                self._get_or_create_collection()
                self.collection.load()

            query_vector = self.embeddings.embed_query(query)
            
            search_params = {"metric_type": self.metric_type, "params": {"nprobe": 10}}
            
            results = self.collection.search(
                data=[query_vector],
                anns_field="vector",
                param=search_params,
                limit=k,
                expr=expr,
                output_fields=["chunk_id", "text", "metadata"]
            )
            
            final_results = []
            for hit in results[0]:
                final_results.append({
                    "id": hit.entity.get("chunk_id"),
                    "score": hit.score,
                    "text": hit.entity.get("text"),
                    "metadata": hit.entity.get("metadata")
                })
            return final_results
            
        except Exception as e:
            logger.error(f"Milvus æœç´¢å¤±è´¥: {e}")
            return []

    def add_documents(self, new_chunks: List[Document]) -> bool:
        """å‘ Milvus æ’å…¥æ–°æ–‡æ¡£"""
        return self.build_vector_index(new_chunks)

    def get_collection_stats(self) -> Dict[str, Any]:
        if self.collection:
            return {
                "row_count": self.collection.num_entities,
                "collection_name": self.collection_name
            }
        return {"error": "Collection not loaded"}

    def delete_collection(self) -> bool:
        try:
            utility.drop_collection(self.collection_name)
            logger.info(f"é›†åˆ {self.collection_name} å·²åˆ é™¤")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤é›†åˆå¤±è´¥: {e}")
            return False

    def close(self):
        connections.disconnect("default")
        logger.info("Milvus è¿æ¥å·²æ–­å¼€")