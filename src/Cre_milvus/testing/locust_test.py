"""
Locustæ€§èƒ½æµ‹è¯•æ¨¡å—

ä»locustProjé¡¹ç›®ç§»æ¤å¹¶é›†æˆåˆ°ä¸»ç³»ç»Ÿä¸­
"""

import time
import random
import logging
import numpy as np
from typing import Dict, Any, Optional
from locust import User, task, between, events
from pymilvus import connections, Collection, utility
import threading

logger = logging.getLogger(__name__)

# å…¨å±€è¿æ¥ç®¡ç†
_connection_initialized = False
_shared_connection = "default"
_shared_collection = None
_shared_dimension = 256
_connection_lock = threading.Lock()


def init_shared_connection(host: str = "localhost", port: str = "19530", 
                          collection_name: str = "locust_test_collection"):
    """
    åˆå§‹åŒ–å…±äº«çš„Milvusè¿æ¥
    
    å‚æ•°:
        host: Milvusä¸»æœºåœ°å€
        port: Milvusç«¯å£
        collection_name: æµ‹è¯•é›†åˆåç§°
    """
    global _connection_initialized, _shared_collection, _shared_dimension
    
    with _connection_lock:
        if _connection_initialized:
            return
        
        try:
            # è¿æ¥åˆ°Milvus
            connections.connect(
                alias=_shared_connection,
                host=host,
                port=port,
                timeout=10
            )
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            if not utility.has_collection(collection_name, using=_shared_connection):
                raise Exception(f"é›†åˆ '{collection_name}' ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºæµ‹è¯•æ•°æ®")
            
            # è·å–é›†åˆå¯¹è±¡
            logger.info(f"åˆ›å»ºCollectionå¯¹è±¡: name={collection_name}, using={_shared_connection}")
            print(f"åˆ›å»ºCollectionå¯¹è±¡: name={collection_name}, using={_shared_connection}")
            
            # éªŒè¯è¿æ¥åˆ«åæ˜¯å¦æœ‰æ•ˆ
            try:
                utility.list_collections(using=_shared_connection)
                logger.info(f"âœ… è¿æ¥åˆ«åéªŒè¯é€šè¿‡: {_shared_connection}")
                print(f"âœ… è¿æ¥åˆ«åéªŒè¯é€šè¿‡: {_shared_connection}")
            except Exception as e:
                logger.error(f"âŒ è¿æ¥åˆ«åéªŒè¯å¤±è´¥: {_shared_connection}, é”™è¯¯: {e}")
                print(f"âŒ è¿æ¥åˆ«åéªŒè¯å¤±è´¥: {_shared_connection}, é”™è¯¯: {e}")
            
            _shared_collection = Collection(collection_name, using=_shared_connection)
            
            # è·å–å‘é‡ç»´åº¦
            schema = _shared_collection.schema
            for field in schema.fields:
                if field.name == "vector":
                    _shared_dimension = field.params.get('dim', 256)
                    break
            
            _connection_initialized = True
            logger.info(f"Milvusè¿æ¥æˆåŠŸï¼å‘é‡ç»´åº¦: {_shared_dimension}")
            
        except Exception as e:
            logger.error(f"Milvusè¿æ¥å¤±è´¥: {e}")
            raise


class MilvusLoadTest:
    """
    Milvusè´Ÿè½½æµ‹è¯•ç®¡ç†å™¨
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–è´Ÿè½½æµ‹è¯•
        
        å‚æ•°:
            config: æµ‹è¯•é…ç½®
        """
        self.config = config
        self.host = config.get('host', 'localhost')
        self.port = config.get('port', '19530')
        self.collection_name = config.get('collection_name', 'locust_test_collection')
        
    def start_test(self, users: int = 5, spawn_rate: float = 1.0, 
                   run_time: str = "60s") -> Dict[str, Any]:
        """
        å¯åŠ¨æ€§èƒ½æµ‹è¯•
        
        å‚æ•°:
            users: å¹¶å‘ç”¨æˆ·æ•°
            spawn_rate: ç”¨æˆ·å¯åŠ¨é€Ÿç‡
            run_time: è¿è¡Œæ—¶é—´
        
        è¿”å›:
            æµ‹è¯•ç»“æœ
        """
        try:
            # åˆå§‹åŒ–è¿æ¥
            init_shared_connection(self.host, self.port, self.collection_name)
            
            # è¿™é‡Œåº”è¯¥å¯åŠ¨Locustæµ‹è¯•
            # ç”±äºLocusté€šå¸¸ä½œä¸ºç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼Œè¿™é‡Œè¿”å›é…ç½®ä¿¡æ¯
            return {
                "status": "started",
                "config": {
                    "users": users,
                    "spawn_rate": spawn_rate,
                    "run_time": run_time,
                    "host": self.host,
                    "port": self.port,
                    "collection": self.collection_name
                }
            }
            
        except Exception as e:
            logger.error(f"å¯åŠ¨æµ‹è¯•å¤±è´¥: {e}")
            return {"status": "error", "message": str(e)}


class MilvusUser(User):
    """
    Milvusç”¨æˆ·è¡Œä¸ºæ¨¡æ‹Ÿç±»
    """
    
    wait_time = between(0.5, 2.0)  # æ“ä½œé—´éš”æ—¶é—´
    
    def on_start(self):
        """ç”¨æˆ·å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
        init_shared_connection()
        self.collection = _shared_collection
        self.dimension = _shared_dimension
    
    def generate_random_vector(self):
        """ç”Ÿæˆéšæœºå‘é‡"""
        vector = np.random.normal(0, 1, self.dimension).astype(np.float32)
        norm = np.linalg.norm(vector)
        if norm > 0:
            vector = vector / norm
        return vector.tolist()
    
    @task(10)
    def single_vector_search(self):
        """å•å‘é‡æœç´¢ï¼ˆæœ€å¸¸è§çš„æ“ä½œï¼‰"""
        self._perform_search("single_search", batch_size=1, top_k=10, nprobe=16)
    
    @task(5)
    def batch_vector_search(self):
        """æ‰¹é‡å‘é‡æœç´¢"""
        batch_size = random.randint(2, 5)
        self._perform_search("batch_search", batch_size=batch_size, top_k=10, nprobe=16)
    
    @task(3)
    def high_precision_search(self):
        """é«˜ç²¾åº¦æœç´¢"""
        self._perform_search("high_precision_search", batch_size=1, top_k=50, nprobe=32)
    
    @task(2)
    def fast_search(self):
        """å¿«é€Ÿæœç´¢"""
        self._perform_search("fast_search", batch_size=1, top_k=5, nprobe=8)
    
    def _perform_search(self, name: str, batch_size: int = 1, top_k: int = 10, nprobe: int = 16):
        """
        æ‰§è¡Œæœç´¢æ“ä½œ
        
        å‚æ•°:
            name: æ“ä½œåç§°
            batch_size: æ‰¹é‡å¤§å°
            top_k: è¿”å›ç»“æœæ•°é‡
            nprobe: æœç´¢å‚æ•°
        """
        start_time = time.time()
        exception = None
        result_count = 0
        
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_vectors = []
            for _ in range(batch_size):
                query_vectors.append(self.generate_random_vector())
            
            # æœç´¢å‚æ•°
            search_params = {
                "metric_type": "L2",
                "params": {"nprobe": nprobe}
            }
            
            # æ‰§è¡Œæœç´¢
            results = self.collection.search(
                data=query_vectors,
                anns_field="vector",
                param=search_params,
                limit=top_k,
                timeout=30
            )
            
            # ç»Ÿè®¡ç»“æœæ•°é‡
            result_count = sum(len(result) for result in results if result is not None)
            
        except Exception as e:
            exception = e
            logger.error(f"æœç´¢å¤±è´¥: {e}")
        
        # è®¡ç®—å“åº”æ—¶é—´
        response_time = (time.time() - start_time) * 1000
        
        # è®°å½•æµ‹è¯•ç»“æœ
        events.request.fire(
            request_type="SEARCH",
            name=name,
            response_time=response_time,
            response_length=result_count,
            exception=exception
        )


# Locustäº‹ä»¶ç›‘å¬å™¨
@events.test_start.add_listener
def on_test_start(environment, **kwargs):
    """æµ‹è¯•å¼€å§‹æ—¶çš„å‡†å¤‡å·¥ä½œ"""
    logger.info("=" * 50)
    logger.info("ğŸš€ Milvusæ€§èƒ½æµ‹è¯•å¼€å§‹")
    logger.info(f"ç›®æ ‡: localhost:19530")
    logger.info("=" * 50)


@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """æµ‹è¯•ç»“æŸæ—¶çš„æ¸…ç†å·¥ä½œ"""
    if environment.stats and environment.stats.total:
        total = environment.stats.total
        logger.info(f"æ€»è¯·æ±‚æ•°: {total.num_requests}")
        logger.info(f"å¤±è´¥è¯·æ±‚æ•°: {total.num_failures}")
        logger.info(f"å¹³å‡å“åº”æ—¶é—´: {total.avg_response_time:.2f}ms")
    
    # æ–­å¼€è¿æ¥
    if _connection_initialized and connections.has_connection(_shared_connection):
        connections.disconnect(_shared_connection)