#!/usr/bin/env python3
"""
Milvus Locustæ€§èƒ½æµ‹è¯•
é’ˆå¯¹æœ¬åœ°Milvus (localhost:19530) çš„ç®€æ´æµ‹è¯•å·¥å…·
"""

import time
import random
import numpy as np
import threading
import warnings
import os
from locust import User, task, between, events
from pymilvus import connections, Collection, utility
import logging

# é…ç½®æ—¥å¿—ï¼ŒæŠ‘åˆ¶grpcçš„è­¦å‘Šä¿¡æ¯
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æŠ‘åˆ¶grpcç›¸å…³çš„è­¦å‘Šå’Œå¼‚å¸¸ä¿¡æ¯
warnings.filterwarnings("ignore", category=UserWarning)
os.environ["GRPC_VERBOSITY"] = "ERROR"
os.environ["GRPC_TRACE"] = ""

# æŠ‘åˆ¶pymilvusçš„è°ƒè¯•ä¿¡æ¯
logging.getLogger("pymilvus").setLevel(logging.WARNING)
logging.getLogger("grpc").setLevel(logging.ERROR)

# å…¨å±€è¿æ¥ç®¡ç†
_connection_lock = threading.Lock()
_shared_connection = "milvus_shared"
_connection_initialized = False
_shared_collection = None
_shared_dimension = 256

def init_shared_connection():
    """åˆå§‹åŒ–å…±äº«è¿æ¥"""
    global _connection_initialized, _shared_collection, _shared_dimension
    
    with _connection_lock:
        if _connection_initialized:
            return
        
        try:
            # å¦‚æœè¿æ¥å·²å­˜åœ¨ï¼Œå…ˆæ–­å¼€
            if connections.has_connection(_shared_connection):
                try:
                    connections.disconnect(_shared_connection)
                except:
                    pass
            
            # åˆ›å»ºå…±äº«è¿æ¥ï¼Œä½¿ç”¨æœ€ç®€å•çš„é…ç½®
            connections.connect(
                alias=_shared_connection,
                host="localhost",
                port="19530",
                timeout=10
            )
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            if not utility.has_collection("locust_test_collection", using=_shared_connection):
                raise Exception("é›†åˆ 'locust_test_collection' ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºæµ‹è¯•æ•°æ®")
            
            # åˆ›å»ºå…±äº«é›†åˆå¯¹è±¡
            _shared_collection = Collection("locust_test_collection", using=_shared_connection)
            
            # è·å–å‘é‡ç»´åº¦
            try:
                schema = _shared_collection.schema
                for field in schema.fields:
                    if field.name == "vector":
                        _shared_dimension = field.params.get('dim', 256)
                        break
            except Exception as e:
                logger.warning(f"è·å–ç»´åº¦å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼256: {e}")
            
            _connection_initialized = True
            logger.info(f"å…±äº«è¿æ¥åˆå§‹åŒ–æˆåŠŸï¼Œå‘é‡ç»´åº¦: {_shared_dimension}")
            
        except Exception as e:
            logger.error(f"å…±äº«è¿æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
            _connection_initialized = False
            raise

class MilvusUser(User):
    """Milvusç”¨æˆ·è¡Œä¸ºæ¨¡æ‹Ÿ"""
    
    wait_time = between(0.5, 2.0)
    
    def on_start(self):
        """ç”¨æˆ·å¯åŠ¨æ—¶åˆå§‹åŒ–"""
        try:
            # ç¡®ä¿å…±äº«è¿æ¥å·²åˆå§‹åŒ–
            init_shared_connection()
            
            # ä½¿ç”¨å…±äº«è¿æ¥å’Œé›†åˆ
            self.connection_alias = _shared_connection
            self.collection = _shared_collection
            self.dimension = _shared_dimension
            
            logger.info(f"ç”¨æˆ· {id(self)} åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨å…±äº«è¿æ¥")
            
        except Exception as e:
            logger.error(f"ç”¨æˆ·åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def on_stop(self):
        """ç”¨æˆ·åœæ­¢æ—¶çš„æ¸…ç†ï¼ˆå…±äº«è¿æ¥ä¸éœ€è¦å•ç‹¬æ¸…ç†ï¼‰"""
        logger.debug(f"ç”¨æˆ· {id(self)} åœæ­¢")
    
    def generate_random_vector(self):
        """ç”ŸæˆéšæœºæŸ¥è¯¢å‘é‡"""
        vector = np.random.normal(0, 1, self.dimension).astype(np.float32)
        # å½’ä¸€åŒ–å‘é‡
        norm = np.linalg.norm(vector)
        if norm > 0:
            vector = vector / norm
        return vector.tolist()
    
    @task(10)
    def single_vector_search(self):
        """å•å‘é‡æœç´¢ - æœ€å¸¸è§çš„æ“ä½œ"""
        self._perform_search("single_search", batch_size=1, top_k=10, nprobe=16)
    
    @task(5)
    def batch_vector_search(self):
        """æ‰¹é‡å‘é‡æœç´¢"""
        batch_size = random.randint(2, 5)
        self._perform_search("batch_search", batch_size=batch_size, top_k=10, nprobe=16)
    
    @task(3)
    def high_precision_search(self):
        """é«˜ç²¾åº¦æœç´¢ - æ›´å¤šç»“æœ"""
        self._perform_search("high_precision", batch_size=1, top_k=50, nprobe=32)
    
    @task(2)
    def fast_search(self):
        """å¿«é€Ÿæœç´¢ - è¾ƒå°‘ç»“æœ"""
        self._perform_search("fast_search", batch_size=1, top_k=5, nprobe=8)
    
    def _perform_search(self, name, batch_size=1, top_k=10, nprobe=16):
        """æ‰§è¡Œæœç´¢æ“ä½œçš„æ ¸å¿ƒæ–¹æ³•"""
        start_time = time.time()
        exception = None
        result_count = 0
        
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_vectors = []
            for _ in range(batch_size):
                query_vectors.append(self.generate_random_vector())
            
            # æœç´¢å‚æ•°
            search_params = {
                "metric_type": "L2",
                "params": {"nprobe": nprobe}
            }
            
            # æ‰§è¡Œæœç´¢
            results = self.collection.search(
                data=query_vectors,
                anns_field="vector",
                param=search_params,
                limit=top_k,
                output_fields=[],
                timeout=30
            )
            
            # ç»Ÿè®¡ç»“æœæ•°é‡
            if results:
                result_count = sum(len(result) for result in results if result is not None)
            
        except Exception as e:
            exception = e
            logger.error(f"æœç´¢æ“ä½œå¤±è´¥ [{name}]: {str(e)}")
        
        # è®¡ç®—å“åº”æ—¶é—´å¹¶è®°å½•æŒ‡æ ‡
        response_time = (time.time() - start_time) * 1000
        
        events.request.fire(
            request_type="SEARCH",
            name=name,
            response_time=response_time,
            response_length=result_count,
            exception=exception
        )

# Locustäº‹ä»¶ç›‘å¬å™¨
@events.test_start.add_listener
def on_test_start(environment, **kwargs):
    """æµ‹è¯•å¼€å§‹æ—¶çš„å›è°ƒ"""
    logger.info("=" * 50)
    logger.info("ğŸš€ Milvusæ€§èƒ½æµ‹è¯•å¼€å§‹")
    logger.info(f"ç›®æ ‡: localhost:19530/default")
    logger.info(f"é›†åˆ: locust_test_collection")
    logger.info("=" * 50)

@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """æµ‹è¯•ç»“æŸæ—¶çš„å›è°ƒ"""
    global _connection_initialized, _shared_connection
    
    logger.info("=" * 50)
    logger.info("ğŸ“ˆ Milvusæ€§èƒ½æµ‹è¯•ç»“æŸ")
    
    if environment.stats and environment.stats.total:
        total = environment.stats.total
        logger.info(f"æ€»è¯·æ±‚æ•°: {total.num_requests}")
        logger.info(f"å¤±è´¥è¯·æ±‚æ•°: {total.num_failures}")
        logger.info(f"å¹³å‡å“åº”æ—¶é—´: {total.avg_response_time:.2f}ms")
        logger.info(f"æœ€å¤§å“åº”æ—¶é—´: {total.max_response_time:.2f}ms")
        logger.info(f"è¯·æ±‚é€Ÿç‡: {total.total_rps:.2f} RPS")
        
        if total.num_requests > 0:
            success_rate = (total.num_requests - total.num_failures) / total.num_requests * 100
            logger.info(f"æˆåŠŸç‡: {success_rate:.2f}%")
    
    # æ¸…ç†å…±äº«è¿æ¥
    try:
        if _connection_initialized and connections.has_connection(_shared_connection):
            connections.disconnect(_shared_connection)
            logger.info("å…±äº«è¿æ¥å·²æ¸…ç†")
    except Exception as e:
        logger.warning(f"æ¸…ç†è¿æ¥æ—¶å‡ºé”™: {e}")
    
    logger.info("=" * 50)

@events.quitting.add_listener
def on_quitting(environment, **kwargs):
    """ç¨‹åºé€€å‡ºæ—¶çš„æ¸…ç†"""
    global _connection_initialized, _shared_connection
    
    try:
        if _connection_initialized and connections.has_connection(_shared_connection):
            connections.disconnect(_shared_connection)
    except:
        pass