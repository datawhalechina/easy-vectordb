<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>ANN搜索算法 | EasyVectorDB 教程</title>
    <meta name="description" content="向量数据库学习与实战指南">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/easy-vectordb/assets/style.DYOv5SWi.css" as="style">
    <link rel="preload stylesheet" href="/easy-vectordb/vp-icons.css" as="style">
    
    <script type="module" src="/easy-vectordb/assets/app.BCqq1O-b.js"></script>
    <link rel="preload" href="/easy-vectordb/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/easy-vectordb/assets/chunks/theme.voKT699j.js">
    <link rel="modulepreload" href="/easy-vectordb/assets/chunks/framework.iC72KZN-.js">
    <link rel="modulepreload" href="/easy-vectordb/assets/base_chapter5_ANN搜索算法.md.DLsR_K_q.lean.js">
    <meta name="theme-color" content="#3c8772">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/easy-vectordb/" data-v-1168a8e4><!--[--><!--]--><!----><span data-v-1168a8e4>EasyVectorDB 教程</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/easy-vectordb/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>首页</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/easy-vectordb/base/chapter1/%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>向量基础</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/easy-vectordb/Faiss/chapter1/%E5%BC%95%E8%A8%80.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Faiss 教程</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/easy-vectordb/Milvus/chapter1/Milvus%20%E4%BB%8B%E7%BB%8D.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Milvus 教程</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/easy-vectordb/projects/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>实战项目</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/datawhalechina/easy-vectordb" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/datawhalechina/easy-vectordb" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>返回顶部</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chapter 1 · 项目介绍</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/easy-vectordb/base/chapter1/%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>项目介绍</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chapter 2 · 向量数据库概念</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/easy-vectordb/base/chapter2/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>为什么需要向量数据库</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chapter 3 · 向量嵌入算法基础</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/easy-vectordb/base/chapter3/%E5%90%91%E9%87%8F%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>向量嵌入算法基础</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chapter 4 · 向量搜索算法基础</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/easy-vectordb/base/chapter4/%E5%90%91%E9%87%8F%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>向量搜索算法基础</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chapter 5 · 向量ANN搜索算法</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/easy-vectordb/base/chapter5/ANN%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>ANN搜索算法</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/easy-vectordb/base/chapter5/IVF%E7%AE%97%E6%B3%95.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>IVF算法</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/easy-vectordb/base/chapter5/HNSW%E7%AE%97%E6%B3%95.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>HNSW算法</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/easy-vectordb/base/chapter5/PQ%E7%AE%97%E6%B3%95.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>PQ算法</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>On this page</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _easy-vectordb_base_chapter5_ANN%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95" data-v-39a288b8><div><h1 id="ann搜索算法" tabindex="-1">ANN搜索算法 <a class="header-anchor" href="#ann搜索算法" aria-label="Permalink to &quot;ANN搜索算法&quot;">​</a></h1><p>聪明的你已经知道暴力搜索是如何工作的：当你要搜索一个向量时，它会计算这个查询向量与数据库中所有其他向量的相似度（如欧氏距离或余弦相似度），然后排序返回最相似的前K个结果.这种方法的​​优势在于结果的绝对准确性​​，因为它比较了所有可能性。但这也是其最大的劣势，因为​​计算成本与数据量成正比​​（O(N)复杂度） 。当数据量从几千增长到百万、千万甚至亿级时，一次查询的耗时可能从毫秒级增加到分钟、小时甚至无法接受，无法满足实时应用的需求。此外，在高维空间中，所有点对之间的距离会变得非常接近，这使得区分真正近邻的难度增加，暴力搜索的效率会进一步降低，这一现象被称为“维度灾难”。具体维度灾难是怎么影响向量搜索，可以详细查看【向量搜索算法基础】这一章节。</p><p><strong>什么是ANN搜索？</strong> ANN（Approximate Nearest Neighbors）搜索是一种用于在高维空间中快速查找最近邻的算法。与暴力搜索不同，ANN搜索通过引入近似计算，在保持较高召回率的同时，显著减少了计算复杂度。ANN的核心价值在于解决了&quot;维度灾难&quot;问题——当数据维度和数量增加时，暴力搜索的计算复杂度呈指数级增长，而ANN通过巧妙的近似方法维持了可接受的搜索性能。</p><p>ANN算法之所以必要，正是为了打破暴力搜索在效率上的瓶颈。其核心思想是：​​牺牲微不足道的精度，换取数百倍甚至数千倍的速度提升​​。这并不是随意的妥协，而是通过智能的索引策略实现的。</p><h2 id="_1-索引类型" tabindex="-1">1.索引类型 <a class="header-anchor" href="#_1-索引类型" aria-label="Permalink to &quot;1.索引类型&quot;">​</a></h2><p>在向量搜索（Vector Search）中，索引（Index）是加速相似度检索的关键结构。 根据核心思想与数据组织方式，向量索引大体可以分为以下几大类👇</p><h3 id="_1-1空间划分类-spatial-partitioning" tabindex="-1">1.1空间划分类（Spatial Partitioning） <a class="header-anchor" href="#_1-1空间划分类-spatial-partitioning" aria-label="Permalink to &quot;1.1空间划分类（Spatial Partitioning）&quot;">​</a></h3><p>通过划分向量空间来减少搜索范围。 代表算法：</p><ul><li>IVF（Inverted File Index）：使用 K-Means 将向量聚成多个簇（Cluster），搜索时只在最相近的几个簇内查找。</li><li>K-D Tree / Ball Tree：以树结构递归划分空间，适合低维向量。</li><li>Annoy（Approximate Nearest Neighbors Oh Yeah）：基于多棵随机投影树（Random Projection Tree），在磁盘上高效存储，适合静态数据。</li></ul><blockquote><p>📌 特点：粗筛效果好，速度快，但在高维空间性能下降明显。</p></blockquote><h3 id="_1-2图索引类-graph-based-index" tabindex="-1">1.2图索引类（Graph-based Index） <a class="header-anchor" href="#_1-2图索引类-graph-based-index" aria-label="Permalink to &quot;1.2图索引类（Graph-based Index）&quot;">​</a></h3><p>通过构建**向量之间的邻接图（近邻关系）**来实现高效导航搜索。 代表算法：</p><ul><li>HNSW（Hierarchical Navigable Small World）：分层小世界图结构，搜索从稀疏层向密集层逐步细化。</li><li>NSG（Navigating Spreading-out Graph）：通过优化边连接减少图复杂度，常用于工业大规模检索。</li><li>NN-Descent：通过“近邻传播”逐步逼近KNN图，常用于HNSW或NSG的预构建阶段。</li></ul><blockquote><p>📌 特点：召回率高、延迟低，是目前性能最优的ANN索引类型之一。</p></blockquote><h3 id="_1-3量化压缩类-quantization-based-index" tabindex="-1">1.3量化压缩类（Quantization-based Index） <a class="header-anchor" href="#_1-3量化压缩类-quantization-based-index" aria-label="Permalink to &quot;1.3量化压缩类（Quantization-based Index）&quot;">​</a></h3><p>通过压缩向量存储与近似距离计算来节省资源。 代表算法：</p><ul><li>PQ（Product Quantization）：将高维向量分块并分别量化，使用短码近似表示原向量。</li><li>OPQ（Optimized PQ）：在PQ基础上增加旋转优化，使量化误差更小。</li><li>SQ（Scalar Quantization）：每个维度独立量化，简单但压缩率有限。</li></ul><blockquote><p>📌 特点：极大降低内存占用，适合海量数据和资源受限场景。</p></blockquote><h3 id="_1-4哈希类-hash-based-index" tabindex="-1">1.4哈希类（Hash-based Index） <a class="header-anchor" href="#_1-4哈希类-hash-based-index" aria-label="Permalink to &quot;1.4哈希类（Hash-based Index）&quot;">​</a></h3><p>通过哈希函数将相似向量映射到相同桶（Bucket），实现近似相似度检索。 代表算法：</p><ul><li>LSH（Locality Sensitive Hashing）：通过特定哈希函数（如随机投影）保持相似性。</li><li>SimHash / MinHash：用于文本或稀疏特征的快速相似度匹配。</li></ul><blockquote><p>📌 特点：计算简单、可并行，但召回率较低，常用于粗筛阶段。</p></blockquote><h3 id="_1-5混合索引-hybrid-index" tabindex="-1">1.5混合索引（Hybrid Index） <a class="header-anchor" href="#_1-5混合索引-hybrid-index" aria-label="Permalink to &quot;1.5混合索引（Hybrid Index）&quot;">​</a></h3><p>结合多种技术取长补短，以兼顾速度、精度与资源。 常见组合：</p><ul><li>IVF+PQ（FAISS 默认方案）：先聚类再量化，平衡性能与存储。</li><li>HNSW+PQ：在图索引基础上进行量化，适合大规模高维检索。</li><li>DiskANN / SPANN：结合图索引与磁盘访问优化，用于超大规模数据。</li></ul><blockquote><p>📌 特点：工业级应用首选方案，广泛用于 Milvus、FAISS、Weaviate、Elasticsearch dense vector 等系统。</p></blockquote><h3 id="_1-6基于磁盘或分布式的扩展索引" tabindex="-1">1.6基于磁盘或分布式的扩展索引 <a class="header-anchor" href="#_1-6基于磁盘或分布式的扩展索引" aria-label="Permalink to &quot;1.6基于磁盘或分布式的扩展索引&quot;">​</a></h3><p>针对**超大规模数据（数十亿向量）**场景：</p><ul><li>DiskANN（Microsoft）：图索引 + 顺序磁盘访问优化，可在TB级数据上实现亚秒级响应。</li><li>SPANN（Microsoft）：分布式向量搜索架构，结合多层索引与分区调度。</li><li>ScaNN（Google）：融合空间划分与量化，优化了ANN在TPU/GPU环境下的性能。</li></ul><blockquote><p>📌 特点：面向分布式、超大规模、云原生向量检索。</p></blockquote><h2 id="_2-向量索引类型对比表" tabindex="-1">2.向量索引类型对比表 <a class="header-anchor" href="#_2-向量索引类型对比表" aria-label="Permalink to &quot;2.向量索引类型对比表&quot;">​</a></h2><table tabindex="0"><thead><tr><th>索引类型</th><th>代表算法</th><th>核心思想</th><th>优势</th><th>局限</th></tr></thead><tbody><tr><td><strong>空间划分类</strong></td><td>IVF, KD-Tree, Annoy</td><td>空间划分 + 局部搜索</td><td>简单高效</td><td>高维退化</td></tr><tr><td><strong>图索引类</strong></td><td>HNSW, NSG</td><td>构建近邻图进行导航搜索</td><td>高召回率，低延迟</td><td>构建成本高，更新慢</td></tr><tr><td><strong>量化压缩类</strong></td><td>PQ, OPQ, SQ</td><td>向量压缩 + 近似距离计算</td><td>内存占用低，速度快</td><td>精度下降</td></tr><tr><td><strong>哈希类</strong></td><td>LSH, SimHash</td><td>哈希映射保持相似性</td><td>查询速度极快，可并行</td><td>召回率较低</td></tr><tr><td><strong>混合索引</strong></td><td>IVF+PQ, HNSW+PQ</td><td>融合多种索引优势</td><td>平衡速度、精度与存储</td><td>实现复杂，参数多</td></tr></tbody></table><p>接下来，本节针对不同索引中的<strong>代表性算法</strong>进行详细介绍。</p><h3 id="_2-1-基于聚类的索引-ivf" tabindex="-1">2.1 基于聚类的索引 (IVF) <a class="header-anchor" href="#_2-1-基于聚类的索引-ivf" aria-label="Permalink to &quot;2.1 基于聚类的索引 (IVF)&quot;">​</a></h3><p>IVF（<strong>Inverted File Index</strong>，倒排文件索引）是一种<strong>基于聚类思想</strong>的近似最近邻搜索方法。<br> 它通过将整个向量空间划分为若干个<strong>簇（Cluster）</strong>，并将每个向量分配到对应的簇中，从而在搜索时只需在与查询向量最相近的簇中进行查找，大幅减少搜索范围。</p><p>可以把 IVF 想象成在一个<strong>巨大的图书馆</strong>中找书的过程。<br> 如果所有书籍都杂乱无章地堆在一起，你只能一本一本地翻查，这就相当于<strong>暴力搜索（Brute Force Search）</strong>，效率极低。<br> 而一个高效的图书馆，会先将书籍按照主题（如文学、历史、科学）分类摆放。这样，当你要找一本“物理学”相关的书时，只需去“科学”书架中查找即可——这正是 IVF 的工作原理。</p><p>IVF 采用的核心思想是 <strong>“分而治之（Divide and Conquer）”</strong>：</p><ol><li><p><strong>聚类阶段（索引构建）</strong>：<br> 使用聚类算法（如 K-Means）将所有向量划分成若干个簇，并记录每个簇的中心点（Centroid）。<br> 每个向量只与其所属簇绑定，形成一种“倒排表”结构。</p></li><li><p><strong>搜索阶段（查询过程）</strong>：</p><ul><li>首先计算查询向量与所有簇中心的距离；</li><li>选出距离最近的几个簇（通常称为 <code>nprobe</code>）；</li><li>仅在这些簇内部进行精细的相似度计算。</li></ul></li></ol><p>这种策略大幅减少了需要比较的向量数量，使搜索效率相比暴力搜索实现<strong>指数级提升</strong>。</p><p><strong>✅ IVF 的核心优势</strong></p><ul><li><strong>高效率</strong>：只在部分簇内搜索，显著减少计算量；</li><li><strong>易扩展</strong>：聚类结构清晰，适用于海量向量场景；</li><li><strong>可组合性强</strong>：常与 PQ（Product Quantization）或 HNSW 等算法结合，进一步提升性能。</li></ul><p>因此，IVF 是向量数据库（如 <strong>FAISS、Milvus</strong>）中最经典、最广泛使用的索引结构之一，为高维向量的高效检索奠定了基础。</p><h3 id="_2-2-基于图的索引-hnsw-​" tabindex="-1">2.2 基于图的索引 (HNSW)​ <a class="header-anchor" href="#_2-2-基于图的索引-hnsw-​" aria-label="Permalink to &quot;2.2 基于图的索引 (HNSW)​&quot;">​</a></h3><p>HNSW（<strong>Hierarchical Navigable Small World</strong>，分层可导航小世界图）是一种<strong>基于图结构的近似最近邻搜索算法</strong>。<br> 与 IVF 的“分而治之”思路不同，HNSW 采用的是“以图搜图”的策略——通过构建一个<strong>多层次的邻近关系图（近似小世界网络）</strong>，让向量之间形成高效的导航路径，从而快速找到目标向量。</p><p>可以把 HNSW 想象成在一座<strong>多层迷宫城市</strong>中寻找目标位置的过程。<br> 城市中的每一栋建筑代表一个向量，而道路代表这些向量之间的相似关系：</p><ul><li>在最上层，只有少量的建筑和粗略的主干道，方便快速确定大致方向；</li><li>越往下层，建筑越来越多，道路也越来越密集，用于在局部区域中进行更精确的搜索。</li></ul><p>当有一个查询向量进入系统时，算法会先从最高层开始，像在城市的高空俯瞰一样，快速确定一个靠近目标的大致位置；<br> 然后逐层向下“着陆”，在更低层的图中进行局部搜索，直到找到最接近的向量。<br> 这种“逐层缩小范围 + 层内局部精细搜索”<strong>的机制，使得 HNSW 能在极大程度上兼顾搜索的</strong>速度与精度。</p><p>相比 IVF 依赖聚类划分空间，HNSW 不需要显式的聚类步骤，而是通过构建稀疏的、层级化的图结构，使得每个节点既能快速跳转到远处的区域，又能在邻域内进行细粒度搜索。<br> 这类似于人类在地图上<strong>先定位城市 → 再找街区 → 最后找到门牌号</strong>的过程。</p><p><strong>✅ HNSW 的核心优势</strong></p><ul><li><strong>高查准率</strong>：能在高维空间中保持较高的近似精度；</li><li><strong>搜索高效</strong>：图结构天然支持“跳跃式”导航，能快速锁定目标区域；</li><li><strong>动态可扩展</strong>：可以逐步插入新向量而无需完全重建索引。</li></ul><p>因此，HNSW 已成为当今向量数据库（如 <strong>Milvus、FAISS、Weaviate</strong> 等）中性能最优、应用最广的索引结构之一。</p><h3 id="_2-3-量化技术-pq" tabindex="-1">2.3 量化技术 (PQ) <a class="header-anchor" href="#_2-3-量化技术-pq" aria-label="Permalink to &quot;2.3 量化技术 (PQ)&quot;">​</a></h3><p>PQ（<strong>Product Quantization</strong>，乘积量化）是一种<strong>向量压缩与近似搜索技术</strong>，其核心目标是——<strong>在保证较高检索精度的同时，显著降低存储空间与计算成本</strong>。<br> 它通常与 IVF 等索引结构结合使用（如 IVF-PQ），成为高效的近似最近邻搜索方案。</p><p>想象一下，你需要在上亿个高维向量中找到最相似的几个向量。<br> 如果每个向量都要完整地存储和比对，那么不仅占用巨量内存，还会导致搜索时间暴涨。<br> PQ 的思路就像是“<strong>把复杂的向量拆开压缩成小片段，再在压缩后的空间中进行高效比较</strong>”。</p><p><strong>🧩 PQ 的核心思想</strong></p><p>PQ 通过一种“分块 + 量化”的策略来表示高维向量：</p><ol><li><p><strong>分块（Subspace Division）</strong><br> 将原始的高维向量（如 128 维）划分为若干个低维子空间（如 8 个 16 维子空间）。</p></li><li><p><strong>量化（Quantization）</strong><br> 对每个子空间单独进行聚类（如使用 K-Means），生成多个<strong>子码本（Codebook）</strong>，每个向量在对应子空间中会被表示为<strong>一个聚类中心的编号</strong>。<br> 最终，一个向量就不再以浮点数存储，而是以一组“索引编号”表示——大大减少存储空间。</p></li><li><p><strong>搜索阶段（Approximate Distance Computation）</strong><br> 在搜索时，PQ 不再计算完整的欧氏距离，而是通过预先计算的“查表法（Lookup Table）”快速估算向量间的距离，实现<strong>常数时间级别的相似度计算</strong>。</p></li></ol><p><strong>✅ PQ 的核心优势</strong></p><ul><li><strong>极高的压缩率</strong>：可将原始向量存储空间压缩至原来的 1/10 甚至更少；</li><li><strong>计算高效</strong>：通过查表法快速估算距离，极大减少计算量；</li><li><strong>可组合性强</strong>：常与 IVF（IVF-PQ）、HNSW（HNSW-PQ）等索引结构结合，兼顾速度与精度。</li></ul><p><strong>💡 类比理解</strong></p><p>可以把 PQ 想象成“<strong>把一本厚重的百科全书拆分成若干个主题册，然后只保留每册的索引编号</strong>”。<br> 虽然你丢失了一些细节信息（近似计算），但通过这些编号，你依然能快速定位最相关的章节（相似向量）。</p><p>因此，PQ 是现代向量数据库中<strong>兼顾存储效率与搜索速度</strong>的关键技术之一，广泛应用于大规模向量检索场景，如图像检索、文本相似度匹配和推荐系统等。</p><h3 id="_2-4-基于哈希的索引-hash-based-index" tabindex="-1">2.4 基于哈希的索引 (Hash-based Index) <a class="header-anchor" href="#_2-4-基于哈希的索引-hash-based-index" aria-label="Permalink to &quot;2.4 基于哈希的索引 (Hash-based Index)&quot;">​</a></h3><p>基于哈希（<strong>Hashing</strong>）的索引是一类通过<strong>哈希函数将高维向量映射为紧凑的二进制码</strong>的近似最近邻搜索方法。<br> 它的核心思想是：<strong>相似的向量在哈希空间中应被映射到相似或相同的哈希码上</strong>，从而实现“以码代距”的快速近似搜索。</p><p>想象一下，你要在上亿张图片中找到与目标图片相似的几张。<br> 如果每张图片都需要计算完整的特征距离，代价极高。<br> 而哈希技术就像为每张图片打上一个“特征指纹”，<strong>相似的图片指纹也会相似</strong>。<br> 这样，系统只需比较指纹之间的差异（哈希码距离），就能快速筛出候选结果。</p><p><strong>⚙️ 哈希索引的核心思想</strong></p><p>哈希方法的基本流程可分为三步：</p><ol><li><p><strong>哈希函数构建（Hash Function Design）</strong><br> 通过特定的哈希函数（如随机投影、学习哈希）将高维向量映射到低维二进制空间。例如，一个 128 维向量可能被映射成一个 64 位的二进制码。</p></li><li><p><strong>哈希码生成（Hash Code Generation）</strong><br> 每个向量被编码成固定长度的哈希码（如 <code>101010...</code>），这相当于为每个数据生成唯一的“二进制身份标识”。</p></li><li><p><strong>哈希桶查找（Bucket Search）</strong><br> 检索时，系统根据查询向量的哈希码，直接查找与之相同或相近的哈希桶（Bucket）中的向量，而不必遍历所有数据。<br> 相似度可通过哈希码之间的 <strong>汉明距离（Hamming Distance）</strong> 进行快速比较。</p></li></ol><p><strong>✅ 哈希技术的主要优势</strong></p><ul><li><strong>速度极快</strong>：二进制运算和汉明距离计算可在硬件级实现，速度远高于传统距离计算；</li><li><strong>存储高效</strong>：每个向量只需几个字节的哈希码，大幅减少内存占用；</li><li><strong>适用于超大规模数据</strong>：可轻松应对上亿级别的向量检索任务。</li></ul><p><strong>⚠️ 哈希索引的局限</strong></p><ul><li><strong>精度较低</strong>：哈希映射存在信息损失，可能导致部分近邻被错过；</li><li><strong>难以自适应</strong>：传统随机哈希（如 LSH）无法很好适应数据分布。</li></ul><p>因此，在现代向量数据库中，哈希方法往往与其他技术（如 <strong>IVF、PQ、HNSW</strong>）组合使用，用于<strong>粗筛阶段</strong>或<strong>快速预检索</strong>。</p><p><strong>💡 类比理解</strong></p><p>可以把哈希索引想象成<strong>为每个向量生成一张“指纹卡”</strong>。<br> 当你需要找相似的对象时，不必看完整的照片（向量特征），<br> 而是只需比对“指纹”是否相似（哈希码距离）。<br> 虽然这种方法略有误差，但在大规模检索场景下，能以极低的成本实现惊人的搜索速度。</p><p>因此，基于哈希的索引是向量检索体系中<strong>最轻量、最快速</strong>的一类方案，<br> 特别适合在早期阶段进行<strong>候选集快速过滤</strong>，再结合其他高精度索引进行精细搜索。</p><h3 id="_2-5-混合索引-hybrid-index" tabindex="-1">2.5 混合索引 (Hybrid Index) <a class="header-anchor" href="#_2-5-混合索引-hybrid-index" aria-label="Permalink to &quot;2.5 混合索引 (Hybrid Index)&quot;">​</a></h3><p>混合索引（<strong>Hybrid Index</strong>）是一种<strong>融合多种索引技术优势</strong>的近似最近邻搜索方法。<br> 它的设计目标是——<strong>在速度、精度、存储开销三者之间取得最优平衡</strong>。<br> 在实际的大规模向量检索系统中，单一索引往往难以同时满足所有需求，因此混合索引成为工业级系统的主流方案之一。</p><p>想象一下，你要在一座<strong>超大型图书馆</strong>中快速找到某个主题的书：</p><ul><li>你可以先根据**主题分类（IVF）**确定大致区域；</li><li>再用**哈希指纹（Hashing）**快速筛掉无关的书；</li><li>最后通过**精确匹配或量化比较（PQ/HNSW）**确定最相似的几本。<br> 这套多层过滤与精细查找结合的机制，就是混合索引的核心思想。</li></ul><p><strong>⚙️ 混合索引的常见组合形式</strong></p><ol><li><p><strong>IVF + PQ（最经典组合）</strong></p><ul><li>先用 IVF 将向量空间划分为多个簇；</li><li>再在每个簇内部使用 PQ 对向量进行压缩存储与快速距离估计。<br> ✅ 兼顾了搜索速度与内存效率，广泛应用于 FAISS、Milvus 等系统。</li></ul></li><li><p><strong>HNSW + PQ</strong></p><ul><li>HNSW 提供高精度的图结构导航；</li><li>PQ 用于减少存储占用与计算量。<br> ✅ 适合高精度要求但资源受限的场景。</li></ul></li><li><p><strong>IVF + HNSW</strong></p><ul><li>IVF 用于粗粒度聚类分区；</li><li>HNSW 用于分区内的精细图搜索。<br> ✅ 同时提升搜索速度与局部召回率。</li></ul></li><li><p><strong>Hash + IVF 或 Hash + HNSW</strong></p><ul><li>先用哈希快速过滤候选；</li><li>再使用更精细的索引算法进行高精度检索。<br> ✅ 适合亿级以上规模的向量预筛阶段。</li></ul></li></ol><p><strong>✅ 混合索引的核心优势</strong></p><ul><li><strong>性能均衡</strong>：融合不同算法优点，在速度、精度、资源占用之间取得最佳折中；</li><li><strong>灵活可配置</strong>：可根据场景灵活组合组件（如粗检 + 精检）；</li><li><strong>可扩展性强</strong>：支持增量更新与多层次结构优化；</li><li><strong>工程实用性高</strong>：已成为向量数据库的主流选择（如 Milvus 的 IVF_PQ、HNSW_PQ、Hybrid Index 等实现）。</li></ul><p><strong>💡 类比理解</strong></p><p>可以把混合索引理解为一套<strong>多阶段检索系统</strong>：<br> 像机场安检一样，</p><ul><li>第一关快速筛查（哈希/聚类），</li><li>第二关重点检测（量化/图搜索），</li><li>最后一关人工复核（精确比对）。</li></ul><p>这种多层次策略既能保持高效率，又能确保搜索结果的高质量。</p><p>因此，混合索引（Hybrid Index）代表了当前向量检索领域的<strong>工程最佳实践</strong>，<br> 是连接理论算法与实际应用性能的关键桥梁。</p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><div class="edit-info" data-v-e257564d><div class="edit-link" data-v-e257564d><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/datawhalechina/easy-vectordb/edit/main/docs/base/chapter5/ANN搜索算法.md" target="_blank" rel="noreferrer" data-v-e257564d><!--[--><span class="vpi-square-pen edit-link-icon" data-v-e257564d></span> 在 GitHub 上编辑此页<!--]--></a></div><div class="last-updated" data-v-e257564d><p class="VPLastUpdated" data-v-e257564d data-v-e98dd255>最后更新于: <time datetime="2025-10-16T07:06:37.000Z" data-v-e98dd255></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/easy-vectordb/base/chapter4/%E5%90%91%E9%87%8F%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Previous page</span><span class="title" data-v-e257564d>向量搜索算法基础</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/easy-vectordb/base/chapter5/IVF%E7%AE%97%E6%B3%95.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>IVF算法</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>基于 MIT 许可发布</p><p class="copyright" data-v-e315a0ad>Copyright © 2025 datawhale</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"annoy_chapter1_annoy介绍.md\":\"B9LjJx6u\",\"annoy_chapter1_基础api使用.md\":\"CGsJUPNH\",\"base_chapter1_项目介绍.md\":\"Bf1XuBXH\",\"base_chapter2_为什么需要向量数据库.md\":\"CMQleAgq\",\"base_chapter3_向量嵌入算法基础.md\":\"CE_2rmdT\",\"base_chapter4_向量搜索算法基础.md\":\"DLW2Z3cg\",\"base_chapter5_ann搜索算法.md\":\"DLsR_K_q\",\"base_chapter5_hnsw算法.md\":\"3_CN7OI7\",\"base_chapter5_ivf算法.md\":\"CrCllLML\",\"base_chapter5_lsh算法.md\":\"CToN_k6H\",\"base_chapter5_pq算法.md\":\"Bdh6lUJ6\",\"faiss_backup_1.1faiss核心原理与架构.md\":\"DOm6-Y2G\",\"faiss_backup_faisssear_faiss全面指南：从基础使用到高级索引.md\":\"DdxZBYFK\",\"faiss_chapter1_基础使用.md\":\"DseEVS8b\",\"faiss_chapter1_引言.md\":\"CeiY8MuA\",\"faiss_chapter2_gpu加速.md\":\"ZPotE3qK\",\"faiss_chapter2_索引.md\":\"CsQX4qMw\",\"faiss_chapter3_总结.md\":\"Bt2CCxhT\",\"faiss_chapter3_问答实战.md\":\"DjAN-Iri\",\"index.md\":\"Du0WkDlT\",\"milvus_chapter1_milvus 介绍.md\":\"DpBN9lMJ\",\"milvus_chapter1_milvus 索引介绍.md\":\"D_xXM9TJ\",\"milvus_chapter1_聚类算法介绍.md\":\"BHzgI9BC\",\"milvus_chapter2_milvus lite部署与应用.md\":\"BcXY6Vbd\",\"milvus_chapter2_milvus standalone部署.md\":\"DuJi1a2T\",\"milvus_chapter2_mineru部署教程.md\":\"qfjR8UXM\",\"milvus_chapter3_milvus pdf 多模型嵌入实战.md\":\"B1CybaWI\",\"milvus_chapter3_milvus pdf 嵌入实战.md\":\"DwNNi4jc\",\"milvus_chapter3_milvus 数据切分总结.md\":\"CkWlNt75\",\"milvus_chapter3_milvus 文本嵌入实战.md\":\"BPBb5plU\",\"milvus_chapter4_gpu加速检索-基于fusionanns.md\":\"CoxosFhH\",\"milvus_chapter4_k-mean算法详解.md\":\"9OlhA6Oy\",\"milvus_chapter4_meta-chunking：一种新的文本切分策略.md\":\"CgctkaPg\",\"milvus_chapter4_milvus 存储优化.md\":\"9trbjHuo\",\"milvus_chapter4_向量_code_meta_limit_code_startup.md\":\"BCnWTJfJ\",\"milvus_chapter4_向量_向量.md\":\"C1OOTDHL\",\"projects_index.md\":\"C0e4_T-L\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"EasyVectorDB 教程\",\"description\":\"向量数据库学习与实战指南\",\"base\":\"/easy-vectordb/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"returnToTopLabel\":\"返回顶部\",\"outline\":{\"level\":[1,4]},\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"向量基础\",\"link\":\"/base/chapter1/项目介绍\"},{\"text\":\"Faiss 教程\",\"link\":\"/Faiss/chapter1/引言.md\"},{\"text\":\"Milvus 教程\",\"link\":\"/Milvus/chapter1/Milvus 介绍\"},{\"text\":\"实战项目\",\"link\":\"/projects/\"}],\"sidebar\":{\"/base/\":[{\"text\":\"Chapter 1 · 项目介绍\",\"items\":[{\"text\":\"项目介绍\",\"link\":\"/base/chapter1/项目介绍\"}]},{\"text\":\"Chapter 2 · 向量数据库概念\",\"items\":[{\"text\":\"为什么需要向量数据库\",\"link\":\"/base/chapter2/为什么需要向量数据库\"}]},{\"text\":\"Chapter 3 · 向量嵌入算法基础\",\"items\":[{\"text\":\"向量嵌入算法基础\",\"link\":\"/base/chapter3/向量嵌入算法基础\"}]},{\"text\":\"Chapter 4 · 向量搜索算法基础\",\"items\":[{\"text\":\"向量搜索算法基础\",\"link\":\"/base/chapter4/向量搜索算法基础\"}]},{\"text\":\"Chapter 5 · 向量ANN搜索算法\",\"items\":[{\"text\":\"ANN搜索算法\",\"link\":\"/base/chapter5/ANN搜索算法\"},{\"text\":\"IVF算法\",\"link\":\"/base/chapter5/IVF算法\"},{\"text\":\"HNSW算法\",\"link\":\"/base/chapter5/HNSW算法\"},{\"text\":\"PQ算法\",\"link\":\"/base/chapter5/PQ算法\"}]}],\"/Faiss/\":[{\"text\":\"Chapter 1 · 基础概念\",\"items\":[{\"text\":\"Faiss介绍\",\"link\":\"/Faiss/chapter1/引言\"},{\"text\":\"基础使用\",\"link\":\"/Faiss/chapter1/基础使用\"}]},{\"text\":\"Chapter 2 · 索引与GPU加速\",\"items\":[{\"text\":\"基础索引原理\",\"link\":\"/Faiss/chapter2/索引\"},{\"text\":\"GPU 加速\",\"link\":\"/Faiss/chapter2/GPU加速\"}]},{\"text\":\"Chapter 3 · 问答实战\",\"items\":[{\"text\":\"问答实战\",\"link\":\"/Faiss/chapter3/问答实战\"},{\"text\":\"总结\",\"link\":\"/Faiss/chapter3/总结\"}]}],\"/Milvus/\":[{\"text\":\"Chapter 1 · 基础概念\",\"items\":[{\"text\":\"Milvus 介绍\",\"link\":\"/Milvus/chapter1/Milvus 介绍\"},{\"text\":\"milvus 索引介绍\",\"link\":\"/Milvus/chapter1/milvus 索引介绍\"},{\"text\":\"聚类算法介绍\",\"link\":\"/Milvus/chapter1/聚类算法介绍\"}]},{\"text\":\"Chapter 2 · 基础部署\",\"items\":[{\"text\":\"Milvus Lite 部署与应用\",\"link\":\"/Milvus/chapter2/Milvus Lite部署与应用\"},{\"text\":\"Milvus Standalone 部署\",\"link\":\"/Milvus/chapter2/Milvus Standalone部署\"},{\"text\":\"MinerU 部署教程\",\"link\":\"/Milvus/chapter2/MinerU部署教程\"}]},{\"text\":\"Chapter 3 · 实战进阶\",\"items\":[{\"text\":\"milvus 文本嵌入实战\",\"link\":\"/Milvus/chapter3/milvus 文本嵌入实战\"},{\"text\":\"milvus pdf 嵌入实战\",\"link\":\"/Milvus/chapter3/milvus pdf 嵌入实战\"},{\"text\":\"milvus pdf 多模型嵌入实战\",\"link\":\"/Milvus/chapter3/milvus pdf 多模型嵌入实战\"},{\"text\":\"milvus 数据切分总结\",\"link\":\"/Milvus/chapter3/milvus 数据切分总结\"}]},{\"text\":\"Chapter 4 · 优化与实践\",\"items\":[{\"text\":\"milvus 存储优化\",\"link\":\"/Milvus/chapter4/milvus 存储优化\"},{\"text\":\"GPU 加速检索 - 基于 FusionANNS\",\"link\":\"/Milvus/chapter4/GPU加速检索-基于FusionANNS\"},{\"text\":\"向量\",\"link\":\"/Milvus/chapter4/向量/向量.md\"},{\"text\":\"Meta-Chunking：一种新的文本切分策略\",\"link\":\"/Milvus/chapter4/Meta-Chunking：一种新的文本切分策略\"}]}],\"/projects/\":[{\"text\":\"实战项目\",\"items\":[{\"text\":\"项目概览\",\"link\":\"/projects/\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/datawhalechina/easy-vectordb\"}],\"footer\":{\"message\":\"基于 MIT 许可发布\",\"copyright\":\"Copyright © 2025 datawhale\"},\"search\":{\"provider\":\"local\"},\"editLink\":{\"pattern\":\"https://github.com/datawhalechina/easy-vectordb/edit/main/docs/:path\",\"text\":\"在 GitHub 上编辑此页\"},\"lastUpdated\":{\"text\":\"最后更新于\",\"formatOptions\":{\"dateStyle\":\"short\",\"timeStyle\":\"medium\"}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>