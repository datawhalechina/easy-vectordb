# Chapter 2 Milvus核心概念：数据模型与索引体系

## 2.1 学习目标

- 掌握Milvus的核心数据模型（数据库、集合、分区、字段、向量、数据行）及各组件的详细特性与约束规则
- 理解数据模型各层级的嵌套关系、依赖逻辑及多租户隔离机制
- 掌握Milvus索引的核心作用、底层原理与常见索引类型的技术特性
- 学会根据数据规模、精度需求、资源限制选择合适的索引类型与距离度量方式

## 2.2 Milvus核心数据模型

Milvus采用“多层级嵌套”的数据组织模型，从顶层到底层依次为：数据库（Database）→ 集合（Collection）→ 分区（Partition）→ 段（Segment）→ 字段（Field）→ 数据行（Row）。该模型通过清晰的层级划分实现数据的逻辑隔离、精细化管理与高效检索，各层级的核心定义、功能特性及关联关系如下：

### 2.2.1 数据库（Database）

数据库是Milvus中最高层级的逻辑命名空间，核心作用是实现不同业务场景、多租户的数据隔离与资源管控。它为下层的集合（Collection）提供独立的存储与操作边界，不同数据库内的资源（集合、索引等）互不干扰，支持多业务线在同一Milvus实例中并行运行。

核心特性与约束：

- 隔离机制：支持物理级数据隔离与资源组绑定，可通过RBAC权限控制实现租户级访问限制，保障数据安全
- 默认配置：系统默认提供“default”数据库，用户无需创建即可直接使用；自定义数据库数量默认限制为64个（集群级配置可调整）
- 适用场景：按业务线划分（如“电商推荐数据库”“智能文档检索数据库”），或按租户划分（如“企业A专属数据库”“企业B专属数据库”）

### 2.2.2 集合（Collection）

集合是Milvus中存储向量数据及关联元数据的基本单元，等价于传统关系型数据库中的“表”，但专为高维向量数据的存储与检索优化设计。每个集合必须通过Schema（模式）定义数据结构，所有插入的数据需严格遵循Schema规范，确保数据类型与字段约束的一致性。Schema支持动态特性，可在特定场景下提升集合的扩展性

核心特性与约束：

Schema依赖：必须显式定义Schema（数据模式），Schema是集合数据结构的“蓝图”，核心组成包括字段定义、字段约束、系统默认配置三大模块，是数据校验、存储优化与检索效率保障的基础。其中字段定义需明确字段名称、数据类型；字段约束包含是否为主键、是否非空、默认值、长度限制等；系统默认配置涵盖时间戳字段、动态字段开关等。Schema定义后需严格遵循，所有插入数据将通过Schema进行类型校验与约束检查，不满足条件的数据会被拒绝插入

- 字段要求：强制包含至少一个向量字段（存储高维特征向量），同时可配置多个标量字段（存储属性元数据）；每个集合有且仅有一个主键字段（标量类型），用于唯一标识数据行
- 层级关联：一个数据库下可创建多个集合（默认上限65535个），每个集合对应一个具体的业务数据集（如“商品向量集合”“用户行为向量集合”“文本嵌入向量集合”）
- 物理存储：集合的物理存储单元为“段（Segment）”，数据插入时会先写入内存段，满足阈值后自动持久化为磁盘段，段是索引构建与检索的最小物理单元

### 2.2.3 分区（Partition）

分区是集合的逻辑子单元，用于对集合内的数据按指定规则进行分组管理，本质是将一个集合的Schema复用至多个子数据集。通过分区可缩小检索时的数据扫描范围，提升查询效率，同时简化数据生命周期管理（如按分区清理过期数据）。

核心特性与约束：

- 分区方式：支持按业务属性（如商品类别：服装、电子产品、食品）、时间范围（如2024年1月、2024年2月）、哈希规则（按主键哈希均匀分布）划分；也可通过Partition Key实现自动路由，数据插入时按分区键值自动分配至对应分区
- 隔离与资源：分区支持物理级资源隔离，可绑定独立资源组；单个集合默认最大支持1024个分区，基于Partition Key的动态分区可支持更高租户规模（百万级）
- 核心价值：检索时可指定分区列表（Partition-aware Search），避免全集合扫描；支持按分区执行批量删除、备份等操作，降低数据管理成本

### 2.2.4 字段（Field）

字段是数据存储的最小单元，定义了数据的类型、属性约束及存储特性，所有字段均需在集合的Schema中预先定义（动态字段除外）。根据存储数据类型的不同，分为向量字段与标量字段两类，两类字段协同实现“向量检索+标量过滤”的混合检索能力。此外，Milvus还包含系统默认字段，同时支持字段级索引配置，进一步提升检索效率

1. 向量字段（必填）

专门用于存储高维向量数据（如文本嵌入向量、图像特征向量），是Milvus实现相似性检索的核心字段。

- 支持类型：FLOAT_VECTOR（浮点型向量，如float32，主流模型默认输出类型，适用绝大多数AI场景）、BINARY_VECTOR（二进制向量，仅存储0/1值，用于轻量化检索场景，存储成本与计算开销更低）
- 核心配置：必须指定向量维度（如768维对应BERT模型、1536维对应GPT模型、2048维对应ResNet-50模型），维度大小需与模型输出严格一致；FLOAT_VECTOR支持1-65536维，BINARY_VECTOR维度需为8的整数倍（如64维、128维）。此外，可配置向量存储参数，如是否启用压缩存储（适用于大规模FLOAT_VECTOR场景）
- 索引支持：向量字段是索引构建的核心对象，所有Milvus支持的索引类型（如IVF_FLAT、HNSW等）均针对向量字段创建；一个向量字段可创建多个不同类型的索引，但同一时间仅能有一个生效
- 标量字段（可选）

用于存储与向量关联的属性元数据，支持多种基础数据类型，可作为检索时的过滤条件（如价格≤1000、是否上架）。

- 支持类型：基础标量类型包括Int64（商品ID、用户ID等唯一标识）、Float64（价格、评分、相似度分值等数值型属性）、String/VARCHAR（商品名称、描述、标签等文本属性，VARCHAR需指定最大长度）、Bool（是否上架、是否推荐等布尔属性）、DATE（创建时间、更新时间等时间属性）；进阶类型包括Array（数组类型，如商品所属分类列表）、JSON（轻量结构化数据，如用户画像标签）
- 主键约束：必须指定一个标量字段作为主键，支持两种赋值方式——手动赋值（需保证唯一性）、自动生成（如自增Int64、UUID）；主键字段的值具有强唯一性，不可重复，且支持主键索引（默认自动创建），可通过主键快速定位单条数据
- 索引支持：主流标量类型（Int64、Float64、String/VARCHAR等）可创建标量索引，如BloomFilter（用于快速判空与去重）、Range Index（用于范围查询，如价格>1000）、Trie Index（用于String类型的前缀匹配查询）；标量索引与向量索引协同工作，可先通过标量索引过滤数据，再对剩余向量执行相似性检索，大幅提升混合检索效率
- 约束配置：可设置非空约束（字段值不可为NULL）、默认值约束（如将“是否上架”默认设为false）、长度约束（如VARCHAR(100)限制商品名称最长100字符），约束配置在Schema定义时生效，插入数据时自动校验

### 2.2.5 数据行（Row）

数据行是集合中实际存储的单条数据记录，对应Schema定义的一套完整字段值组合，即“主键值+向量值+其他标量值”的集合。每条数据行会通过分区规则分配至集合的某个分区，最终存储在对应分区的段（Segment）中。

示例：一条商品向量数据行

- {商品ID（主键）: 1001, 商品名称（String）: "华为手机", 价格（Float64）: 3999.0, 是否上架（Bool）: true, 向量（FLOAT_VECTOR）: [0.12, 0.34, ..., 0.56]（768维）}

核心特性：数据行的字段值必须匹配Schema定义的类型与约束；支持动态插入，但未启用动态字段时不允许新增Schema外的字段；删除数据行时需通过主键或分区批量删除。此外，Milvus默认会为每个数据行添加两个系统字段，无需在Schema中定义：① _row_id：系统生成的唯一行标识，用于内部数据定位；② _timestamp：数据插入时的时间戳，用于数据版本管理与时间范围过滤

### 2.2.6 数据模型层级关系与传统数据库对比

1. 层级关系总结（从顶层到底层）

Database（业务/租户隔离）→ Collection（Schema定义的数据集）→ Partition（数据集分组）→ Segment（物理存储单元）→ Field（数据最小单元）→ Row（单条数据记录）

核心关联逻辑：一个Database包含多个Collection，一个Collection包含多个Partition，一个Partition包含多个Segment，一个Segment包含多个Row，每个Row包含所有Field的具体值。

2. 与传统关系型数据库对比

| Milvus数据模型     | 传统关系型数据库（如MySQL） | 核心差异                                                     |
| :----------------- | :-------------------------- | :----------------------------------------------------------- |
| Database           | Database                    | 均为顶层命名空间，支持多租户隔离；Milvus新增资源组绑定能力   |
| Collection         | Table                       | 均为数据存储基本单元；Collection强制要求向量字段，依赖Schema定义 |
| Partition          | Partition                   | 均为表/集合的子单元；Milvus支持Partition Key自动路由，隔离粒度更细 |
| Field（向量+标量） | Column                      | Milvus新增向量字段类型，支持高维数据存储；主键字段为强制要求 |
| Row                | Row/Tuple                   | 均为单条数据记录；Milvus行必须包含向量值，支持混合检索       |

## 2.3 Milvus索引体系

索引是提升Milvus相似性检索性能的核心技术手段。未创建索引时，Milvus采用“暴力检索（Brute-force Search）”，需遍历所有向量计算距离，效率极低（亿级数据检索耗时分钟级）；创建索引后，通过预构建的索引结构缩小检索范围，可将亿级向量检索耗时缩短至毫秒级，实现高效相似性匹配。

### 2.3.1 索引的核心作用

- 降低检索延迟：通过索引结构快速定位候选相似向量，避免全量计算，核心目标是实现“海量数据+低延迟”检索
- 平衡精度与效率：不同索引类型在检索精度（召回率）与检索速度之间存在权衡，可根据业务需求灵活选择（如追求极致速度选HNSW，追求高精度选FLAT）
- 支持混合检索：索引与标量过滤协同工作，可先通过标量字段过滤缩小数据范围，再对剩余向量执行索引检索，进一步提升效率
### 2.3.2 索引的代价

- 存储开销：向量索引也需要占用额外的存储空间，这种空间开销有时甚至可能超过原始数据本身的大小。
- 时间开销：大规模数据的索引构建需要大量的时间。
- 内存占用：索引加载到内存中会消耗RAM
- 精度损失：近似搜索可能错过一些真正的最相似结果

### 2.3.3 Milvus常见索引类型

Milvus 支持 11 种以上索引类型，可分为“近似最近邻检索（ANN）索引”和“精确最近邻检索（NN）索引”两大类。其中 ANN 索引通过牺牲少量精度来换取显著的检索效率提升，是实际大规模应用的主流选择；而 NN 索引则适用于小规模数据或对精度要求极高的场景。

ANNS（近似近邻检索）的核心技术理念，是在可接受的精度损失范围内，优先追求检索性能的大幅提高，从而显著加快海量数据集上的相似性搜索速度，使其具备实际应用可行性。索引作为实现 ANNS 的关键组件，是建立在数据之上的附加结构，其内部形态取决于所采用的具体 ANNS 算法。

在 Milvus 中，索引作为字段级结构存在，主要用于提升向量搜索和标量过滤的性能。然而，索引的构建与使用并非没有代价：它会引入额外的预处理时间、存储空间及内存开销，有时还可能伴随召回率的轻微下降（尽管通常可忽略，但仍需关注）。因此，在实际应用中需仔细权衡索引构建的预处理成本与检索阶段带来的收益。

1. IVF_FLAT（最常用基础ANN索引）

- 原理：基于倒排文件（Inverted File）思想，先通过k-means算法将向量空间聚类为nlist个“聚类中心”；检索时先计算目标向量与各聚类中心的距离，选择距离最近的k个聚类中心（nprobe参数控制），再在这些中心包含的向量中执行暴力检索

![alt text](/images/IVF3.png)

- 特点：检索精度接近精确检索（召回率＞95%），性能稳定，内存占用适中；索引构建速度较快，无精度损失（聚类过程不改变向量值）
- 适用场景：中小规模向量数据（百万级-千万级），对精度要求较高、资源预算适中的场景（如电商商品检索、中小规模文档检索）
- 缺点：在进行近似最近邻搜索时，可能会出现一种情况：通过算法找到的“最接近查询嵌入的候选嵌入”实际上并不是真正的最近邻（IVF系列索引在聚类过程中，可能会将距离较远的向量分配到同一个聚类中，导致在搜索过程中，虽然找到了距离较近的聚类中心，但该聚类中心内的向量可能并不包含真正的最近邻。）
- 核心参数：
    - nlist（聚类中心数量，范围[1,65536]，默认128，建议值为数据量的平方根，如100万数据设为1024；nlist越大，聚类越细，检索精度越高但构建耗时越长）；
    - nprobe（检索时探查的聚类中心数量，范围[1,nlist]，默认8，值越大精度越高但检索越慢，通常为nlist的1%-10%，如nlist=1024时，nprobe可设为8-100）；
    - max_empty_result_buckets 控制在检索时最多连续跳过多少个空聚类桶后就停止搜索，用于平衡性能与召回率，尤其在数据稀疏或 nlist 过大时生效（范围[1,65535]，默认2）

2. IVF_SQ8（内存优化型ANN索引）

- 原理：在IVF_FLAT基础上增加“标量量化（Scalar Quantization）”步骤，将向量的float32类型值压缩为int8类型，减少内存占用（压缩比约4:1）
- 特点：内存占用仅为IVF_FLAT的1/4，检索速度比IVF_FLAT快3-5倍；但量化过程会导致少量精度损失（召回率比IVF_FLAT低5%-10%，决于压缩率）
- 适用场景：内存资源有限、对精度要求不极致的大规模场景（如海量用户行为向量检索、实时推荐系统）
- 核心参数：nlist（同IVF_FLAT）；quantization_type（量化类型，默认int8）

3. IVF_PQ
- 原理：在 IVF_FLAT 基础上增加“乘积量化”（Product Quantization, PQ），将高维向量分段后分别进行聚类编码，提供比 SQ（标量量化）更高的压缩率和更快的检索速度。  
- 特点：内存占用仅为 IVF_FLAT 的 \(1/m\)（实际取决于 `m` 和 `nbits`），检索速度比 IVF_FLAT 快 3–5 倍；但量化过程会引入近似误差，导致一定精度损失（召回率通常比 IVF_FLAT 低 10%–20%，具体取决于压缩率）。  
- 适用场景：内存资源极其有限、对精度要求不极致的极大规模场景（如十亿级向量库、移动端部署、低成本云服务）。  
- 缺点：因乘积量化引入近似误差，导致检索精度（召回率）明显低于 IVF_FLAT，尤其在高压缩率下损失更显著。
- 核心参数：  
  - `nlist`（同 IVF_FLAT）：聚类中心数量，建议设为数据量的平方根；  
  - `m`（压缩基数）：将原始向量均匀划分为 `m` 个子向量（需满足 `d % m == 0`，否则自动填充）；  
  - `nbits`（每个子向量的编码位数）：通常取 8（对应 256 个码字），也可选 4、6、12 等；  
  - 最终的压缩率为：  
    \[
    \text{压缩率} = \frac{32 \times d}{m \times nbits}
    \]  
    其中 \(d\) 为原始向量维度（假设为 float32 类型，每维占 32 位）。例如，当 \(d=128\)、\(m=16\)、\(nbits=8\) 时，压缩率为 \( (32 \times 128) / (16 \times 8) = 32 \)，即内存占用降至原始的 1/32。

> 综合来看，IVF系列三种索引的内存占用呈现IVF_PQ \< IVF_SQ8 \< IVF_FLAT的关系，而召回率则相反，IVF_FLAT最优，IVF_SQ8次之，IVF_PQ最低。这种差异源于量化技术的逐步引入与深化，体现了存储效率与检索精度之间的权衡。

4. HNSW（高性能 ANN 索引）

- 原理：  
  基于分层可导航小世界（Hierarchical Navigable Small World, HNSW）图结构，构建一个多层“跳表式”邻接网络。底层（第0层）包含所有向量节点，上层由通过“投币”机制随机采样得到的稀疏子集构成——高层提供长距离“捷径”，用于快速粗定位；低层提供密集连接，用于精细近邻搜索。检索时从顶层固定入口点出发，逐层向下执行贪婪搜索，最终在底层返回最相似结果。

> “投币”机制，是一种用于决定节点在图中所处层级的随机化策略。其原理类似于通过抛硬币（即概率决策）来确定新插入节点是否进入更高层图结构的过程。
> * 新节点加入时，会先被放入最底层（第0层），然后以一定的概率（如50%）决定是否将其提升到上一层。这个过程可以形象地理解为“投币”：如果结果是“正面”，节点就进入上一层；如果是“反面”，则停留在当前层。
> * 通常情况下，高层级的节点数量比低层级少得多，例如每向上一层，节点数量大约减半。这种设计保证了图结构的稀疏性，使得高层可用于快速导航，而底层则提供更精细的搜索能力。
> * 上层图可以看做下层图的一个缩影，检索时，从上到下，不断指引检索过程逐步靠近想要探寻的向量空间。另外在构图过程中HNSW通过边的裁剪来保证图的连通性。

![alt text](/images/hnsw.png)

- 特点：  
  - 检索速度极快：查询延迟通常比 IVF_FLAT 快 10–100 倍，支持对数级时间复杂度（≈ O(log N)）；
  - 精度高：召回率接近甚至媲美 IVF_FLAT（尤其在合理设置 `ef` 时）；
  - 代价明显：索引构建耗时较长，内存占用较大（约为 IVF_FLAT 的 1.5–2 倍，具体取决于 `M`）；
  - 无量化损失：基础 HNSW 存储原始 float32 向量，不引入近似误差。

- 适用场景：  
  大规模向量数据（千万级至亿级），对**检索延迟极度敏感**、且能接受较高内存开销的场景，如实时语义搜索、在线推荐系统、图像/视频检索 API 服务等。

- 核心参数：
  - `M`（每节点最大连接数）  
    - 作用：控制图的连接密度（即每个节点的“朋友数量”）  
    - 推荐值：8–64（常用 16–48）  
    - 影响：`M` 越大，图越稠密，召回率和鲁棒性越高，但内存占用和构建时间显著增加。
  
  - `efConstruction`（构建时的搜索范围）  
    - 作用：索引构建阶段用于寻找近邻的候选池大小  
    - 推荐值：100–500（常用 200）  
    - 影响：值越大，图结构质量越高（连通性更好），但构建时间线性增长。
  
  - `ef`（搜索时的探索范围）  
    - 作用：查询阶段动态维护的候选近邻队列大小  
    - 推荐值：≥ top_k，通常 10–2000（如 top_k=10 时，`ef=64` 较常见）  
    - 影响：`ef` 越大，召回率越高，但查询延迟上升；**不影响索引结构，仅影响搜索过程**。

- 内存优化变体：  
  为降低 HNSW 的高内存开销，衍生出多种**量化融合版本**，在牺牲少量精度或构建速度的前提下大幅压缩存储：

  | 变体名称     | 核心技术             | 内存占用 | QPS 性能 | 构建时间   | 召回率   | 主要特点 |
  |------------|--------------------|--------|---------|----------|--------|--------|
  | **HNSW**   | 原始 float32 图结构     | 高      | 高       | 基准       | 高      | 无损、低延迟、高召回，适合性能优先场景 |
  | **HNSW_SQ**| 标量量化（如 SQ6/SQ8） | 低      | 较高     | 适度增加    | 较高    | 将浮点值离散为有限整数（如 64/256 档），内存减半以上，QPS 几乎不受损 |
  | **HNSW_PQ**| 乘积量化               | 中–低   | 中       | 显著增加    | 中      | 向量分段量化，压缩灵活，但精度损失较明显 |
  | **HNSW_PRQ**| 乘积残差量化           | 中–低   | 中       | 增加数倍    | ≈ PQ 或略优 | 对 PQ 残差二次量化，压缩控制更精细，精度可能提升 |

> 选型建议：若内存充足且追求极致低延迟与高召回，首选 **HNSW**；若内存受限但可接受轻微精度损失，**HNSW_SQ** 是最佳平衡点；**HNSW_PQ/PRQ** 更适用于超大规模、资源极度受限的离线或边缘场景。


5. FLAT（精确NN索引）

- 原理：无索引结构，本质是将向量原始存储，检索时遍历所有向量计算距离，返回精确的Top-K结果
- 特点：检索精度100%（无召回损失），索引构建时间为0（无需预构建）；但检索速度极慢，随数据量增长呈线性下降
- 适用场景：小规模向量数据（万级以下）、对精度要求极高的测试场景（如算法模型效果验证）、数据量极少的边缘计算场景
- 缺点：高精确性是以巨大的计算开销为代价的，当数据量增长时，FLAT索引的搜索时间呈线性增长
- 核心参数：无（无需配置额外参数）

根据您提供的信息，我将按照之前HNSW的格式编排，并对内容进行了适当的检查和调整以符合Milvus索引规范。以下是关于GPU索引类型的整理：

6. GPU_CAGRA
- **原理**：基于图结构优化的GPU索引，通过高效的图剪枝和并行搜索算法来实现快速检索。
- **特点**：
  - 内存使用量约为原始数据的1.8倍；
  - 提供丰富的构建参数（如`intermediate_graph_degree`推荐值32或64，`graph_degree`需小于前者，`build_algo`支持IVF_PQ或NN_DESCENT算法）和搜索参数（如`itopk_size`至少为目标`top_k`且通常设为2的幂次，`search_width`入口点数量，迭代次数范围`min_iterations/max_iterations`）。
- **适用场景**：极高吞吐量场景，特别是对延迟有严格要求的应用。
  
7. GPU_IVF_FLAT
- **原理**：类似于CPU版本的IVF_FLAT，但利用了GPU进行加速。
- **特点**：
  - 内存占用与原始数据相同；
  - 查询性能对`nq`（输入向量数）和`nprobe`（搜索簇数）非常敏感。
- **适用场景**：中小规模查询场景，适合那些不需要极高速度但需要较高准确性的应用。

8. GPU_IVF_PQ
- **原理**：在GPU上运行的IVF_PQ，通过乘积量化降低存储需求。
- **特点**：
  - 内存占用取决于压缩参数设置，通常比IVF_SQ8更小；
  - 存在一定的精度损失。
- **适用场景**：内存资源受限，同时可以容忍一定程度精度损失的大型应用场景。

9. GPU_BRUTE_FORCE
- **原理**：直接在GPU上执行暴力搜索，确保最高的召回率。
- **特点**：
  - 内存需求与原始数据相当；
  - 只需配置基本的距离度量(`metric_type`)和返回结果数量(`top_k`)。
- **适用场景**：当数据规模较小且对结果的准确性有极高要求时的理想选择。


### 2.3.4 索引创建的核心注意事项

- 索引创建时机：支持“插入数据前”或“插入数据后”创建。建议插入数据后创建，避免插入过程中重复更新索引结构，降低插入效率；批量插入大量数据后，需先执行Flush操作（将内存数据持久化至磁盘）再创建索引
- 索引生效条件：创建索引后，必须调用“加载集合”（load_collection）接口将索引加载至内存，索引才能生效；支持按分区加载索引，进一步节省内存
- 索引与集合的关系：一个集合可创建多个索引（针对同一向量字段或不同向量字段），但同一时间仅能有一个索引生效；切换生效索引时需先卸载当前索引，再加载目标索引
- 索引参数调优：核心参数（如nlist、M、ef）需根据数据量、向量维度、业务精度/速度需求调整；建议通过小批量测试对比不同参数组合的召回率与延迟，选择最优配置；具体可参考Milvus官方参数调优指南
- 索引文件大小：可通过index_file_size参数控制索引分块大小（默认1GB），数据量较大时建议调小该值，避免单块索引过大导致加载失败


### 2.3.5 不同索引的使用场景

在向量检索系统中，索引类型的选择需紧密围绕**数据规模、内存资源、延迟要求、召回率目标**四大维度进行权衡。不同索引因其底层机制差异，在实际业务场景中各有优劣：

#### 1. 基于量化的索引：IVF系列  
适用于**大规模数据集**（千万至亿级）且**内存资源受限**的场景。  
-IVF_FLAT：适合对精度要求较高、内存尚可接受的中等规模场景（如百万级），是 IVF 系列中召回率最高的变体。  
- IVF_SQ8：在内存有限但需保持较高召回率时使用，通过标量量化减少约 75% 内存，适合通用 ANN 检索。  
- IVF_PQ：面向**超大规模、极致压缩需求**的场景（如十亿级向量），以显著精度损失换取极低内存占用（可低至原始数据的 1/64），常配合 mmap 或 DiskANN 使用。  

> 典型场景：推荐系统粗排、日志分析、边缘设备部署。

#### 2. 基于图的索引：HNSW系列  
适用于**对查询延迟极度敏感、且内存充足**的高性能在线服务。  
- HNSW：提供接近 FLAT 的召回率与毫秒级响应，是**低延迟、高 QPS 场景的首选**（如实时语义搜索、图像检索 API）。  
- HNSW_SQ / HNSW_PQ / HNSW_PRQ：在内存受限时引入量化，牺牲部分精度以降低存储开销，适用于需兼顾速度与成本的大模型 RAG 系统。  

> 注意：HNSW 构建时间较长、内存占用高（约 1.5–2 倍原始数据），不适用于频繁更新或内存紧张的环境。

#### 3. GPU索引  
适用于**超高吞吐、高并发批量查询**场景，尤其在 nq（查询向量数）较大时优势显著。  
- GPU_CAGRA：图结构优化 + GPU 并行，**低延迟 + 高吞吐**，适合在线推理服务。  
- GPU_IVF_FLAT / GPU_IVF_PQ：分别对应 CPU 版本的加速实现，适合已有 IVF 流程迁移到 GPU 的场景。  
- GPU_BRUTE_FORCE：仅用于**小规模、高精度验证**或作为召回率基准测试。  

> 关键认知：GPU 加速主要提升**吞吐量**（QPS），而非单次查询延迟；且硬件成本高，需评估 ROI。

#### 4. FLAT索引  
唯一能保证 **100% 召回率** 的索引，但计算开销随数据量线性增长。  
- 仅推荐用于**小规模数据集**（通常 ≤ 10 万条）或**对精度绝对敏感**的任务（如医疗诊断、法律判例检索）。  
- 常作为**其他索引的性能评估基准**，用于衡量近似索引的召回损失。  
- 在 RAG 系统中，即使使用 FLAT 检索到精确上下文，仍需警惕**语言模型幻觉**问题——**高召回 ≠ 高可信**。

> 切记：FLAT 不适用于生产级大规模应用，其“暴力”本质在数据量增大后迅速成为性能瓶颈。

### 选型一句话口诀（供快速参考）：
- 要快又准，内存够？ → 选 HNSW 
- 数据太大，内存紧？ → 选 IVF_PQ + mmap
- 小数据、要 100% 准？ → 选 FLAT
- 高并发、大批量、有 GPU？ → 选 GPU_CAGRA


可以运行下面的代码,查看不同索引的效果

点击:[代码实践](milvus_perf_test.py)

运行后，可以看到下面的效果：

![alt text](/images/milvus_perf_comparison_20250710-003445.png)

## 2.4 距离度量方式

距离度量方式是判断两个向量相似程度的核心标准，通过计算向量空间中两个向量的“距离”或“相似度”量化关联程度。不同类型的向量（文本、图像、音频）、不同模型编码的向量，需匹配对应的距离度量方式才能保证检索效果。Milvus支持多种距离度量方式，核心常用类型如下：

### 2.4.1 余弦距离（Cosine Distance）

- 原理：计算两个向量之间夹角的余弦值，取值范围[-1, 1]；值越接近1，向量夹角越小，语义/特征相似度越高；值接近-1时，相似度最低。本质是衡量向量的“方向一致性”，忽略向量的绝对大小（自动归一化）
- 适用场景：文本向量（如BERT、Sentence-BERT编码）、图像向量（如ResNet、ViT编码）等语义/特征匹配场景；适用于向量绝对值无实际业务意义的场景（如文本的语义相似性）  
- **重要说明**：余弦相似度在数学上等价于**对向量先做 L2 归一化后再计算内积（IP）**。因此，在 Milvus 中若要使用余弦相似度，**推荐做法是：先将所有向量进行 L2 归一化，然后选择 `metric_type="IP"`**。这样既能获得与余弦完全一致的排序结果，又能避免额外的除法开销，性能更高。

### 2.4.2 欧氏距离（L2 Distance）

- 原理：计算两个向量在空间中的直线距离（L2范数），取值范围[0, +∞)；值越小，向量在空间中的位置越近，相似度越高  
- 适用场景：图像识别、目标检测等计算机视觉场景（图像向量的绝对值代表像素特征强度）；向量绝对值大小具有实际意义的场景（如用户行为强度向量）；大部分深度学习视觉模型的默认推荐度量方式  
- Milvus 优化细节：当选择欧氏距离作为距离度量时，**Milvus 实际计算的是“平方欧氏距离”（即不执行最后的开平方根操作）**。由于平方根是单调函数，这种优化**不会影响最终的排序结果**，但显著提升了计算性能。  
- 与 IP 的关系：**只有当所有向量都经过 L2 归一化后，L2 距离的排序结果才与 IP 内积的排序结果完全一致（只是方向相反）**。如果未归一化，L2 和 IP 的结果可能完全不同。若发现两者返回结果不一致，请首先检查向量是否已正确归一化。

### 2.4.3 曼哈顿距离（L1 Distance）

- 原理：计算两个向量对应维度差值的绝对值之和（L1范数），取值范围[0, +∞)；值越小，相似度越高。相较于欧氏距离，对异常值更敏感，且计算复杂度更低  
- 适用场景：低维向量数据（维度＜100）、对异常值敏感的场景（如异常检测、欺诈识别）、资源受限的边缘设备检索场景

### 2.4.4 其他常用度量方式

- 内积（Dot Product）：计算两个向量的点积，取值范围[-∞, +∞)；值越大，相似度越高。**内积同时受向量方向和长度影响**——长向量即使方向稍偏也可能得分很高。**当向量已 L2 归一化时，内积等价于余弦相似度**，此时可直接用 `metric_type="IP"` 高效实现语义匹配。适用于已归一化的向量场景，计算速度比余弦距离快（无需额外归一化步骤）  
- 汉明距离（Hamming Distance）：适用于二进制向量，计算两个向量对应位不同的数量；值越小，相似度越高。适用于轻量化检索场景（如指纹识别、低维特征匹配）

### 2.4.5 距离度量方式选择建议

- 优先遵循模型推荐：文本向量（BERT、Sentence-BERT、LLaMA）优先选余弦距离或内积；图像向量（ResNet、ViT、CLIP）优先选欧氏距离；二进制向量必须选汉明距离  
- 结合业务场景判断：关注“语义/特征方向”忽略大小 → 余弦距离（**务必先归一化，再用 IP**）；关注“特征强度差异” → 欧氏距离；低维+异常敏感 → 曼哈顿距离；轻量化二进制向量 → 汉明距离  
- 关键排查点：如果 L2 和 IP 返回的 top-k 结果排序不一致，**首要怀疑向量未归一化**。请确保在使用 IP 实现余弦相似度前，所有向量均已进行 L2 归一化处理。

## 2.5 本章小结

本章核心掌握Milvus数据模型与索引体系的核心逻辑，重点包括：

- 数据模型的六层结构（Database→Collection→Partition→Segment→Field→Row），各层级的定义、约束规则及关联逻辑；理解向量字段与标量字段的协同作用，掌握Schema设计的核心要求
- 多租户隔离机制在数据模型中的体现（数据库级、集合级、分区级），理解分区管理对检索效率与数据生命周期的价值
- 常见索引类型（IVF_FLAT、IVF_SQ8、HNSW、FLAT）的底层原理、特性差异及适用场景，掌握索引创建与调优的核心注意事项
- 主流距离度量方式的原理与适用场景，学会根据向量类型、模型输出、业务需求选择合适的度量方式

这些概念是后续Milvus实操（集合创建、数据插入、索引构建、相似性检索）的基础，需重点理解各组件的依赖关系与设计初衷，才能在实际业务中灵活设计数据结构与检索方案。