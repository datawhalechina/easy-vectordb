import time
import random
import threading
import statistics
import argparse
import os
from pymilvus import (
    connections,
    Collection,
    FieldSchema,
    CollectionSchema,
    DataType,
    utility
)
from prettytable import PrettyTable
import matplotlib.pyplot as plt

class MilvusIndexTester:
    def __init__(self, host='localhost', port='19530', 
                 collection_name='perf_test', dim=128, 
                 num_vectors=100000, warmup_queries=1000):
        """
        åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•å™¨
        
        å‚æ•°:
            host: Milvus æœåŠ¡å™¨åœ°å€
            port: Milvus ç«¯å£
            collection_name: æµ‹è¯•é›†åˆåç§°
            dim: å‘é‡ç»´åº¦
            num_vectors: æµ‹è¯•æ•°æ®é‡
            warmup_queries: é¢„çƒ­æŸ¥è¯¢æ¬¡æ•°
        """
        self.host = host
        self.port = port
        self.collection_name = collection_name
        self.dim = dim
        self.num_vectors = num_vectors
        self.warmup_queries = warmup_queries
        
        # è¿æ¥ Milvus
        connections.connect("default", host=host, port=port)
        print(f"âœ… å·²è¿æ¥åˆ° Milvus æœåŠ¡å™¨: {host}:{port}")
        
        # æ£€æŸ¥å¹¶åˆ é™¤å·²å­˜åœ¨çš„åŒåé›†åˆ
        self._prepare_collection()
    
    def _prepare_collection(self):
        """å‡†å¤‡æµ‹è¯•é›†åˆ"""
        # å¦‚æœé›†åˆå­˜åœ¨ï¼Œå…ˆå¸è½½ç„¶ååˆ é™¤
        if utility.has_collection(self.collection_name):
            print(f"â™»ï¸ å‘ç°ç°æœ‰é›†åˆ: {self.collection_name}")
            
            # è·å–é›†åˆå®ä¾‹
            collection = Collection(self.collection_name)
            
            # å¦‚æœé›†åˆå·²åŠ è½½ï¼Œå…ˆé‡Šæ”¾
            try:
                if hasattr(collection, 'loaded') and collection.loaded:
                    print("  é‡Šæ”¾å·²åŠ è½½çš„é›†åˆ...")
                    collection.release()
            except Exception:
                pass
            
            # åˆ é™¤é›†åˆ
            utility.drop_collection(self.collection_name)
            print(f"  å·²åˆ é™¤ç°æœ‰é›†åˆ")
        
        # åˆ›å»ºæ–°é›†åˆ
        self._create_collection()
        print(f"ğŸ†• å·²åˆ›å»ºæ–°é›†åˆ: {self.collection_name} (ç»´åº¦={self.dim})")
        
        # æ’å…¥æµ‹è¯•æ•°æ®
        self._insert_test_data()
        print(f"ğŸ“Š å·²æ’å…¥ {self.num_vectors} æ¡æµ‹è¯•æ•°æ®")
    
    def _create_collection(self):
        """åˆ›å»ºæµ‹è¯•é›†åˆ"""
        fields = [
            FieldSchema("id", DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema("embedding", DataType.FLOAT_VECTOR, dim=self.dim)
        ]
        schema = CollectionSchema(fields, description="æ€§èƒ½æµ‹è¯•é›†åˆ")
        self.collection = Collection(self.collection_name, schema)
    
    def _insert_test_data(self):
        """æ’å…¥éšæœºæµ‹è¯•æ•°æ®"""
        # ç”Ÿæˆéšæœºå‘é‡
        vectors = [[random.random() for _ in range(self.dim)] 
                  for _ in range(self.num_vectors)]
        
        # æ’å…¥æ•°æ®ï¼ˆåˆ†æ‰¹è¿›è¡Œï¼‰
        batch_size = 5000
        total_batches = (self.num_vectors + batch_size - 1) // batch_size
        
        for i in range(0, self.num_vectors, batch_size):
            batch_vectors = vectors[i:i+batch_size]
            self.collection.insert([batch_vectors])
            progress = min(i + batch_size, self.num_vectors)
            print(f"  æ’å…¥è¿›åº¦: {progress}/{self.num_vectors} ({progress/self.num_vectors*100:.1f}%)", end='\r')
        
        # åˆ·æ–°æ•°æ®ç¡®ä¿å¯è§
        self.collection.flush()
        print("\nâœ… æ•°æ®æ’å…¥å®Œæˆ")
    
    def create_index(self, index_type, index_params):
        """
        åˆ›å»ºç´¢å¼•
        
        å‚æ•°:
            index_type: ç´¢å¼•ç±»å‹ (HNSW, IVF_FLAT, IVF_SQ8, etc.)
            index_params: ç´¢å¼•å‚æ•°
        """
       # ç¡®ä¿é›†åˆæœªåŠ è½½
        if hasattr(self.collection, 'loaded') and self.collection.loaded:
            print("  é‡Šæ”¾å·²åŠ è½½çš„é›†åˆ...")
            self.collection.release()
            # ç­‰å¾…é›†åˆé‡Šæ”¾å®Œæˆ
            start_time = time.time()
            while True:
                try:
                    if utility.load_state(self.collection_name) != "Loaded":
                        print("âœ… é›†åˆå·²æˆåŠŸé‡Šæ”¾")
                        break
                    time.sleep(0.5)
                    if time.time() - start_time > 10:
                        print("âš ï¸ é›†åˆé‡Šæ”¾è¶…æ—¶ï¼Œå°è¯•å¼ºåˆ¶ç»§ç»­")
                        break
                except Exception as e:
                    print(f"  æ£€æŸ¥é›†åˆçŠ¶æ€å¤±è´¥: {str(e)}")
                    time.sleep(1)
        
        # åˆ é™¤ç°æœ‰ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.collection.has_index():
            print("  åˆ é™¤ç°æœ‰ç´¢å¼•...")
            try:
                self.collection.drop_index()
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤ç´¢å¼•æ—¶å‡ºé”™: {str(e)}")
                # å°è¯•å†æ¬¡é‡Šæ”¾åé‡è¯•
                if "collection is loaded" in str(e):
                    print("  å†æ¬¡å°è¯•é‡Šæ”¾é›†åˆ...")
                    self.collection.release()
                    time.sleep(2)
                    self.collection.drop_index()
                    print("âœ… æˆåŠŸåˆ é™¤ç´¢å¼•")
        
        # åˆ›å»ºæ–°ç´¢å¼•
        print(f"ğŸ› ï¸ åˆ›å»º {index_type} ç´¢å¼•ï¼Œå‚æ•°: {index_params}")
        self.collection.create_index(
            field_name="embedding",
            index_params={
                "index_type": index_type,
                "metric_type": "L2",
                "params": index_params
            }
        )
        
        # ç­‰å¾…ç´¢å¼•æ„å»ºå®Œæˆ
        start_time = time.time()
        while True:
            time.sleep(2)
            try:
                index_info = utility.index_building_progress(self.collection_name)
                indexed = index_info['indexed_rows']
                total = index_info['total_rows']
                
                if indexed == total:
                    print("âœ… ç´¢å¼•æ„å»ºå®Œæˆ")
                    break
                
                print(f"  ç´¢å¼•æ„å»ºè¿›åº¦: {indexed}/{total} ({indexed/total*100:.1f}%)")
                
                # è¶…æ—¶æ£€æŸ¥ï¼ˆ10åˆ†é’Ÿï¼‰
                if time.time() - start_time > 600:
                    print("âš ï¸ ç´¢å¼•æ„å»ºè¶…æ—¶ï¼")
                    break
            except Exception as e:
                print(f"  è·å–ç´¢å¼•è¿›åº¦å¤±è´¥: {str(e)}")
                time.sleep(5)
        
        # åŠ è½½é›†åˆåˆ°å†…å­˜
        print("ğŸ“¥ åŠ è½½é›†åˆåˆ°å†…å­˜...")
        self.collection.load()
        
        # æ–°çš„è¿›åº¦æ£€æŸ¥é€»è¾‘
        start_time = time.time()
        last_progress = -1
        
        while True:
            time.sleep(1)
            try:
                # è·å–åŠ è½½çŠ¶æ€ï¼ˆè¿”å›æ ¼å¼ï¼š{'loading_progress': 'X%'}ï¼‰
                progress_info = utility.loading_progress(self.collection_name)
                
                # è§£æç™¾åˆ†æ¯”å€¼
                progress_str = progress_info.get('loading_progress', '0%')
                progress_percent = int(progress_str.strip('%'))
                
                # æ‰“å°è¿›åº¦ï¼ˆä»…åœ¨è¿›åº¦å˜åŒ–æ—¶æ‰“å°ï¼‰
                if progress_percent != last_progress:
                    print(f"  åŠ è½½è¿›åº¦: {progress_percent}%")
                    last_progress = progress_percent
                
                # æ£€æŸ¥æ˜¯å¦å®ŒæˆåŠ è½½
                if progress_percent >= 100:
                    print("âœ… é›†åˆå·²åŠ è½½åˆ°å†…å­˜")
                    break
                    
            except Exception as e:
                print(f"  è·å–åŠ è½½è¿›åº¦å¤±è´¥: {str(e)}")
                # ç›´æ¥æ£€æŸ¥é›†åˆåŠ è½½çŠ¶æ€ä½œä¸ºåå¤‡æ–¹æ¡ˆ
                try:
                    if self.collection.loaded:
                        print("âœ… é›†åˆå·²åŠ è½½åˆ°å†…å­˜ (é€šè¿‡loadedå±æ€§éªŒè¯)")
                        break
                except Exception as e2:
                    print(f"  éªŒè¯é›†åˆåŠ è½½çŠ¶æ€å¤±è´¥: {str(e2)}")
            
            # è¶…æ—¶æ£€æŸ¥ï¼ˆ10åˆ†é’Ÿï¼‰
            if time.time() - start_time > 600:
                print("âš ï¸ é›†åˆåŠ è½½è¶…æ—¶ï¼")
                break

    def _run_test(self, index_config, threads, duration):
        """æ‰§è¡Œå•ä¸ªç´¢å¼•é…ç½®çš„æ€§èƒ½æµ‹è¯•"""
        print(f"\nğŸš€ å¼€å§‹æµ‹è¯•é…ç½®: {index_config['name']}")
        print("-" * 60)
        
        # åˆ›å»ºç´¢å¼•
        self.create_index(index_config["type"], index_config["params"])
        
        # é¢„çƒ­é˜¶æ®µ
        print(f"ğŸ”¥ é¢„çƒ­æŸ¥è¯¢ ({self.warmup_queries} æ¬¡)...")
        for i in range(self.warmup_queries):
            vector = [[random.random() for _ in range(self.dim)]]
            self.collection.search(
                vector, 
                "embedding", 
                index_config["search_params"], 
                limit=10
            )
            if (i + 1) % 100 == 0:
                print(f"  é¢„çƒ­è¿›åº¦: {i+1}/{self.warmup_queries}", end='\r')
        print("\nâœ… é¢„çƒ­å®Œæˆ")
        
        # æ€§èƒ½æŒ‡æ ‡
        latencies = []
        query_count = 0
        running = True
        start_time = None
        
        def query_worker(worker_id):
            """æŸ¥è¯¢å·¥ä½œçº¿ç¨‹"""
            nonlocal query_count
            local_count = 0
            local_latencies = []
            
            while running:
                try:
                    # ç”ŸæˆéšæœºæŸ¥è¯¢å‘é‡
                    vector = [[random.random() for _ in range(self.dim)]]
                    
                    # æ‰§è¡ŒæŸ¥è¯¢
                    start_time = time.perf_counter()
                    self.collection.search(
                        vector, 
                        "embedding", 
                        index_config["search_params"], 
                        limit=10
                    )
                    
                    # è®°å½•å»¶è¿Ÿ(æ¯«ç§’)
                    latency = (time.perf_counter() - start_time) * 1000
                    local_latencies.append(latency)
                    local_count += 1
                except Exception as e:
                    print(f"âš ï¸ çº¿ç¨‹ {worker_id} æŸ¥è¯¢å¤±è´¥: {str(e)}")
                    continue
            
            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            nonlocal latencies
            with threading.Lock():
                query_count += local_count
                latencies.extend(local_latencies)
        
        # åˆ›å»ºå·¥ä½œçº¿ç¨‹
        workers = []
        print(f"ğŸ› ï¸ å¯åŠ¨ {threads} ä¸ªæŸ¥è¯¢çº¿ç¨‹...")
        for i in range(threads):
            t = threading.Thread(target=query_worker, args=(i+1,))
            t.daemon = True
            t.start()
            workers.append(t)
        
        # è¿è¡ŒæŒ‡å®šæ—¶é•¿
        print(f"â±ï¸ è¿è¡Œæµ‹è¯• {duration} ç§’...")
        start_time = time.perf_counter()
        last_report = start_time
        
        while time.perf_counter() - start_time < duration:
            time.sleep(1)
            elapsed = time.perf_counter() - start_time
            if time.perf_counter() - last_report >= 5:  # æ¯5ç§’æŠ¥å‘Šä¸€æ¬¡
                current_qps = query_count / elapsed if elapsed > 0 else 0
                print(f"  å·²è¿è¡Œ: {elapsed:.1f}s, å½“å‰QPS: {current_qps:.2f}, æ€»æŸ¥è¯¢æ•°: {query_count}", end='\r')
                last_report = time.perf_counter()
        
        running = False
        print("\nğŸ›‘ æµ‹è¯•ç»“æŸï¼Œç­‰å¾…çº¿ç¨‹é€€å‡º...")
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        for t in workers:
            t.join(timeout=1)
        
        # è®¡ç®—å®é™…è¿è¡Œæ—¶é—´
        elapsed = time.perf_counter() - start_time
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        if query_count == 0:
            print("âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸæ‰§è¡Œçš„æŸ¥è¯¢!")
            return {
                "name": index_config["name"],
                "qps": 0,
                "avg_latency": 0,
                "p95_latency": 0,
                "max_latency": 0,
                "total_queries": 0
            }
        
        qps = query_count / elapsed
        avg_latency = statistics.mean(latencies)
        p95_latency = statistics.quantiles(latencies, n=100)[94] if len(latencies) > 1 else avg_latency
        max_latency = max(latencies)
        
        print("\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"  æ€»æŸ¥è¯¢æ¬¡æ•°: {query_count}")
        print(f"  å®é™…æµ‹è¯•æ—¶é—´: {elapsed:.2f} ç§’")
        print(f"  QPS: {qps:.2f} æ¬¡/ç§’")
        print(f"  å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f} ms")
        print(f"  P95å»¶è¿Ÿ: {p95_latency:.2f} ms")
        print(f"  æœ€å¤§å»¶è¿Ÿ: {max_latency:.2f} ms")
        print(f"  æœ€å°å»¶è¿Ÿ: {min(latencies):.2f} ms")
        # æµ‹è¯•å®Œæˆåé‡Šæ”¾é›†åˆ
        print("â™»ï¸ æµ‹è¯•å®Œæˆï¼Œé‡Šæ”¾é›†åˆ...")
        try:
            if utility.load_state(self.collection_name) == "Loaded":
                self.collection.release()
                # ç¡®è®¤é›†åˆå·²é‡Šæ”¾
                start_time = time.time()
                while utility.load_state(self.collection_name) == "Loaded":
                    time.sleep(0.5)
                    if time.time() - start_time > 10:
                        print("âš ï¸ é›†åˆé‡Šæ”¾ç¡®è®¤è¶…æ—¶")
                        break
                print("âœ… é›†åˆå·²é‡Šæ”¾")
        except Exception as e:
            print(f"âš ï¸ é‡Šæ”¾é›†åˆæ—¶å‡ºé”™: {str(e)}")
        return {
            "name": index_config["name"],
            "qps": qps,
            "avg_latency": avg_latency,
            "p95_latency": p95_latency,
            "max_latency": max_latency,
            "total_queries": query_count
        }
    
    def run_comparison(self, index_configs, threads=100, duration=60):
        """
        è¿è¡Œå¤šç´¢å¼•é…ç½®å¯¹æ¯”æµ‹è¯•
        
        å‚æ•°:
            index_configs: ç´¢å¼•é…ç½®åˆ—è¡¨
            threads: å¹¶å‘çº¿ç¨‹æ•°
            duration: æ¯ä¸ªæµ‹è¯•è¿è¡Œæ—¶é•¿(ç§’)
        """
        results = []
        
        # è¿è¡Œæ‰€æœ‰é…ç½®çš„æµ‹è¯•
        for i, config in enumerate(index_configs):
            print(f"\n{'=' * 60}")
            print(f"ğŸ å¼€å§‹æµ‹è¯• {i+1}/{len(index_configs)}: {config['name']}")
            print(f"{'=' * 60}")
            
            result = self._run_test(config, threads, duration)
            results.append(result)
            
            # æµ‹è¯•å®Œæˆåé‡Šæ”¾é›†åˆ
            print("â™»ï¸ æµ‹è¯•å®Œæˆï¼Œé‡Šæ”¾é›†åˆ...")
            if self.collection.load():
                self.collection.release()
        
        # æ‰“å°å¯¹æ¯”ç»“æœ
        self._print_results_table(results)
        
        # ç”Ÿæˆæ€§èƒ½å›¾è¡¨
        self._plot_results(results)
        
        return results
    
    def _print_results_table(self, results):
        """æ‰“å°ç»“æœè¡¨æ ¼"""
        table = PrettyTable()
        table.field_names = ["ç´¢å¼•é…ç½®", "QPS", "å¹³å‡å»¶è¿Ÿ(ms)", "P95å»¶è¿Ÿ(ms)", "æœ€å¤§å»¶è¿Ÿ(ms)", "æ€»æŸ¥è¯¢æ•°"]
        table.align["ç´¢å¼•é…ç½®"] = "l"
        table.align["QPS"] = "r"
        table.align["å¹³å‡å»¶è¿Ÿ(ms)"] = "r"
        table.align["P95å»¶è¿Ÿ(ms)"] = "r"
        table.align["æœ€å¤§å»¶è¿Ÿ(ms)"] = "r"
        table.align["æ€»æŸ¥è¯¢æ•°"] = "r"
        
        for res in results:
            table.add_row([
                res["name"],
                f"{res['qps']:.2f}",
                f"{res['avg_latency']:.2f}",
                f"{res['p95_latency']:.2f}",
                f"{res['max_latency']:.2f}",
                f"{res['total_queries']:,}"
            ])
        
        print("\n" + "=" * 80)
        print("ğŸ”¥ Milvus ç´¢å¼•æ€§èƒ½å¯¹æ¯”ç»“æœ")
        print("=" * 80)
        print(table)
        print("=" * 80)
    
    def _plot_results(self, results):
        """ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        if not results:
            print("âš ï¸ æ²¡æœ‰ç»“æœå¯ç”Ÿæˆå›¾è¡¨")
            return
        
        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(15, 10))
        plt.suptitle('Milvus ç´¢å¼•æ€§èƒ½å¯¹æ¯”', fontsize=16)
        
        # QPS å¯¹æ¯”å›¾
        plt.subplot(2, 2, 1)
        names = [res["name"] for res in results]
        qps_values = [res["qps"] for res in results]
        plt.bar(names, qps_values, color='skyblue')
        plt.title('QPS å¯¹æ¯” (è¶Šé«˜è¶Šå¥½)')
        plt.ylabel('QPS (æ¬¡/ç§’)')
        plt.xticks(rotation=15)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # å¹³å‡å»¶è¿Ÿå¯¹æ¯”å›¾
        plt.subplot(2, 2, 2)
        avg_latencies = [res["avg_latency"] for res in results]
        plt.bar(names, avg_latencies, color='lightgreen')
        plt.title('å¹³å‡å»¶è¿Ÿå¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        plt.ylabel('å»¶è¿Ÿ (ms)')
        plt.xticks(rotation=15)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # P95å»¶è¿Ÿå¯¹æ¯”å›¾
        plt.subplot(2, 2, 3)
        p95_latencies = [res["p95_latency"] for res in results]
        plt.bar(names, p95_latencies, color='salmon')
        plt.title('P95å»¶è¿Ÿå¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        plt.ylabel('å»¶è¿Ÿ (ms)')
        plt.xticks(rotation=15)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # æœ€å¤§å»¶è¿Ÿå¯¹æ¯”å›¾
        plt.subplot(2, 2, 4)
        max_latencies = [res["max_latency"] for res in results]
        plt.bar(names, max_latencies, color='gold')
        plt.title('æœ€å¤§å»¶è¿Ÿå¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        plt.ylabel('å»¶è¿Ÿ (ms)')
        plt.xticks(rotation=15)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # ä¿å­˜å›¾è¡¨
        plt.tight_layout()
        plt.subplots_adjust(top=0.92)
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs("results", exist_ok=True)
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        filename = f"results/milvus_perf_comparison_{timestamp}.png"
        plt.savefig(filename, dpi=150)
        print(f"ğŸ“ˆ æ€§èƒ½å›¾è¡¨å·²ä¿å­˜è‡³: {filename}")


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='Milvus ç´¢å¼•æ€§èƒ½å¯¹æ¯”æµ‹è¯•å·¥å…·')
    parser.add_argument('--host', default='localhost', help='Milvus æœåŠ¡å™¨åœ°å€')
    parser.add_argument('--port', default='19530', help='Milvus ç«¯å£')
    parser.add_argument('--dim', type=int, default=128, help='å‘é‡ç»´åº¦')
    parser.add_argument('--data-size', type=int, default=100000, help='æµ‹è¯•æ•°æ®é‡')
    parser.add_argument('--threads', type=int, default=100, help='å¹¶å‘çº¿ç¨‹æ•°')
    parser.add_argument('--duration', type=int, default=60, help='æ¯ä¸ªæµ‹è¯•æ—¶é•¿(ç§’)')
    parser.add_argument('--warmup', type=int, default=1000, help='é¢„çƒ­æŸ¥è¯¢æ¬¡æ•°')
    args = parser.parse_args()
    
    # å®šä¹‰è¦æµ‹è¯•çš„ç´¢å¼•é…ç½®
    index_configs = [
        {
            "name": "HNSW (ef=32)",
            "type": "HNSW",
            "params": {"M": 16, "efConstruction": 200},
            "search_params": {"metric_type": "L2", "params": {"ef": 32}}
        },
        {
            "name": "HNSW (ef=64)",
            "type": "HNSW",
            "params": {"M": 16, "efConstruction": 200},
            "search_params": {"metric_type": "L2", "params": {"ef": 64}}
        },
        {
            "name": "HNSW (ef=128)",
            "type": "HNSW",
            "params": {"M": 16, "efConstruction": 200},
            "search_params": {"metric_type": "L2", "params": {"ef": 128}}
        },
        {
            "name": "IVF_FLAT (nprobe=16)",
            "type": "IVF_FLAT",
            "params": {"nlist": 1024},
            "search_params": {"metric_type": "L2", "params": {"nprobe": 16}}
        },
        {
            "name": "IVF_FLAT (nprobe=32)",
            "type": "IVF_FLAT",
            "params": {"nlist": 1024},
            "search_params": {"metric_type": "L2", "params": {"nprobe": 32}}
        },
        {
            "name": "IVF_SQ8 (nprobe=32)",
            "type": "IVF_SQ8",
            "params": {"nlist": 1024},
            "search_params": {"metric_type": "L2", "params": {"nprobe": 32}}
        }
    ]
    
    print("=" * 80)
    print("ğŸš€ Milvus å¤šç´¢å¼•æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    print(f"æµ‹è¯•å‚æ•°:")
    print(f"  Milvus åœ°å€: {args.host}:{args.port}")
    print(f"  å‘é‡ç»´åº¦: {args.dim}")
    print(f"  æµ‹è¯•æ•°æ®é‡: {args.data_size}")
    print(f"  å¹¶å‘çº¿ç¨‹æ•°: {args.threads}")
    print(f"  æ¯ä¸ªæµ‹è¯•æ—¶é•¿: {args.duration} ç§’")
    print(f"  é¢„çƒ­æŸ¥è¯¢æ¬¡æ•°: {args.warmup}")
    print(f"  æµ‹è¯•é…ç½®æ•°: {len(index_configs)}")
    print("=" * 80)
    
    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = MilvusIndexTester(
        host=args.host,
        port=args.port,
        dim=args.dim,
        num_vectors=args.data_size,
        warmup_queries=args.warmup
    )
    
    # è¿è¡Œå¯¹æ¯”æµ‹è¯•
    results = tester.run_comparison(
        index_configs=index_configs,
        threads=args.threads,
        duration=args.duration
    )
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    os.makedirs("results", exist_ok=True)
    timestamp = time.strftime("%Y%m%d-%H%M%S")
    result_file = f"results/milvus_perf_results_{timestamp}.txt"
    
    with open(result_file, "w") as f:
        f.write(f"Milvus æ€§èƒ½æµ‹è¯•ç»“æœ ({timestamp})\n")
        f.write("=" * 80 + "\n")
        f.write(f"Milvus åœ°å€: {args.host}:{args.port}\n")
        f.write(f"å‘é‡ç»´åº¦: {args.dim}\n")
        f.write(f"æµ‹è¯•æ•°æ®é‡: {args.data_size}\n")
        f.write(f"å¹¶å‘çº¿ç¨‹æ•°: {args.threads}\n")
        f.write(f"æ¯ä¸ªæµ‹è¯•æ—¶é•¿: {args.duration} ç§’\n")
        f.write(f"é¢„çƒ­æŸ¥è¯¢æ¬¡æ•°: {args.warmup}\n\n")
        
        f.write("æ€§èƒ½å¯¹æ¯”ç»“æœ:\n")
        for res in results:
            f.write(f"\né…ç½®: {res['name']}\n")
            f.write(f"  QPS: {res['qps']:.2f}\n")
            f.write(f"  å¹³å‡å»¶è¿Ÿ: {res['avg_latency']:.2f} ms\n")
            f.write(f"  P95å»¶è¿Ÿ: {res['p95_latency']:.2f} ms\n")
            f.write(f"  æœ€å¤§å»¶è¿Ÿ: {res['max_latency']:.2f} ms\n")
            f.write(f"  æ€»æŸ¥è¯¢æ¬¡æ•°: {res['total_queries']}\n")
    
    print(f"ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {result_file}")
    print("âœ… æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()


# python milvus_perf_test.py \
#   --host your-milvus-host \
#   --data-size 500000 \
#   --threads 200 \
#   --duration 120 \
#   --warmup 2000

# å‚æ•°	é»˜è®¤å€¼	è¯´æ˜
# --host	localhost	Milvus æœåŠ¡å™¨åœ°å€
# --port	19530	Milvus ç«¯å£
# --dim	128	å‘é‡ç»´åº¦
# --data-size	100000	æµ‹è¯•æ•°æ®é›†å¤§å°
# --threads	100	å¹¶å‘æŸ¥è¯¢çº¿ç¨‹æ•°
# --duration	60	æ¯ä¸ªç´¢å¼•æµ‹è¯•æ—¶é•¿(ç§’)
# --warmup	1000	é¢„çƒ­æŸ¥è¯¢æ¬¡æ•°
