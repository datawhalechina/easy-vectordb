# 向量索引选择指南

## ANNS向量索引概述

### ANNS技术核心与价值

ANNS（近似近邻检索）的核心技术理念在于不局限于返回最精确的topK结果，而是**通过在可接受范围内牺牲一定精确度，换取检索效率的显著提升**。其核心价值体现在能够有效加快大型数据集上相似性搜索的速度，从而提升此类查询的实用性  。

作为实现ANNS的关键组件，索引是建立在数据之上的附加结构，其内部结构取决于所采用的具体ANNS算法 。在向量数据库Milvus中，索引作为字段级结构存在，主要用于提升向量搜索和标量过滤性能 。然而，索引的构建和使用并非无代价：它会产生额外的预处理时间、存储空间及RAM开销，同时可能导致召回率的轻微降低（尽管这种影响通常可忽略，但仍需关注） 。因此，在实际应用中需权衡索引的预处理成本与搜索收益。

### 索引分类

ANNS向量索引的分类可从多个维度构建，核心包括实现方法与向量嵌入类型两大逻辑维度，不同维度间存在交叉关联，共同构成索引技术的全局认知框架。

从实现方法角度，ANNS向量索引可分为四大类：基于树结构、基于图结构、基于哈希方法和基于量化技术。基于树结构的索引通过空间划分构建层级树（如KD树），实现向量的快速检索；基于图结构的索引通过构建近邻图（如HNSW），利用图遍历高效定位相似向量；基于哈希方法的索引将高维向量映射到低维哈希码，通过哈希表实现快速查找；基于量化技术的索引则通过向量编码压缩（如乘积量化PQ、标量量化SQ），在降低存储和计算成本的同时保持检索性能。

| 实现方法分类 | 核心技术原理       | 典型代表算法            |
| ------ | ------------ | ----------------- |
| 基于树结构  | 空间划分构建层级树    | KD树               |
| 基于图结构  | 构建近邻图实现高效遍历  | HNSW              |
| 基于哈希方法 | 高维向量映射到低维哈希码 | 局部敏感哈希(LSH)       |
| 基于量化技术 | 向量编码压缩降低存储成本 | 乘积量化(PQ)、标量量化(SQ) |



从向量嵌入类型角度，索引可按处理的数据类型划分为浮点嵌入索引、二进制嵌入索引、稀疏嵌入索引及GPU索引。浮点嵌入索引支持各类浮点精度向量（如FLOAT32、FLOAT16），典型代表包括FLAT、IVF系列（IVF_FLAT、IVF_SQ8、IVF_PQ）、HNSW、SCANN、DiskANN等；二进制嵌入索引针对二值化向量，如BIN_FLAT、BIN_IVF_FLAT；稀疏嵌入索引适用于非零元素占比低的稀疏向量，如SPARSE_INVERTED_INDEX、SPARSE_WAND；GPU索引则通过图形处理器加速计算，如GPU_CAGRA、GPU_IVF_FLAT等。

| 嵌入类型    | 支持数据类型               | 典型索引示例                            |
| ------- | -------------------- | --------------------------------- |
| 浮点嵌入索引  | FLOAT32、FLOAT16等精度向量 | FLAT、IVF系列、HNSW、SCANN、DiskANN     |
| 二进制嵌入索引 | 二值化向量                | BIN_FLAT、BIN_IVF_FLAT             |
| 稀疏嵌入索引  | 非零元素占比低的稀疏向量         | SPARSE_INVERTED_INDEX、SPARSE_WAND |
| GPU索引   | 各类向量（需GPU加速）         | GPU_CAGRA、GPU_IVF_FLAT、GPU_IVF_PQ |



不同分类维度存在显著关联性。例如，基于量化技术的索引（如IVF_SQ8、IVF_PQ）主要属于浮点嵌入索引，**通过量化压缩浮点向量以平衡性能与资源消耗**；二进制嵌入索引的实现常结合量化或哈希方法，将浮点向量二值化后构建索引。以Milvus为例，其索引类型与目标字段数据类型严格映射：**浮点向量字段支持IVF系列、HNSW等多种实现方法的索引；二进制向量字段对应BIN_FLAT等专用索引；稀疏浮点向量字段则适配稀疏反转索引**，体现了向量嵌入类型与实现方法的协同选择逻辑。

下面的示例展示了如何定义一个包含二进制向量字段的集合，并向其中插入一条记录。注意这里我们生成了一个长度为16字节（对应128位）的随机二进制向量作为演示。：
```python 
from pymilvus import Collection,FieldSchema,CollectionSchema,DataType
import numpy as np

field1 = FieldSchema(name="id",dtype=DataType.INT64,is_primary=True)
field2 = FieldSchema(name="embedding",dtype=DataType.BINARY_VECTOR,dim=128)

schema = CollectionSchema(fields=[field1,field2],description="Test collection")

collection = Collection(name="example_collection",schema=schema)

binary_vector = np.random.randint(0,256,(1,16),dtype=np.uint8).tolist()

data = [
   [i for i in range(1)],
   binary_vector
]

collection.insert(data)

```

| 目标字段数据类型                           | 支持的索引类型                                  |
| ---------------------------------- | ---------------------------------------- |
| 浮点向量（FLOAT_VECTOR、FLOAT16_VECTOR等） | 平面、IVF_FLAT、IVF_SQ8、IVF_PQ、GPU_IVF_FLAT、GPU_IVF_PQ、HNSW、DISKANN |
| 二进制向量                              | BINARY_VECTOR、BIN_IVF_FLAT                    |
| 稀疏浮点矢量                             | 稀疏反转索引                                   |
| 变量                                 | 反转（推荐）、BITMAP、Trie                       |
| BOOL                               | BITMAP（推荐）、反转                            |
| 整数（INT8/16/32/64）                  | 反转、STL_SORT                              |
| 浮点/双精度（FLOAT/DOUBLE）               | 反转                                       |
| 数组（BOOL、INT8/16/32/64、VARCHAR元素）   | BITMAP（推荐）                               |
| 数组（BOOL、INT8/16/32/64等多类型元素）       | 反转                                       |
| JSON                               | 反转                                       |



通过上述多维度分类及关联性分析，可清晰识别各类索引的技术路径差异，为索引选择提供系统化框架。

## 欧氏距离、内积、归一化

这一部分是学习索引的基础，需了解，但如果您不考虑极致的优化，下面的内容看一看知道即可。下面我们将**倒着**向您介绍这一部分。

### 归一化


归一化是干嘛的？用专业术语来解释，归一化是把向量中的元素缩放到一个固定的范围，比如0到1。
**公式：** 
对于向量 `V = [v₁, v₂, ..., vₙ]`，其 L2 范数为 `||V||₂ = √(v₁² + v₂² + ... + vₙ²)`。归一化后的向量 V_norm 为：
`V_norm = V / ||V||₂ = [v₁/||V||₂, v₂/||V||₂, ..., vₙ/||V||₂]`
我们举个例子：
小刘和小牧一起跑步，小刘跑了100米，小牧跑了200米。
小刘用了10秒，小牧用了20秒。谁更快？我们用什么来判断呢，距离？时间？按照距离判断的话，小牧跑了200米，那说明小牧更快，按照时间判断的话，小刘跑了100米，小牧跑了200米，小刘用了10秒，小牧用了20秒。小刘更快。看到这里，你会发现这样计算不公平也都不对。
此时，就需要用到归一化了，归一化就是一个“公平”的比较标准，我们计算他们的速度，你可以发现小刘和小牧的速度都一样，那么现在，我们比较速度这个归一化后的值，可以发现，两个人一样快，那么这个速度就是归一化后的结果，**它消除了跑的距离不同这个因素的影响**，只关注快慢本身。

现在让我们回到向量的场景上，现在请你想象向量为一个箭头，这个箭头有方向和长度，**归一化就是让这个箭头的长度变为1，但方向不变。**是不是有点点不明白，下面将详细解释一下：

在很多时候，我们关心的知识两个箭头的方向是否相似，（两个箭头可以是两端文本或者是两个图片）方向相似，那么才能说明向量相似。但是，如果两个箭头都很长，即使方向有点不同，它们的内积（IP）也可能很大，欧氏距离（L2）也可能不小。如果两个箭头都很短，即使方向差别很大，内积可能很小，欧氏距离也可能不大。**长度影响了我们对“方向相似度”的判断！**。当所有向量长度都是1时，计算欧氏距离（L2）的大小顺序（谁小谁更近）和计算内积（IP）的大小顺序（谁大谁更相似）是完全一致的！ 它们描述的是同一件事（方向相似度）的两种不同表达方式（距离 vs 相似度分数）。

现在，让我们回到公式上，

假设你有一个向量` V = [3, 4]` （想象一个从原点指向点(3,4)的箭头）。

Step 1: 计算这个向量的长度（L2范数）
`长度 = ||V||₂ = √(3² + 4²) = √(9 + 16) = √25 = 5`

Step 2: 把向量中的每一个数字都除以这个长度归一化后的向量 `V_norm = [3/5, 4/5] = [0.6, 0.8]`

验证新向量的长度： `||V_norm||₂ = √(0.6² + 0.8²) = √(0.36 + 0.64) = √1 = 1`。成功！长度变成了1。

至此，归一化的介绍结束了，Milvus官方网站中有下面的一段内容：

[为什么欧氏距离（L2）和内积（IP）返回的结果不同？](https://milvus.io/docs/zh/product_faq.md#Why-do-Euclidean-distance-L2-and-inner-product-IP-return-different-results)
对于归一化向量，欧氏距离（L2）在数学上等同于内积（IP）。如果这些相似性度量返回不同的结果，请检查您的向量是否归一化.

当您看到这里时，是不是就可以理解了，如果你的 L2 距离结果 和 IP 内积结果 排序不同，首要怀疑对象就是：你的向量没有归一化！再去看看代码，或者，直接扔给模型，告诉他帮我改进我的代码！
### 应用场景以及性能差距
欧氏距离和内积是两种计算方法，选择L2还是IP，主要取决于你的具体任务和对相似性的定义：
1. 对于欧氏距离L2来说，其核心思想是衡量两个点之间在空间中的绝对距离。
   * 在之后我们学习的[聚类算法介绍](聚类算法介绍.md)中,我们可以看到K-means聚类算法就用到了l2距离，目标是计算最小化簇内点与质心之间的距离。
   * 如果您在计算向量的时候，更加关心特征空间中位置的距离，那么L2距离是一个更好的选择。例如，在图像处理中，L2距离可以用来衡量两个图像之间的相似度。
   * 当向量本身不包含重要信息，或者以及被归一化了，L2和IP的排序等价，L2是距离，会更加直观。值越小表示越相似。

2. 对于内积IP来说，其核心思想是衡量两个点之间的方向关系。
   * 在自然语言NLP中，词向量和句子向量之间的相似度可以使用余弦相似度来衡量，余弦相似度就是内积的一种形式。
   * 如果您在计算向量的时候，更加关心特征空间中方向的一致性，那么IP内积是一个更好的选择。例如，在推荐系统中，IP内积可以用来衡量用户和物品之间的兴趣相似度。
   * 值越大表示越相关，值可正可负，负值表示负相关/相反方向。

3. 在计算复杂度上，L2和IP的计算复杂度都是O(d)，其中d是向量的维度。因此，在维度较高的情况下，两者的计算复杂度是相同的。
   但是！我们来分析一下两者的计算步骤：
   1. L2(A, B):

      计算差值向量 C = A - B (需要 n 次减法)。

      计算 C 中每个元素的平方 (需要 n 次乘法)。

      求平方和 (需要 (n-1) 次加法)。

      开平方根 (1 次相对昂贵的运算)。

   2. IP(A, B):
      需要 n 次乘法 + (n-1) 次加法。

   你可以看到**L2 比 IP 多做了 n 次减法和 1 次开平方根运算**。对于单次计算，L2的开销要比IP要高，但这种差异在绝大多数场景下均是可忽略的。主要的时间消耗在于n 次乘法和 (n-1) 次加法，
4. 如果需要物理距离或形状匹配感，或者向量已归一化且长度无意义，优先用 L2。

如果需要衡量相关性，或者向量长度本身编码了重要信息（如推荐系统中的物品热度），优先用 IP (或未归一化的余弦)。
### 欧氏距离L2
关于这一部分，我们说的是你在使用milvus的场景下！
![pic](https://milvus.io/docs/v2.6.x/assets/euclidean-metric.png)
**当选择欧氏距离作为距离度量时，Milvus 只计算应用平方根之前的值1。**

这意味着Milvus在计算欧氏距离时会跳过开平方根的步骤，只计算平方和的结果。


其中 a = (a₀, a₁, ..., aₙ₋₁) 和 b = (b₀, b₁, ..., bₙ₋₁) 是n维欧氏空间中的两个点1。

正常情况下，欧氏距离需要计算完平方和后再开平方根。但是Milvus为了优化性能，只计算平方根之前的值，也就是只计算 Σ(aᵢ - bᵢ)² 这部分，而不进行最后的开平方根操作1。

这样做的好处是：

减少计算量，提高性能
对于相似性比较来说，开不开平方根不影响排序结果，因为平方根是单调递增函数
所以虽然数值上不是真正的欧氏距离，但在向量相似性搜索中，这种优化不会影响搜索结果的准确性。
### 内积IP
![pic](https://milvus.io/docs/v2.6.x/assets/IP-formula.png)
两个向量在相同维度空间中的一种运算，结果是一个标量（单个数字）。值越大（正值），表示方向越接近；值为 0 表示正交（垂直）；值为负表示方向相反。它也间接包含了向量长度信息（模长）。
## 核心索引类型技术原理与特性

### 浮点嵌入索引

#### 精确检索索引：FLAT

FLAT索引作为一种精确检索索引，其核心原理是**不对向量进行压缩，采用暴力搜索（即穷举搜索）策略**，在每次查询时将目标向量与数据集中的所有向量进行逐一比较。这一特性使得FLAT能够保证100%的召回率，也是目前唯一能实现这一结果的索引类型。因此，FLAT索引在小规模数据集（通常为百万量级）或对检索精度有极高要求的场景中具有不可替代性，尤其适用于需要完美精确度的任务。然而，由于其线性扫描的本质，FLAT索引的搜索速度较慢，不适合处理海量数据。在参数设置方面，FLAT索引较为简单，仅需指定距离计算方式（如L2欧氏距离或IP内积），且无需额外的训练过程  。此外，FLAT索引的检索结果常被用作其他近似索引的性能比较基准，为评估不同索引的召回率提供参考标准。

| 特性      | 详细说明                              |
| ------- | --------------------------------- |
| 索引类型    | 精确检索索引，采用暴力搜索（穷举搜索）策略             |
| 核心原理    | 不对向量进行压缩，每次查询时将目标向量与数据集中所有向量逐一比较  |
| 召回率     | 100%，是目前唯一能实现这一结果的索引类型            |
| 适用场景    | 小规模数据集（通常为百万量级）或对检索精度有极高要求的场景     |
| 搜索速度    | 较慢（由于线性扫描本质）                      |
| 海量数据适用性 | 不适合处理海量数据                         |
| 参数设置    | 仅需指定距离计算方式（如L2欧氏距离或IP内积），无需额外训练过程 |
| 主要用途    | 精确检索任务、作为其他近似索引的性能比较基准            |



#### 基于量化的索引：IVF系列

倒排索引如同图书馆的分类目录，它会将数据预先划分成多个类别，比如 “科技类”“文学类” 等，在执行搜索任务时，只需在相关类别内进行数据比对，从而减少搜索范围。

   倒排索引主要由词汇表和倒排记录表（Posting List, PL）组成，词汇表存储着在所有文档集合中出现过的词汇，倒排记录表记录包含对于每一个词汇项对应的所有文档标识符（即文档的ID）以及词频、位置等信息。
   > 假设有以下文档集合：
   >  文档1: "Hello world"
   >  文档2: "Hello DataWhale"
   >  文档3: "Hello easy_vectorDB"

    >构建倒排索引后，结果如下：
    > Hello: [文档1, 文档2, 文档3]
    > world: [文档1]
    > DataWhale: [文档2]
    > easy_vectorDB: [文档3]
IVF系列索引的核心机制是通过基于中心点的分区策略将向量聚类到多个桶中，在搜索过程中仅扫描与查询向量中心点相近的桶内向量，从而显著降低计算成本。
![alt text](/images/IVF1.png)
上图中你可以看到IVF系列索引对数据的聚类，通过不同的聚类算法将数据聚类到不同的桶中，每一聚类都有一个聚类中心。
![alt text](/images/IVF2.png)
每一个聚类中心对应的有一个向量表示，如上图所示。
当我们提供一个查询向量时，会先计算该向量与所有聚类中心之间的距离，然后选择距离最近的聚类中心，并仅搜索该聚类中心内的向量。通过这种方式，IVF系列索引能够显著减少搜索空间，提高搜索效率。但这种方法也存在缺点，在进行近似最近邻搜索时，可能会出现一种情况：通过算法找到的“最接近查询嵌入的候选嵌入”实际上并不是真正的最近邻。
![alt text](/images/IVF3.png)

这是因为IVF系列索引在聚类过程中，可能会将距离较远的向量分配到同一个聚类中，导致在搜索过程中，虽然找到了距离较近的聚类中心，但该聚类中心内的向量可能并不包含真正的最近邻。因此，IVF系列索引更适合用于近似最近邻搜索，而不是精确最近邻搜索。
> 具体来说，当使用聚类方法（例如IVF_FLAT中的k-means）对数据点进行分组时，每个聚类都有一个中心点（centroid）。在查询时，算法首先会确定哪个聚类的中心点与查询向量最为接近，然后在该聚类内部查找最近的向量作为候选嵌入。然而，如果实际的最近邻（即距离查询向量最近的数据点）位于另一个聚类中，而这个聚类的中心点与查询向量的距离相对更远，那么根据中心点选择的聚类将不会包含真实的最近邻。这就导致了找到的候选嵌入不是准确的最近嵌入。

为了解决这个问题，IVF_FLAT提供了两个超参数供我们调整：

* nlist:指定整个数据集将被分成多少个子集（即使用k-means算法创建的聚类中心的数量）。增加这个值可以使得每个分区内的向量更加相似，但同时也会增加计算开销。

* nprobe:搜索期间会检查的分区数量。增大这个值可以提高召回率（即找到真正最近邻的可能性），因为更多的候选分区被考虑进来，但这同样会增加搜索时间。


通过增加nprobe 值，可以在搜索中包含更多分区，这有助于确保不会错过与查询最接近的嵌入，即使它位于不同的分区中。不过，这样做的代价是增加搜索时间，因为需要评估更多候选项。

IVF系列包含IVF_FLAT、IVF_SQ8和IVF_PQ三种主要类型，其技术演进逻辑围绕压缩率提升与精度平衡展开，逐步实现内存占用的降低。

| 索引类型     | 构建参数                                     | 搜索参数                                     | 压缩技术                              | 内存占用             | 召回率  |
| -------- | ---------------------------------------- | ---------------------------------------- | --------------------------------- | ---------------- | ---- |
| IVF_FLAT | nlist（范围[1,65536]，默认128）                 | nprobe（范围[1,nlist]，默认8）、max_empty_result_buckets（范围[1,65535]，默认2） | 无压缩                               | 最高（与原始数据相近）      | 最优   |
| IVF_SQ8  | nlist（范围[1,65536]，默认128）                 | nprobe（范围[1,nlist]，默认8）、max_empty_result_buckets（范围[1,65535]，默认2） | 标量量化（SQ），将FLOAT（4字节）转换为UINT8（1字节） | 中等（减少70-75%内存消耗） | 次之   |
| IVF_PQ   | nlist（范围[1,65536]，默认128）、m（乘积量化因子数，需满足dim mod m=0）、nbits（范围[1,64]，默认8） | nprobe（范围[1,nlist]，默认8）、max_empty_result_buckets（范围[1,65535]，默认2） | 乘积量化（PQ），将高维向量分解为低维子向量并量化         | 最低               | 最低   |




IVF_FLAT作为系列基础，是FLAT索引的改进版本，其核心特点是每个桶内存储原始向量，未进行压缩处理。构建时需指定nlist参数（聚类数量，取值范围[1,65536]，默认128）以确定桶的数量；搜索阶段支持普通搜索（通过nprobe参数设置查询桶数，范围[1,nlist]，默认8）和范围搜索（通过max_empty_result_buckets参数控制最大空白桶数，范围[1,65535]，默认2）。由于保留原始向量，IVF_FLAT的索引文件大小与原始数据相近，内存占用最高，但召回率表现最优。

在IVF_FLAT基础上，IVF_SQ8通过引入标量量化（SQ）技术实现压缩，将每个4字节的FLOAT类型向量分量转换为1字节的UINT8类型，可减少70-75%的内存消耗（例如1B规模的SIFT数据集仅需140GB存储空间）。其构建参数（nlist）和搜索参数（nprobe、max_empty_result_buckets）与IVF_FLAT完全一致，适用于内存资源有限且可接受召回率轻微下降的场景。相较于IVF_FLAT，IVF_SQ8以精度的小幅损失换取了显著的内存优化。

IVF_PQ则进一步采用乘积量化（PQ）技术深化压缩，其流程为：先通过IVF进行聚类分区，再将每个高维向量分解为多个低维子向量，对各子向量独立量化后存储。该方法使索引文件体积较IVF_SQ8进一步减小，但精度损失更为明显。构建时除nlist参数外，还需配置m（乘积量化因子数，需满足向量维度dim能被m整除）和nbits（每个子向量的存储位数，范围[1,64]，默认8）。搜索参数与IVF_FLAT、IVF_SQ8保持一致。

综合来看，IVF系列三种索引的内存占用呈现IVF_PQ \< IVF_SQ8 \< IVF_FLAT的关系，而召回率则相反，IVF_FLAT最优，IVF_SQ8次之，IVF_PQ最低。这种差异源于量化技术的逐步引入与深化，体现了存储效率与检索精度之间的权衡。


#### 基于图的索引：HNSW系列

图索引像是一张关系网，每个数据点都记录着自己的 “最近邻居”，搜索时能够沿着这张关系网快速跳转，实现高效查找。在前文中，我们使用过的HNSW索引就是一种典型的图索引。

HNSW索引是一种基于图的索引，在使用此索引构建向量后，能够提高搜索的精度（相对于使用量化的索引来说）和速度。但内存的消耗会增大。

分层导航小世界（HNSW）算法构建了一个多层图，有点像不同缩放级别的地图。底层包含所有数据点，而上层则由从底层采样的数据点子集组成。在这种层次结构中，每一层都包含代表数据点的节点，节点之间由表示其接近程度的边连接。上层提供远距离跳转，以快速接近目标，而下层则进行细粒度搜索，以获得最准确的结果。

下面是它的工作原理：

1. 入口点：搜索从顶层的一个固定入口点开始，该入口点是图中的一个预定节点。
2. 贪婪搜索：算法贪婪地移动到当前层的近邻，直到无法再接近查询向量为止。上层起到导航作用，作为粗过滤器，为下层的精细搜索找到潜在的入口点。
3. 层层下降：一旦当前层达到局部最小值，算法就会利用预先建立的连接跳转到下层，并重复贪婪搜索。
4. 最后 细化：这一过程一直持续到最底层，在最底层进行最后的细化步骤，找出最近的邻居。

![alt text](/images/hnsw.png)
HNSW（分层导航小世界图Navigable Small World Graph）通过构建多层导航图实现高效向量检索，其核心结构特点为上层稀疏、下层密集，搜索过程从上层起始逐步向下层精确导航，这一设计使其能够实现对数时间复杂度的查询性能，从而具备低延迟优势。HNSW在每层都是一个小世界图，通过图数据结构组织，上层节点也是通过投币决定在哪一层，并且它们在下层图中都有记录，
> “投币”机制，是一种用于决定节点在图中所处层级的随机化策略。其原理类似于通过抛硬币（即概率决策）来确定新插入节点是否进入更高层图结构的过程。
> * 新节点加入时，会先被放入最底层（第0层），然后以一定的概率（如50%）决定是否将其提升到上一层。这个过程可以形象地理解为“投币”：如果结果是“正面”，节点就进入上一层；如果是“反面”，则停留在当前层。
> * 通常情况下，高层级的节点数量比低层级少得多，例如每向上一层，节点数量大约减半。这种设计保证了图结构的稀疏性，使得高层可用于快速导航，而底层则提供更精细的搜索能力。
> * 上层图可以看做下层图的一个缩影，检索时，从上到下，不断指引检索过程逐步靠近想要探寻的向量空间。另外在构图过程中HNSW通过边的裁剪来保证图的连通性。

在构建阶段，通过参数M（图中节点最大传出连接数量，取值范围[2,2048]）控制图的连接密度，efConstruction（构建时的搜索范围，取值范围[1,int_max]）平衡索引质量与构建时间；搜索阶段则通过参数ef（搜索时的搜索范围，取值范围[top_k,int_max]）调节查询时间与准确度的权衡。

为优化内存占用，HNSW系列衍生出多种量化变体，这些变体通常通过牺牲部分召回率和构建速度来换取内存效率的提升。HNSW_SQ结合标量量化（SQ）技术，将浮点数据离散化为有限数值（如SQ6量化为64个值），显著减少内存占用，同时保持较高的QPS性能，但构建时间较基础HNSW有所增加。HNSW_PQ则采用乘积量化（PQ），将向量分解为多个子向量并分别量化，可灵活权衡索引大小与准确性，但相比HNSW_SQ，其QPS和召回率更低，构建时间更长。

| 变体名称     | 核心技术       | 内存占用 | QPS性能 | 构建时间 | 召回率   | 主要特点                          |
| -------- | ---------- | ---- | ----- | ---- | ----- | ----------------------------- |
| HNSW     | 分层导航小世界图   | 高    | 高     | 基准   | 高     | 适用于高速查询、高召回率场景，通过M和ef参数控制性能   |
| HNSW_SQ  | 标量量化（如SQ6） | 低    | 较高    | 适度增加 | 较高    | 将浮点数据离散化为有限数值（如64个值），显著减少内存占用 |
| HNSW_PQ  | 乘积量化       | 中-低  | 中     | 更长   | 中     | 向量分解为子向量量化，可灵活权衡索引大小与准确性      |
| HNSW_PRQ | 乘积残差量化     | 中-低  | 中     | 增加数倍 | 与PQ相当 | 对PQ残差再次量化，压缩率控制更灵活，精度保持或提升    |



HNSW_PRQ作为基于乘积残差量化（PRQ）的变体，通过对PQ量化后的残差进行再次量化，进一步优化了索引大小与准确性的权衡灵活性。在相同压缩率下，HNSW_PRQ的QPS和召回率与HNSW_PQ相当，但其残差补偿机制使得在精度保持或提升的同时，能够实现更灵活的压缩控制，不过这也可能导致构建时间增加数倍。

#### 其他浮点索引：SCANN与DiskANN

在浮点嵌入索引中，SCANN与DiskANN作为两类重要的优化方案，分别在查询性能与大规模数据存储方面展现了独特优势。  

SCANN（可扩展近邻）与IVF_PQ在基础架构上具有相似性，但通过引入SIMD（单指令多数据）优化显著提升了计算效率，尤其针对GPU环境进行了深度适配，从而实现了更高的查询吞吐量（QPS）。其核心优势在于极高速查询能力与高召回率，适用于内存资源充足的场景。在参数配置方面，SCANN的构建参数包括nlist（聚类数量）和with_raw_data（是否包含原始数据，默认值为True）；搜索阶段则可通过调整nprobe（查询的聚类中心数量）、reorder_k（候选向量数量，默认值为top_k）及max_empty_result_buckets（范围搜索参数，默认值为2）进一步优化性能。  

| 索引类型    | 核心技术                   | 适用场景                | 构建参数                              | 搜索参数                                     |  |
| ------- | ---------------------- | ------------------- | --------------------------------- | ---------------------------------------- | ---- |
| SCANN   | 类IVF_PQ架构，SIMD优化，GPU适配 | 极高速查询、高召回率、内存资源充足场景 | nlist（聚类数量）、with_raw_data（默认True） | nprobe、reorder_k（默认top_k）、max_empty_result_buckets（默认2） |      |
| DiskANN | Vamana图结构，PQ量化，磁盘存储    | 内存无法容纳的十亿级及以上大规模数据集 | -                                 | -                                        |      |



DiskANN则专注于解决内存资源限制下的大规模数据存储问题，其技术路径基于Vamana图结构，并结合乘积量化（PQ）技术实现磁盘-内存混合存储。具体而言，DiskANN将图结构存储于磁盘以突破内存容量限制，同时通过PQ对向量进行压缩，减小数据体积并加速近似距离计算，有效缓解了磁盘IOPS瓶颈。这一设计使其特别适用于内存无法容纳的十亿级及以上规模数据集，在平衡查询延迟与存储容量方面具有不可替代性   。

### 二进制嵌入索引

二进制嵌入索引通过将向量转换为二进制表示形式，显著提升了存储效率。其存储空间计算公式为n/8字节（n为向量维度），例如128维二进制向量仅需16字节，远低于同等维度浮点向量的存储需求。该类索引支持JACCARD和HAMMING两种距离度量方式，主要包含两种典型实现：BIN_FLAT和BIN_IVF_FLAT。

| 索引类型         | 适用场景                  | 支持的距离度量         | 存储效率          | 核心特点             |
| ------------ | --------------------- | --------------- | ------------- | ---------------- |
| BIN_FLAT     | 小数据集、需100%召回率、无需压缩的场景 | JACCARD、HAMMING | n/8字节（n为向量维度） | 精确检索，与FLAT原理一致   |
| BIN_IVF_FLAT | 高速查询、高召回率的场景          | JACCARD、HAMMING | n/8字节（n为向量维度） | 基于IVF结构，通过量化加速查询 |



其中，BIN_FLAT索引与FLAT索引原理一致，专为二进制嵌入设计，适用于小数据集、需100%召回率且无需压缩的场景；BIN_IVF_FLAT则基于倒排文件（IVF）结构，通过量化加速查询过程，适合对查询速度和召回率均有较高要求的场景。在选型边界方面，二进制嵌入索引与浮点索引的核心区别由向量类型决定：当处理对象为二进制向量时，应优先选择二进制嵌入索引以充分发挥其存储效率优势；若向量为浮点类型，则需采用浮点索引类型。

### 稀疏嵌入索引

稀疏嵌入的核心特征是向量中非零值占比极低，这种稀疏性使其在存储和计算上具有独特优势，但也对索引结构提出了特殊要求。稀疏嵌入索引主要支持内积（IP）和BM25（全文检索）度量方式，目前主流的索引类型包括SPARSE_INVERTED_INDEX和SPARSE_WAND两种。

| 索引类型                  | 适用场景        | 召回率    | 性能特点                                | 关键参数                       |
| --------------------- | ----------- | ------ | ----------------------------------- | -------------------------- |
| SPARSE_INVERTED_INDEX | 小数据集        | 100%   | 确保完全召回，大规模数据效率有限                    | 无                          |
| SPARSE_WAND           | 需平衡速度与召回率场景 | 接近100% | 弱-AND算法加速，向量密度增加时性能下降，通过参数调整精度与性能平衡 | drop_ratio_search（范围[0,1]） |



SPARSE_INVERTED_INDEX（稀疏反转索引）适用于小数据集场景，其设计目标是确保100%的召回率，即在检索过程中不会遗漏任何相关结果，但在处理大规模数据时效率相对有限。

SPARSE_WAND（稀疏弱AND索引）则通过引入弱-AND（Weak-AND）算法实现性能优化。该算法的核心机制是减少对完整内积（IP）距离的计算次数：通过预设阈值筛选出对距离计算贡献较大的非零维度，仅对这些关键维度进行计算，从而显著提升检索速度。然而，SPARSE_WAND的性能表现与向量密度密切相关——当向量密度（非零值比例）增加时，需要计算的维度增多，弱-AND算法的筛选效率下降，导致性能出现衰减。为平衡检索精度与性能，SPARSE_WAND提供了drop_ratio_search参数（取值范围为[0,1]），该参数通过设置忽略小值的比例，进一步减少参与计算的非零维度数量，从而在牺牲少量召回率的前提下提升检索效率。

### GPU索引

GPU索引通过利用GPU的并行计算能力，显著提升向量索引构建与搜索过程的吞吐量，尤其适用于极高吞吐量场景，但其加速效果主要体现在数据处理规模上，不一定能直接减少单次查询的延迟。不同类型的GPU索引在内存占用、精度、查询性能等方面各具特性，适用于不同业务需求场景。

| 索引类型            | 内存占用情况            | 精度/召回率   | 主要特点                                     | 适用场景                 |
| --------------- | ----------------- | -------- | ---------------------------------------- | -------------------- |
| GPU_CAGRA       | 约为原始数据的1.8倍       | -        | 基于图结构优化，提供丰富构建（如intermediate_graph_degree）与搜索参数（如itopk_size），低延迟表现突出 | 极高吞吐量场景，对延迟敏感的业务需求   |
| GPU_IVF_FLAT    | 与原始数据等大           | -        | 查询时间随nq（输入向量数）和nprobe（搜索簇数）增加急剧上升        | 中小规模查询场景             |
| GPU_IVF_PQ      | 取决于压缩参数，小于IVF_SQ8 | 精度损失较大   | 通过向量压缩降低内存占用，索引文件较小                      | 内存资源有限且可接受一定精度损失的场景  |
| GPU_BRUTE_FORCE | 与原始数据等大           | 100% 召回率 | 暴力搜索，仅需配置metric_type和top_k参数             | 对结果准确性要求极高、数据规模较小的场景 |



GPU_CAGRA是基于图结构的GPU优化索引，其内存使用量约为原始数据的1.8倍。该索引提供了丰富的构建与搜索参数以平衡性能，例如构建阶段可通过调整intermediate_graph_degree（剪枝前图度数，推荐32或64）、graph_degree（剪枝后图度数，需小于前者）、build_algo（支持IVF_PQ或NN_DESCENT算法）等参数优化图结构；搜索阶段则可通过itopk_size（中间结果大小，至少为目标top_k且通常设为2的幂次）、search_width（入口点数量）、迭代次数范围（min_iterations/max_iterations）等参数控制搜索效率与精度。由于其图结构优化和并行计算适配性，GPU_CAGRA在低延迟场景中表现突出。

GPU_IVF_FLAT的原理与CPU版本的IVF_FLAT类似，需占用与原始数据等大的内存空间。其查询时间对输入向量数量（nq）和搜索簇数（nprobe）较为敏感，两者的增加会导致查询时间急剧上升，因此更适合中小规模查询场景。

GPU_IVF_PQ通过向量压缩降低内存占用，其索引文件大小小于IVF_SQ8，但会引入一定的精度损失，内存占用量取决于具体的压缩参数配置，适用于内存资源有限且可接受一定精度损失的场景。

GPU_BRUTE_FORCE采用暴力搜索方式，能够实现100%的召回率，但其内存需求与原始数据相当，且仅需配置metric_type（距离度量类型）和top_k（返回结果数量）两个核心参数，适用于对结果准确性要求极高、数据规模较小的场景。

在高并发场景中，GPU索引凭借并行计算优势可高效处理大量并发查询，显著提升系统整体吞吐量。然而，其应用需权衡硬件成本：GPU设备本身购置成本较高，且不同索引对内存容量要求各异（如GPU_CAGRA需1.8倍原始数据内存，GPU_IVF_FLAT与GPU_BRUTE_FORCE需等大内存），因此需结合业务对延迟、召回率、吞吐量的需求及硬件预算综合选择。

## 代码实践
学习完上述的索引的知识后，我们将通过代码来更加可观的观察不同索引在定量数据集上的表现。
![alt text](/images/milvus_perf_comparison_20250710-003445.png)

点击:[代码实践](milvus_perf_test.py)
运行如下命令，安装需要的包
```shell
pip install pymilvus prettytable matplotlib
```

运行如下命令，运行代码
```shell
python milvus_perf_test.py
```


## 关键性能指标与权衡关系

### 核心性能指标定义

ANNS向量索引的核心性能指标是评估和选择索引方案的基础，主要包括构建时间、每秒查询次数（QPS）、召回率及内存使用量。其中，构建时间指索引创建过程所消耗的时间，直接影响索引的初始化效率；每秒查询次数（QPS）反映搜索操作的效率，即单位时间内可处理的查询请求数量；召回率衡量搜索结果的准确性，体现返回的相关结果占所有相关结果的比例；内存使用量则表征索引对系统内存资源的占用情况，其大小受数据结构设计、量化压缩策略及精炼器等因素影响 。

在实际应用中，需根据场景需求明确各指标的优先级逻辑。例如，实时应用（如在线推荐、实时检索服务）对响应速度要求严苛，QPS通常作为核心优先级指标；离线分析场景（如大规模数据挖掘、批量检索任务）更注重结果的完整性和准确性，此时召回率应优先考虑；而构建时间和内存使用量需结合资源约束进行权衡，如高频更新的动态数据集对构建时间敏感，资源受限的边缘设备则需重点关注内存占用。通过建立包含上述指标的评估框架，可实现对索引性能的量化分析，为后续索引选择决策提供客观依据。

### 性能权衡规律

ANNS向量索引的选择需遵循“速度-精度-内存”三角权衡模型，即提升某一维度性能往往以牺牲其他维度为代价。以下结合具体索引案例分析其内在规律：

在**速度（查询效率）** 维度，基于图的索引（如HNSW）通常表现更优，其QPS（每秒查询次数）普遍高于IVF系列变体。这一优势在小topK（如小于2000）场景中尤为显著，而当topK较大（如大于2000或占数据集比例≥1%）时，IVF变体因分桶机制更适配批量查询需求。此外，过滤率（搜索前过滤数据比例）也影响速度表现：过滤率\<85%时图索引效率占优，85%-95%时IVF更合适，>98%时则需采用暴力搜索（FLAT）以平衡精度与计算成本。

**精度（召回率）** 方面，量化技术（如PQ、SQ）是内存优化的主要手段，但会导致精度损失。相同压缩率下，PQ较SQ能保留更高召回率，但查询速度略慢；而IVF系列（如IVF-PQ）虽通过量化显著降低内存占用，其召回率通常低于非量化索引（如HNSW）。对于极致精度需求（如过滤率>98%），FLAT索引仍是唯一选择，因其无近似计算误差。

**内存占用** 是资源受限场景的核心考量。IVF系列（如IVF-PQ）通过乘积量化技术实现高效压缩，内存消耗仅为11MB/百万128维向量，远低于HNSW的640MB/百万128维向量。对于超大规模数据集，DiskANN可通过磁盘存储管理数据，但需注意潜在的IOPS瓶颈对查询速度的影响。



| 索引类型      | QPS表现     | 召回率适用过滤率 | 内存占用（128维向量/百万） | 适用场景                        |
| --------- | --------- | -------- | --------------- | --------------------------- |
| HNSW（图索引） | 通常优于IVF变体 | \<85%    | 640MB           | 小topK（\<2000）、高召回率、高吞吐低延迟场景 |
| IVF变体     | 低于HNSW    | 85%-95%  | 取决于量化技术         | 大topK（>2000或≥数据集1%）、批量查询    |
| IVF-PQ    | -         | -        | 11MB            | 内存受限场景，需结合mmap              |
| FLAT      | 最低（暴力搜索）  | >98%     | 最高（无压缩）         | 极致精度需求，过滤率>98%              |
| DiskANN   | 受IOPS瓶颈影响 | -        | 磁盘存储，内存占用低      | 超大规模数据集，磁盘级数据管理             |



## 索引选择决策

### 决策关键因素

在选择ANNS向量索引时，需综合考虑多维度决策关键因素，这些因素可系统地分为数据特性、资源约束和业务需求三大类，并需建立清晰的优先级排序逻辑以指导选择过程。  
我们将使用通俗的话来解释这三大类：
1. 数据特性：数据特性主要设计数据的存储位置，如内存、磁盘等。这直接影响索引的存储设计与访问效率。
2. 资源约束：内存资源是核心考量因素，包括内存是否有限或充足，以及是否需要通过量化技术或磁盘存储来优化内存使用。  
3. 业务需求则涵盖多个关键性能指标，包括
   * 召回率要求（如高召回率或可接受一定程度的召回率下降）
   * 查询延迟（如低延迟或可接受范围内的延迟）
   * topK大小（如小批量或大批量结果返回）
   * 过滤率（如低过滤率或高过滤率需求）
   * 整体性能要求（如QPS、延迟与召回率的平衡） 

例如：在政务问答系统中，往往我们需要召回大量的数据，尽可能的将模型上下文拉满，以获得更好的结果。因此，我们需要选择一个高召回率的索引，同时考虑到内存资源有限，我们可能需要选择一个内存占用较低的索引，如IVF-PQ结合mmap。除此之外，我们还需考虑到查询延迟，因为政务问答系统需要实时返回结果，因此我们需要选择一个查询延迟较低的索引，如HNSW。最后，我们需要考虑整体性能要求，选择一个综合考虑上述关键因素的索引，如HNSW、IVF+精炼。
为帮助用户系统选择适合的ANNS向量索引，可基于实际应用场景构建决策矩阵，并将其转化为分步骤筛选流程。以下为整合后的推荐索引决策矩阵：

| 场景            | 推荐索引          | 注释            |
| ------------- | ------------- | ------------- |
| 原始数据适合内存      | HNSW、IVF+精炼   | HNSW适合低k/高召回率 |
| 原始数据在磁盘/固态硬盘  | DiskANN       | 适合延迟敏感查询      |
| 原始数据在磁盘且RAM有限 | IVFPQ/SQ+mmap | 平衡内存与磁盘访问     |
| 高过滤率（>95%）    | FLAT（暴力）      | 避免候选集过小的索引开销  |
| 大型k（≥数据集的1%）  | IVF           | 簇剪枝减少计算量      |
| 极高召回率（>99%）   | FLAT+GPU      | --            |



| 场景            | 推荐索引          | 注释            |
| ------------- | ------------- | ------------- |
| 原始数据适合内存      | HNSW、IVF+精炼   | HNSW适合低k/高召回率 |
| 原始数据在磁盘/固态硬盘  | DiskANN       | 适合延迟敏感查询      |
| 原始数据在磁盘且RAM有限 | IVFPQ/SQ+mmap | 平衡内存与磁盘访问     |
| 高过滤率（>95%）    | FLAT（暴力）      | 避免候选集过小的索引开销  |
| 大型k（≥数据集的1%）  | IVF           | 簇剪枝减少计算量      |
| 极高召回率（>99%）   | FLAT+GPU      | --            |

基于上述矩阵，索引选择流程可分为以下步骤：首先，判断数据存储位置及内存适配情况。若数据可完全加载至内存，优先考虑HNSW（适用于低k值、高召回率场景）或IVF+精炼组合；若数据存储于磁盘或固态硬盘且对查询延迟敏感，选择DiskANN；若数据在磁盘且内存资源有限，则采用IVFPQ/SQ结合内存映射（mmap）以平衡内存占用与磁盘访问效率 。其次，考虑查询特性与需求：当过滤率超过95%时，FLAT（暴力搜索）可避免索引带来的额外开销；当查询k值较大（≥数据集规模的1%），IVF通过簇剪枝能有效减少计算量；若需极高召回率（>99%），建议使用FLAT+GPU方案。

此外，需注意例外情况：在GPU环境下，应优先考虑GPU加速的索引（如GPU_CAGRA），以充分利用硬件算力提升查询性能。通过上述流程，可根据具体场景快速定位最优索引方案。

## 实战参数配置与优化

### 核心索引参数调优

核心索引参数的调优是平衡向量检索系统召回率、查询性能（如QPS）及资源消耗的关键环节。不同类型的ANNS索引具有独特的核心参数，其调整机制直接影响索引的构建效率、查询速度及检索精度。

| 索引类型  | 参数名称              | 参数作用          | 推荐值范围      | 性能影响                   |
| ----- | ----------------- | ------------- | ---------- | ---------------------- |
| IVF系列 | nlist             | 决定向量空间聚类划分粒度  | 百万级数据1024  | 增大可提升搜索速度，但可能降低召回率     |
| IVF系列 | nprobe            | 控制查询时遍历的簇数量   | 8-100      | 增大可提高召回率，但会增加查询时间      |
| HNSW  | M                 | 图中每个节点的连接度数   | 16-48      | 增大可提升检索精度，但增加构建时间和内存占用 |
| HNSW  | efConstruction    | 索引构建阶段的搜索范围参数 | 200-500    | 增大可提升索引质量，但延长构建时间      |
| HNSW  | ef                | 查询阶段的搜索范围参数   | top_k-2000 | 增大可提高搜索精度，但降低查询速度      |
| SCANN | reorder_k         | 重排序候选向量数量     | top_k-1000 | 增大可提高召回率，但增加计算量和查询时间   |
| 稀疏索引  | drop_ratio_search | 查询时忽略小值元素的比例  | -          | 调整可在精度与性能之间取得平衡        |



对于IVF（倒排文件）系列索引，核心参数包括nlist（簇数量）和nprobe（查询时访问的簇数量）。其中，nlist决定了向量空间的聚类划分粒度，其值增大可减少每个簇内的向量数量，从而提升搜索速度，但过大会导致聚类效果下降，反而降低召回率。实际应用中，推荐根据数据集规模调整nlist，例如百万级数据集可设置为1024  。nprobe则控制查询时遍历的簇数量，增大nprobe能覆盖更多潜在相似向量，从而提高召回率，但会增加查询时间，通常推荐取值范围为8-100  。

HNSW（层次化近似最近邻）索引的核心参数包括M、efConstruction和ef。M表示图中每个节点的连接度数，其值增大可增强图的连通性，提升检索精度，但会显著增加索引构建时间和内存占用，推荐取值范围为16-48。efConstruction是索引构建阶段的搜索范围参数，增大该值可提升索引质量（即图结构的准确性），但会延长构建时间，推荐设置为200-500。ef为查询阶段的搜索范围参数，其作用与efConstruction类似，增大ef能提高搜索精度，但会降低查询速度，实际取值需结合目标top_k，推荐范围为top_k至2000  。

SCANN（可扩展最近邻搜索）索引的核心参数为reorder_k（重排序候选向量数量）。该参数决定了查询过程中参与重排序阶段的候选向量规模，增大reorder_k可保留更多潜在相似向量，从而提高召回率，但会增加计算量并延长查询时间，推荐取值范围为top_k至1000  。

针对稀疏向量索引，核心参数为drop_ratio_search（查询时忽略小值元素的比例）。通过调整该参数，可在检索过程中过滤掉贡献度较低的稀疏向量元素，减少计算开销，从而在精度与性能之间取得平衡  。

参数调优的通用方法论建议从索引的默认参数开始，通过控制变量法逐步调整目标参数，并实时监控召回率、QPS、内存占用等关键指标的变化。例如，在调整nprobe时，可从默认值开始逐步增大，观察召回率提升趋势及QPS下降幅度，直至找到满足业务需求（如召回率阈值、延迟要求）的最优平衡点。对于多参数组合（如HNSW的M与ef），则需通过正交实验或网格搜索方法，综合评估参数交互对整体性能的影响。

### 内存与存储优化策略

在向量索引的实际部署中，内存与存储资源的高效利用是关键挑战之一。以100万128维向量为例，不同索引类型的内存占用差异显著，如IVF_PQ索引仅需11MB内存，而HNSW_PQ索引则需136MB，这种差异凸显了优化策略的重要性。



**内存占用对比数据：**
- IVF_PQ 索引：11 MB
- HNSW_PQ 索引：136 MB




内存规划可遵循以下步骤：首先，根据数据集规模（如向量数量、维度）和选定的索引类型（如IVF、HNSW等）估算基础内存需求。若估算结果超出可用内存，则需采用针对性优化手段。常用策略包括量化、内存映射（mmap）及磁盘存储方案（如DiskANN）。

| 优化策略       | 技术方法     | 效果描述               |
| ---------- | -------- | ------------------ |
| 量化         | PQ（乘积量化） | 实现64倍压缩            |
| 量化         | SQ（标量量化） | IVF_SQ8索引减少75%内存消耗 |
| 内存映射（mmap） | 直接访问磁盘文件 | 减少I/O开销，扩展存储容量     |
| DiskANN    | 图结构存储于磁盘 | 处理内存无法容纳的超大型数据集    |



量化技术通过压缩向量表示降低内存占用，典型方法包括乘积量化（PQ）和标量量化（SQ）。例如，PQ可实现64倍压缩，而IVF_SQ8索引通过标量量化能减少75%的内存消耗。内存映射（mmap）技术允许直接访问磁盘文件，在减少I/O开销的同时扩展存储容量，适用于内存资源有限但磁盘空间充足的场景。对于内存无法容纳的超大型数据集，可采用DiskANN等磁盘存储方案，将图结构存储于磁盘以处理大规模数据 。通过结合上述策略，可在保证检索性能的前提下，有效降低内存与存储成本。

## 特殊场景与最佳实践

### 超大规模数据集（十亿级）

在处理十亿级规模的超大规模向量数据集时，由于内存资源通常无法完全容纳全部数据，需依赖磁盘存储与内存访问的协同优化。DiskANN是应对此类场景的关键技术之一，其核心原理是通过磁盘存储Vamana图结构，并结合乘积量化（PQ）压缩技术，实现对内存无法容纳的超大规模数据集的高效检索 。这种“磁盘图结构+压缩存储”的设计，既能突破内存容量限制，又能通过PQ量化减少数据传输与存储开销。

在延迟表现方面，与基于内存映射（mmap）的方案（如IVF_PQ/SQ+mmap）相比，DiskANN的延迟更为稳定。mmap方案虽通过内存映射平衡内存占用与磁盘访问，但磁盘I/O的随机性可能导致延迟波动；而DiskANN通过优化的图遍历策略与预取机制，可减少磁盘访问的不确定性，从而提供更一致的响应延迟。

针对十亿级数据集的索引组合方案，实践中主要有两类选择：一是采用DiskANN结合PQ量化，利用磁盘存储图结构并通过PQ压缩向量，适用于极致内存受限场景 ；二是使用IVF_PQ/SQ与mmap结合，通过IVF的粗聚类减少检索范围，配合PQ/SQ量化降低内存占用，同时借助mmap实现磁盘数据的高效内存访问，在内存与延迟之间取得平衡。具体选择需根据实际内存资源、延迟需求及数据特性综合考量。

### 高并发低延迟场景

在高并发低延迟场景中，向量索引的选择需重点平衡查询吞吐量、响应时间与资源成本。基于图的索引（如HNSW）凭借对数时间复杂度的搜索特性，以及DiskANN针对延迟敏感查询的优化设计，成为该场景下的核心选择 。此外，GPU加速索引（如GPU_CAGRA）通过硬件并行计算能力，可显著提升高并发处理效率。

| 索引类型      | 技术特点       | 适用场景              | 优化参数               | 参考来源 |
| --------- | ---------- | ----------------- | ------------------ | ---- |
| HNSW      | 基于图的对数时间搜索 | 低延迟需求             | ef（探索节点数）          |      |
| DiskANN   | 针对延迟敏感查询优化 | 低延迟需求             | -                  |      |
| GPU_CAGRA | GPU加速并行计算  | 高并发、批量查询（nq>1000） | search_width（搜索宽度） | -    |



从硬件性价比角度看，CPU与GPU的适用场景存在差异：GPU更适合处理批量查询规模较大（nq>1000）的高并发场景，其并行计算架构能有效降低单位查询的处理延迟；而CPU在小规模查询或资源受限环境中可能更具成本优势。

| 硬件类型 | 适用场景              | 优势                | 限制                |
| ---- | ----------------- | ----------------- | ----------------- |
| CPU  | 小规模查询、资源受限环境      | 成本优势              | 并行处理能力有限，高并发下延迟较高 |
| GPU  | 批量查询规模较大（nq>1000） | 并行计算架构，降低单位查询处理延迟 | 资源成本较高，小规模查询性价比低  |



针对低延迟优化，实践中可采用“索引类型+参数调优+硬件加速”的组合策略。例如，HNSW索引可通过增大ef（查询时的探索节点数）参数提升搜索效率，GPU_CAGRA则可调整search_width（搜索宽度）参数平衡延迟与召回率。结合GPU加速技术，此类组合能在保证高召回率的同时，满足毫秒级甚至微秒级的低延迟需求。

### 常见问题解答

**FLAT与IVF_FLAT的核心差异**在于检索方式：FLAT索引通过直接比较查询向量与数据集中所有向量获得精确结果，而IVF_FLAT索引先将向量聚类为nlist个簇，查询时仅比较距离最近的nprobe个簇内向量以减少计算量。当数据集向量总数接近nlist时，IVF_FLAT的聚类优势不明显，性能与FLAT相近；当向量数量远大于nlist时，IVF_FLAT通过减少比较次数显著提升效率  。此处nlist（聚类簇数量）和nprobe（查询时检查的簇数）需协同调整：nlist过小会导致簇内向量过多，削弱加速效果；nprobe过大会增加计算量，接近FLAT的性能。  

| 索引类型     | 检索方式                         | 比较向量范围           | 性能关键参数                  | 性能特点                        | 适用场景             |
| -------- | ---------------------------- | ---------------- | ----------------------- | --------------------------- | ---------------- |
| FLAT     | 直接比较所有向量                     | 全部向量             | 无                       | 精确结果，计算量大，性能随数据量线性下降        | 小数据集，对精度要求极高的场景  |
| IVF_FLAT | 先聚类为nlist个簇，查询时比较nprobe个簇内向量 | 距离最近的nprobe个簇内向量 | nlist（簇数量）、nprobe（查询簇数） | 近似结果，计算量减少，数据量远大于nlist时优势显著 | 大数据集，需平衡精度与速度的场景 |


**PQ与SQ的压缩率差异**体现在量化粒度：标量量化（SQ）如IVF_SQ8对每个向量维度独立压缩，将4字节浮点值转为1字节整数，内存占用减少75%；乘积量化（PQ）如IVF_PQ（以8个子量化器为例）将向量分割为子向量后分别量化，可将512字节向量压缩至8字节，实现64倍压缩率。两者相比，PQ压缩率远高于SQ，但可能伴随更高的精度损失。  

**压缩倍数对比数据：**
- IVF_SQ8 索引：4倍压缩
- IVF_PQ 索引：64倍压缩


| 量化策略    | 压缩方式            | 原始大小 (每向量) | 压缩后大小 (每向量) | 内存减少比例  | 压缩倍数 |
| ------- | --------------- | ---------- | ----------- | ------- | ---- |
| IVF_SQ8 | 标量量化，每个维度独立压缩   | 4字节/维度     | 1字节/维度      | 75%     | 4倍   |
| IVF_PQ  | 乘积量化，8个子量化器分割向量 | 512字节      | 8字节         | 约98.44% | 64倍  |



**避坑指南**方面，小数据集应避免过度量化：由于数据量有限，FLAT或IVF_FLAT索引已能满足性能需求，使用IVF_PQ等强压缩索引反而可能因信息损失导致精度下降。此外，配置IVF类索引时需根据数据规模合理设置nlist（建议为数据量的平方根量级），并通过nprobe平衡召回率与速度（默认值通常为10，需根据精度需求调整）。

### 最后
以上是一个常见的索引优化建议，供学习者学习和参考，具体实现需结合实际数据集和需求进行微调。
对于企业级的检索系统来说，并不能单纯的选择一种或几种索引来优化检索，企业的数据集往往是亿级别的，并且召回率和召回速度要求非常高，普通的索引并不能很好的解决问题。为了提高召回率，部分企业会选择暴力索引来强行拉高召回率，但是采用这个索引的前提是，在召回之前，添加选择器，
> 选择器:（如聚类中心、图路由、学习型路由器、标量过滤器等）本身就是一个近似检索过程。它需要在极短时间（毫秒级）内决定访问哪些分区，这决定了它不可能做到 100% 准确。对于某些“边界”或“模糊”的 query，其真正相关的向量可能均匀散布在大量分区中，或者集中在某个未被选择器选中的“冷门”分区里。选择器很难完美处理所有边界情况。


避免暴力检索所有的数据，尽可能的在选择器的帮助下将搜索范围缩小到n个分区中，再进行暴力检索。不过这种方法存在一些问题，对于一个query，选择器选择出需要检索的k个分区，但是这k个分区中可能存在重复的向量，那么暴力检索就会重复计算。除此之外，可能在其他分区中，也存在会对最终结果造成很大影响的数据，你不能确定和保证其他分区里面没有你需要的数据。这是该策略最致命的弱点。一旦包含关键结果的分区被选择器漏掉，无论该分区内的向量与 query 多么相关，都没有机会进入最终结果集。这与暴力索引追求高召回的目标背道而驰。 对于大量不太热门或特征不典型的 query（长尾 query），选择器基于常见模式训练或设计，更容易出错，遗漏风险更高。


追求全局最优不可能： 在亿级甚至更大规模下，同时实现 100% 召回率、极低延迟和低成本是不可能的“三元悖论”。“暴力索引+选择器”是一种试图在可控成本/延迟下逼近高召回率的工程妥协。
你可以选择
1. 改进选择器
2. 优化分区策略
3. 缓解重复计算
4. **分层检索**

在分区内不使用纯暴力检索，而是使用针对该分区优化过的精确或近似索引（如 HNSW, IVF-PQ）。这能显著加速分区内检索，即使 k 值稍大或存在少量重复，整体延迟也可能可接受。这本质上是用分区内的索引加速来换取选择器可以放宽一些精度要求（允许选稍多分区或降低选择器复杂度），从而间接缓解遗漏问题。

(怎么解决？参考[FusionAnns优化方案](/docs/Milvus/chapter4/GPU加速检索-基于FusionANNS.md))
