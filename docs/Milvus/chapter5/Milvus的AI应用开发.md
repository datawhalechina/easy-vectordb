# Chapter 5 Milvusçš„AIåº”ç”¨å¼€å‘ï¼šå›¾åƒæ£€ç´¢åº”ç”¨å®æˆ˜
æœ¬ç« èŠ‚é‡‡ç”¨ipynbçš„æ–¹å¼è¿›è¡Œæ“ä½œï¼ŒæŒ‰ç…§æŒ‡ç¤ºè¿è¡Œä»£ç ï¼Œæ‰‹æŠŠæ‰‹å¸¦ä½ å®ç°ä¸€ä¸ªæ–‡æœå›¾åº”ç”¨ã€‚

ç‚¹å‡»->[Text_search_picä»£ç ](https://github.com/datawhalechina/easy-vectordb/blob/main/docs/Milvus/chapter5/1_build_text_image_search_engine.ipynb) è¿›è¡Œä¸‹è½½ã€‚

ä¸‹é¢æ˜¯Markdownæ ¼å¼çš„ä»‹ç»
## ç›¸å…³æŠ€æœ¯ä»‹ç»

### Towhere

Towhee æ˜¯ä¸€ä¸ªå¼€æºçš„ **å¤šæ¨¡æ€æ•°æ®å¤„ç†æ¡†æ¶**ï¼Œä¸“æ³¨äºé«˜æ•ˆç”Ÿæˆéç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰ï¼‰çš„å‘é‡è¡¨ç¤ºï¼ˆEmbeddingsï¼‰ï¼Œå¹¶æ”¯æŒæ„å»ºç«¯åˆ°ç«¯çš„ AI æµæ°´çº¿ï¼ˆPipelineï¼‰ã€‚å®ƒæ—¨åœ¨ç®€åŒ–ä»åŸå§‹æ•°æ®åˆ°å‘é‡åŒ–è¡¨ç¤ºå†åˆ°å®é™…åº”ç”¨ï¼ˆå¦‚æœç´¢ã€æ¨èã€é—®ç­”ç³»ç»Ÿï¼‰çš„å¼€å‘æµç¨‹ï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦å¤„ç†å¤šæ¨¡æ€æ•°æ®çš„åœºæ™¯ã€‚

---

### **ä¸€ã€Towhee çš„æ ¸å¿ƒåŠŸèƒ½**
1. **å¤šæ¨¡æ€ Embedding ç”Ÿæˆ**  
   - æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰éç»“æ„åŒ–æ•°æ®çš„å‘é‡åŒ–ã€‚
   - å†…ç½®ä¸°å¯Œçš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ BERTã€CLIPã€ViTã€ResNetã€Whisper ç­‰ï¼‰ï¼Œå¯ç›´æ¥è°ƒç”¨ã€‚
   - æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹é›†æˆï¼Œçµæ´»é€‚é…ä¸šåŠ¡éœ€æ±‚ã€‚

2. **æµæ°´çº¿ï¼ˆPipelineï¼‰æ„å»º**  
   - æä¾›å£°æ˜å¼ APIï¼Œé€šè¿‡é“¾å¼è°ƒç”¨å¿«é€Ÿç»„åˆæ•°æ®å¤„ç†æ­¥éª¤ï¼ˆå¦‚æ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€æ¨¡å‹æ¨ç†ã€åå¤„ç†ç­‰ï¼‰ã€‚
   - ç¤ºä¾‹ï¼šä¸€ä¸ªå›¾åƒæœç´¢æµæ°´çº¿å¯ä»¥åŒ…å« `å›¾åƒè§£ç  â†’ ç‰¹å¾æå– â†’ å‘é‡å½’ä¸€åŒ– â†’ å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“`ã€‚

3. **é«˜æ€§èƒ½ä¸å¯æ‰©å±•æ€§**  
   - æ”¯æŒæ‰¹é‡å¤„ç†ï¼ˆBatch Processingï¼‰å’Œ GPU åŠ é€Ÿã€‚
   - åˆ†å¸ƒå¼è®¡ç®—èƒ½åŠ›ï¼Œé€‚åˆå¤§è§„æ¨¡æ•°æ®å¤„ç†ã€‚
   - é€šè¿‡ç®—å­ï¼ˆOperatorï¼‰æœºåˆ¶ï¼Œå¯çµæ´»æ‰©å±•æ–°åŠŸèƒ½ã€‚

4. **ä¸å‘é‡æ•°æ®åº“æ— ç¼é›†æˆ**  
   - æ·±åº¦å…¼å®¹ Milvusã€Elasticsearchã€FAISS ç­‰å‘é‡æ•°æ®åº“ï¼Œç®€åŒ–æ•°æ®å­˜å‚¨ä¸æ£€ç´¢æµç¨‹ã€‚

---

## å‡†å¤‡
ç¡®ä¿ç³»ç»Ÿæœ‰GPUï¼ˆå¯ä»¥ä½¿ç”¨é­”æ­ç¤¾åŒºæä¾›çš„NoteBookï¼‰ï¼Œå¹¶ä¸”pythonç‰ˆæœ¬ä¸º3.10ï¼Œå½“å‰ä¸æ”¯æŒpython3.12

### ä¸‹è½½ä¾èµ–

```python 

import subprocess
import sys
import os

def install_package(package_name, version=None, use_mirror=True):
    try:
        if version:
            package = f"{package_name}{version}"
        else:
            package = package_name
        
        print(f"æ­£åœ¨å®‰è£… {package}...")
        cmd = [sys.executable, "-m", "pip", "install", package]
        if use_mirror:
            cmd += ["-i", "https://pypi.tuna.tsinghua.edu.cn/simple/", "--trusted-host", "pypi.tuna.tsinghua.edu.cn"]
        cmd.append("--quiet")
        
        subprocess.check_call(cmd)
        print(f"âœ… {package_name} å®‰è£…æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {package_name} å®‰è£…å¤±è´¥: {e}")
        return False

def check_and_install_dependencies():    
    required_packages = [
        ("torch", ">=2.0.0"),
        ("torchvision", None),
        ("transformers", ">=4.21.0"),
        ("open_clip_torch", None),
        ("Pillow", None),
        ("opencv-python", None),
        ("pandas", None),
        ("numpy", None),
        ("gradio", ">=4.0.0"),
        ("scikit-learn", None)
    ]

    for package_name, version in required_packages:
        import_name = package_name
        if package_name == "Pillow":
            import_name = "PIL"
        elif package_name == "open_clip_torch":
            import_name = "open_clip"
        elif package_name == "opencv-python":
            import_name = "cv2"
        else:
            import_name = package_name.replace('-', '_').split('[')[0]

        try:
            __import__(import_name)
            print(f"âœ… {package_name} å·²å®‰è£…")
        except ImportError:
            print(f"âŒ {package_name} æœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...")
            install_package(package_name, version, use_mirror=True)
check_and_install_dependencies()
```

### ç¯å¢ƒæ£€æŸ¥

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹è¿è¡Œç¯å¢ƒï¼š
- Python ç‰ˆæœ¬åº”è¯¥æ˜¯ 3.8 æˆ–æ›´é«˜
- å¦‚æœæœ‰ GPUï¼Œç¡®ä¿ CUDA å¯ç”¨
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ä¸‹è½½æ¨¡å‹å’Œæ•°æ®

### å‡†å¤‡æ•°æ®
æ•°æ®é›†åŒ…å«100ä¸ªå›¾åƒç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ«ä¸­åŒ…å«10å¼ å›¾ç‰‡ã€‚æ•°æ®é›†å¯é€šè¿‡Githubä¸‹è½½ï¼š [Github](https://github.com/towhee-io/examples/releases/download/data/reverse_image_search.zip). 

æ•°æ®é›†åŒ…å«å¦‚ä¸‹ä¸‰ä¸ªéƒ¨åˆ†ï¼š
- **train**: å€™é€‰å›¾ç‰‡ç›®å½•;
- **test**: æµ‹è¯•å›¾ç‰‡ç›®å½•;
- **reverse_image_search.csv**: csvæ–‡ä»¶ï¼Œæ¯å¼ å›¾ç‰‡åŒ…å«ï¼š ***id***, ***path***,  ***label*** ;

```python 
import os
import urllib.request
import zipfile
from pathlib import Path

def download_dataset():
    """ä¸‹è½½å¹¶è§£å‹æ•°æ®é›†"""
    
    # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = ['reverse_image_search.csv']
    required_dirs = ['train', 'test']
    
    all_exist = all(os.path.exists(f) for f in required_files) and all(os.path.exists(d) for d in required_dirs)
    
    if all_exist:
        print("âœ… æ•°æ®é›†å·²å­˜åœ¨")
        return True
    
    print("ğŸ“¥ å¼€å§‹ä¸‹è½½æ•°æ®é›†...")
    
    # å°è¯•å¤šä¸ªä¸‹è½½æº
    download_urls = [
        "https://github.com/towhee-io/examples/releases/download/data/reverse_image_search.zip",
    ]
    
    for i, url in enumerate(download_urls):
        try:
            print(f"å°è¯•ä»æº {i+1} ä¸‹è½½: {url}")
            
            # ä¸‹è½½æ–‡ä»¶
            urllib.request.urlretrieve(url, "reverse_image_search.zip")
            print("ä¸‹è½½å®Œæˆï¼Œæ­£åœ¨è§£å‹...")
            
            # è§£å‹æ–‡ä»¶
            with zipfile.ZipFile("reverse_image_search.zip", 'r') as zip_ref:
                zip_ref.extractall(".")
            
            # æ¸…ç†å‹ç¼©æ–‡ä»¶
            os.remove("reverse_image_search.zip")
            
            print("âœ… æ•°æ®é›†ä¸‹è½½å¹¶è§£å‹å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ ä»æº {i+1} ä¸‹è½½å¤±è´¥: {e}")
            if i < len(download_urls) - 1:
                print("å°è¯•ä¸‹ä¸€ä¸ªä¸‹è½½æº...")
            continue
    
    print("âŒ æ‰€æœ‰ä¸‹è½½æºéƒ½å¤±è´¥äº†")
    print("\nğŸ“‹ æ‰‹åŠ¨ä¸‹è½½è¯´æ˜:")
    print("1. è®¿é—®: https://github.com/towhee-io/examples/releases/download/data/reverse_image_search.zip")
    print("2. ä¸‹è½½ reverse_image_search.zip")
    print("3. è§£å‹åˆ°å½“å‰ç›®å½•")

    return False

# æ‰§è¡Œæ•°æ®é›†ä¸‹è½½
download_success = download_dataset()

if download_success:
    # æ£€æŸ¥æ•°æ®é›†å†…å®¹
    import pandas as pd
    
    try:
        df = pd.read_csv('reverse_image_search.csv')
        print(f"\nğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"- æ€»å›¾ç‰‡æ•°é‡: {len(df)}")
        print(f"- å›¾ç‰‡ç±»åˆ«æ•°: {df['label'].nunique()}")
        print(f"- æ•°æ®åˆ—: {list(df.columns)}")
        
        # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        print("\nğŸ“‹ æ•°æ®æ ·ä¾‹:")
        print(df.head())
        
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®é›†å¤±è´¥: {e}")
else:
    print("âš ï¸  è¯·æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†åå†ç»§ç»­")
```

```python 
 # è§£å‹æ–‡ä»¶
with zipfile.ZipFile("reverse_image_search.zip", 'r') as zip_ref:
    zip_ref.extractall(".")

# æ¸…ç†å‹ç¼©æ–‡ä»¶
# os.remove("reverse_image_search.zip")
```


### æ•°æ®é›†ç»“æ„è¯´æ˜

æˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®é›†åŒ…å«ä»¥ä¸‹ç»“æ„ï¼š

```
reverse_image_search/
â”œâ”€â”€ reverse_image_search.csv  # å›¾ç‰‡ç´¢å¼•æ–‡ä»¶
â”œâ”€â”€ train/                    # è®­ç»ƒå›¾ç‰‡ç›®å½•
â”‚   â”œâ”€â”€ class1/
â”‚   â”œâ”€â”€ class2/
â”‚   â””â”€â”€ ...
â””â”€â”€ test/                     # æµ‹è¯•å›¾ç‰‡ç›®å½•
    â”œâ”€â”€ class1/
    â”œâ”€â”€ class2/
    â””â”€â”€ ...
```

- **CSVæ–‡ä»¶**: åŒ…å«æ¯å¼ å›¾ç‰‡çš„IDã€è·¯å¾„å’Œæ ‡ç­¾ä¿¡æ¯
- **å›¾ç‰‡ç›®å½•**: æŒ‰ç±»åˆ«ç»„ç»‡çš„å›¾ç‰‡æ–‡ä»¶
- **æ€»è®¡**: çº¦1000å¼ å›¾ç‰‡ï¼Œ100ä¸ªç±»åˆ«ï¼Œæ¯ç±»10å¼ å›¾ç‰‡


```python 
# éªŒè¯æ•°æ®é›†å®Œæ•´æ€§
import pandas as pd
import os
from pathlib import Path

def validate_dataset():
    """éªŒè¯æ•°æ®é›†çš„å®Œæ•´æ€§"""
    
    if not os.path.exists('reverse_image_search.csv'):
        print("âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½æ•°æ®é›†")
        return False
    
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv('reverse_image_search.csv')
    print(f"ğŸ“Š CSVæ–‡ä»¶åŒ…å« {len(df)} æ¡è®°å½•")
    
    # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    missing_files = []
    existing_files = 0
    
    for idx, row in df.iterrows():
        if os.path.exists(row['path']):
            existing_files += 1
        else:
            missing_files.append(row['path'])
        
        # åªæ£€æŸ¥å‰100ä¸ªæ–‡ä»¶ä»¥èŠ‚çœæ—¶é—´
        if idx >= 100:
            break
    
    print(f"âœ… æ£€æŸ¥äº†å‰100ä¸ªæ–‡ä»¶ï¼Œ{existing_files}ä¸ªå­˜åœ¨")
    
    if missing_files:
        print(f"âš ï¸  å‘ç° {len(missing_files)} ä¸ªç¼ºå¤±æ–‡ä»¶")
        print("å‰å‡ ä¸ªç¼ºå¤±æ–‡ä»¶:", missing_files[:5])
    
    return len(missing_files) == 0

# æ‰§è¡ŒéªŒè¯
is_valid = validate_dataset()

if is_valid:
    print("\nâœ… æ•°æ®é›†éªŒè¯é€šè¿‡ï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥")
    
    # æ˜¾ç¤ºæ•°æ®æ ·ä¾‹
    df = pd.read_csv('reverse_image_search.csv')
    print("\nğŸ“‹ æ•°æ®é›†å‰5è¡Œ:")
    display(df.head())
    
    print(f"\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
    print(f"- æ€»è®°å½•æ•°: {len(df)}")
    print(f"- å”¯ä¸€æ ‡ç­¾æ•°: {df['label'].nunique()}")
    print(f"- æ ‡ç­¾åˆ†å¸ƒ:")
    print(df['label'].value_counts().head(10))
else:
    print("\nâŒ æ•°æ®é›†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®å®Œæ•´æ€§")
```

ä¸‹é¢çš„fuctionæ˜¯ä½œä¸ºtext-image searchçš„è¾…åŠ©
- **read_images(results)**: é€šè¿‡å›¾ç‰‡IDè¯»å…¥å›¾ç‰‡ï¼Œè¿”å›å›¾ç‰‡åˆ—è¡¨;


```python 
# å›¾åƒå¤„ç†è¾…åŠ©å‡½æ•°
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# åˆ›å»ºå›¾ç‰‡IDåˆ°è·¯å¾„çš„æ˜ å°„
if 'df' in locals():
    id_img = df.set_index('id')['path'].to_dict()
    print(f"âœ… åˆ›å»ºäº† {len(id_img)} ä¸ªå›¾ç‰‡çš„IDæ˜ å°„")
else:
    print("âŒ è¯·å…ˆè¿è¡Œæ•°æ®é›†éªŒè¯ä»£ç ")

def read_images_from_ids(image_ids):
    """æ ¹æ®å›¾ç‰‡IDåˆ—è¡¨è¯»å–å›¾ç‰‡"""
    images = []
    valid_paths = []
    
    for img_id in image_ids:
        if img_id in id_img:
            path = id_img[img_id]
            if os.path.exists(path):
                try:
                    # ä½¿ç”¨PILè¯»å–å›¾ç‰‡
                    img = Image.open(path).convert('RGB')
                    images.append(img)
                    valid_paths.append(path)
                except Exception as e:
                    print(f"âš ï¸  è¯»å–å›¾ç‰‡å¤±è´¥ {path}: {e}")
            else:
                print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        else:
            print(f"âš ï¸  å›¾ç‰‡IDä¸å­˜åœ¨: {img_id}")
    
    return images, valid_paths

def display_images(images, titles=None, max_images=5):
    """æ˜¾ç¤ºå›¾ç‰‡åˆ—è¡¨"""
    if not images:
        print("æ²¡æœ‰å›¾ç‰‡å¯æ˜¾ç¤º")
        return
    
    n_images = min(len(images), max_images)
    fig, axes = plt.subplots(1, n_images, figsize=(15, 3))
    
    if n_images == 1:
        axes = [axes]
    
    for i in range(n_images):
        axes[i].imshow(images[i])
        axes[i].axis('off')
        if titles and i < len(titles):
            axes[i].set_title(titles[i], fontsize=10)
    
    plt.tight_layout()
    plt.show()

# æµ‹è¯•å›¾ç‰‡è¯»å–åŠŸèƒ½
if 'df' in locals() and len(df) > 0:
    print("\nğŸ§ª æµ‹è¯•å›¾ç‰‡è¯»å–åŠŸèƒ½...")
    test_ids = df['id'].head(3).tolist()
    test_images, test_paths = read_images_from_ids(test_ids)
    
    if test_images:
        print(f"âœ… æˆåŠŸè¯»å– {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡")
        display_images(test_images, [f"ID: {test_ids[i]}" for i in range(len(test_images))])
    else:
        print("âŒ æµ‹è¯•å›¾ç‰‡è¯»å–å¤±è´¥")
```
### åˆ›å»ºMilvusé“¾æ¥

ä¸ºäº†é˜²æ­¢ç‰ˆæœ¬å†²çªæƒ…å†µï¼Œç¡®ä¿grpcioçš„ç‰ˆæœ¬é™åˆ¶åœ¨å¦‚ä¸‹çš„èŒƒå›´å†…ï¼Œä¸‹é¢è¿˜å¼•å…¥äº†Milvusï¼Œæ˜¯å› ä¸ºæºç ä¸­æ²¡æœ‰å¯åŠ¨Milvusï¼Œæ‰€ä»¥éœ€è¦æ‰‹åŠ¨å®‰è£…milvusç„¶åå¯åŠ¨milvusæœåŠ¡

```python
import subprocess
import sys

# å®‰è£… Milvus ç›¸å…³ä¾èµ–
try:
    print("æ­£åœ¨å®‰è£… Milvus ä¾èµ–...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "grpcio>=1.49.1,<=1.53.0", "pymilvus", "milvus"])
    print("Milvus ä¾èµ–å®‰è£…å®Œæˆ âœ“")
except Exception as e:
    print(f"å®‰è£…å¤±è´¥: {e}")
    print("å¦‚æœé‡åˆ°ç‰ˆæœ¬å†²çªï¼Œè¯·å…ˆå¸è½½ pymilvus: pip uninstall pymilvus -y")
    print("ç„¶åé‡æ–°å®‰è£…: pip install pymilvus")
```
å¦‚æœä½ å·²ç»å®‰è£…äº†pymilvuså¯¼è‡´äº†ç‰ˆæœ¬å†²çªé—®é¢˜ï¼Œè¯·è¿è¡Œå¦‚ä¸‹ä»£ç ï¼Œé‡æ–°å®‰è£…pymilvus

```shell
! pip uninstall pymilvus -y
```
ç°åœ¨åˆ›å»ºä¸€ä¸ª `text_image_search` çš„milvus collectionï¼Œä½¿ç”¨ [L2 distance metric](https://milvus.io/docs/metric.md#Euclidean-distance-L2) å’Œ [IVF_FLAT index](https://milvus.io/docs/index.md#IVF_FLAT)ç´¢å¼•.

```python
from milvus import default_server  
default_server.start()  
```

```python 
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility

def create_milvus_collection(collection_name, dim):
    connections.connect("default",host='localhost', port='19530')
    
    if utility.has_collection(collection_name):
        utility.drop_collection(collection_name)
    
    fields = [
    FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),
    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)
    ]
    schema = CollectionSchema(fields=fields, description='text image search')
    collection = Collection(name=collection_name, schema=schema)

    # ä¸ºé›†åˆåˆ›å»º IVF_FLAT ç´¢å¼•.
    index_params = {
        'metric_type':'L2',
        'index_type':"IVF_FLAT",
        'params':{"nlist":512}
    }
    collection.create_index(field_name="embedding", index_params=index_params)
    return collection

# collection = create_milvus_collection('text_image_search', 512)
```
## Text Image Search

ä½¿ç”¨ [Towhee](https://towhee.io/), å»ºç«‹ä¸€ä¸ªæ–‡æœ¬å›¾åƒæœç´¢å¼•æ“ã€‚

### ä½¿ç”¨CLIPæ¨¡å‹å¯¹æ–‡æœ¬å’Œå›¾ç‰‡è¿›è¡Œå‘é‡åŒ–

ä½¿ç”¨ [CLIP](https://openai.com/blog/clip/) æå–å›¾åƒæˆ–æ–‡æœ¬çš„ç‰¹å¾ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿé€šè¿‡è”åˆè®­ç»ƒå›¾åƒç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨æ¥æœ€å¤§åŒ–ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œä»è€Œç”Ÿæˆæ–‡æœ¬å’Œå›¾åƒçš„åµŒå…¥è¡¨ç¤ºã€‚

```shell
! pip install towhee
```


```python
from towhee import ops, pipe, DataCollection
import numpy as np
```

### ä»é­”æ­ç¤¾åŒºä¸‹è½½æ¨¡å‹
ä¸‹é¢çš„ä¸¤æ®µä»£ç æ˜¯ä»é­”æ­ç¤¾åŒºä¸‹è½½æ¨¡å‹ï¼Œå»ºè®®è‡ªå·±æ‰‹åŠ¨ä¸‹è½½clip-vit-base-patch16ï¼Œæ”¾åˆ°modelæ–‡ä»¶å¤¹ä¸‹


```python
import os
import subprocess
import sys

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
model_path = "./model"
if not os.path.exists(model_path) or not os.listdir(model_path):
    print("æ­£åœ¨ä¸‹è½½ CLIP æ¨¡å‹...")
    try:
        # å®‰è£… modelscope
        subprocess.check_call([sys.executable, "-m", "pip", "install", "modelscope"])
        
        # ä¸‹è½½æ¨¡å‹
        subprocess.check_call([
            "modelscope", "download", 
            "--model", "openai-mirror/clip-vit-base-patch16", 
            "--local_dir", model_path
        ])
        print("æ¨¡å‹ä¸‹è½½å®Œæˆ âœ“")
        
    except Exception as e:
        print(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        print("è¯·æ‰‹åŠ¨ä¸‹è½½ clip-vit-base-patch16 æ¨¡å‹åˆ° ./model æ–‡ä»¶å¤¹")
        print("æˆ–è€…ä½¿ç”¨ Hugging Face æ¨¡å‹: openai/clip-vit-base-patch16")
else:
    print("æ¨¡å‹å·²å­˜åœ¨ âœ“")
```

```shell
! pip install safetensors
```

```python 
from transformers import CLIPModel

# ç›´æ¥ä½¿ç”¨ safetensors åŠ è½½ï¼ˆä¸éœ€è¦ torch >= 2.6ï¼‰
model = CLIPModel.from_pretrained("./model", use_safetensors=True)

# ä¿å­˜ä¸ºæ–°çš„ safetensors æ¨¡å‹ç›®å½•
model.save_pretrained("./model-safetensors", safe_serialization=True)
```
```python
import numpy as np
import torch
from transformers import CLIPProcessor, CLIPModel
from towhee import register, ops, pipe  #
from towhee.operator import PyOperator
from pydantic import ConfigDict

@register
class CustomClipOperator(PyOperator):
    model_config = ConfigDict(protected_namespaces=())
    
    def __init__(self, model_path='./model'):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = CLIPModel.from_pretrained(model_path).to(self.device)
        self.processor = CLIPProcessor.from_pretrained(model_path)
        
    def __call__(self, img):
        inputs = self.processor(images=img, return_tensors="pt", padding=True)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        outputs = self.model.get_image_features(**inputs)
        return outputs.cpu().detach().numpy()[0]

p = (
    pipe.input('path')
    .map('path', 'img', ops.image_decode.cv2('rgb'))
    .map('img', 'vec', CustomClipOperator(model_path='./model'))
    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))
    .output('img', 'vec')
)
```


```python

# æ£€æŸ¥ PyTorch ç‰ˆæœ¬
import torch
print(torch.__version__)  # åº”è¯¥ >= 2.6.0

# æ£€æŸ¥æ¨¡å‹åŠ è½½
from transformers import CLIPModel
model = CLIPModel.from_pretrained('./model')
print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
```

```shell
! pip install torch>=2.6 --upgrade
```

```python
p2 = (
    pipe.input('text')
    .map('text', 'vec', ops.image_text_embedding.clip(model_name='model', modality='text'))
    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))
    .output('text', 'vec')
)

DataCollection(p2("A teddybear on a skateboard in Times Square.")).show()
```
ä¸‹é¢æ˜¯ä»£ç é‡Šæ„:

- `map('path', 'img', ops.image_decode.cv2_rgb('rgb'))`: å¯¹äºæ•°æ®çš„æ¯ä¸€è¡Œ, è¯»å–å¹¶ä¸”decode `path`ä¸‹çš„æ•°æ®ç„¶åæ”¾åˆ° `img`ä¸­;

- `map('img', 'vec', ops.image_text_embedding.clip(model_name='model', modality='image'/'text'))`ï¼šä½¿ç”¨ `ops.image_text_embedding.clip` æå–å›¾åƒæˆ–æ–‡æœ¬çš„åµŒå…¥ç‰¹å¾ï¼Œè¯¥æ“ä½œç¬¦æ¥è‡ª [Towhee hub](https://towhee.io/image-text-embedding/clip)ã€‚æ­¤æ“ä½œç¬¦æ”¯æŒå¤šç§æ¨¡å‹ï¼ŒåŒ…æ‹¬ `clip_vit_base_patch16`ã€`clip_vit_base_patch32`ã€`clip_vit_large_patch14`ã€`clip_vit_large_patch14_336` ç­‰ã€‚


### å°†å›¾ç‰‡å‘é‡æ•°æ®å¯¼å…¥Milvusä¸­

æˆ‘ä»¬é¦–å…ˆå°†å·²ç»ç”± `clip_vit_base_patch16` æ¨¡å‹å¤„ç†å¥½çš„å›¾ç‰‡å‘é‡åŒ–æ•°æ®æ’å…¥Milvusä¸­ç”¨äºåé¢çš„æ£€ç´¢ã€‚ Towhee æä¾›äº†[method-chaining style API](https://towhee.readthedocs.io/en/main/index.html) å› æ­¤ï¼Œç”¨æˆ·å¯ä»¥ä½¿ç”¨è¿™äº›æ“ä½œç¬¦ç»„è£…ä¸€ä¸ªæ•°æ®å¤„ç†ç®¡é“ã€‚è¿™æ„å‘³ç€ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚ï¼Œå°†ä¸åŒçš„æ“ä½œç¬¦ï¼ˆå¦‚å›¾åƒå’Œæ–‡æœ¬åµŒå…¥æå–æ“ä½œç¬¦ï¼‰ç»„åˆèµ·æ¥ï¼Œåˆ›å»ºå¤æ‚çš„æ•°æ®å¤„ç†æµç¨‹ï¼Œä»¥å®ç°ç‰¹å®šçš„åŠŸèƒ½æˆ–ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒæ£€ç´¢ã€æ–‡æœ¬åŒ¹é…æˆ–å…¶ä»–æ¶‰åŠå¤šæ¨¡æ€æ•°æ®å¤„ç†çš„åº”ç”¨åœºæ™¯ä¸­ï¼Œé€šè¿‡è¿™ç§æ–¹å¼å¯ä»¥çµæ´»åœ°æ„å»ºè§£å†³æ–¹æ¡ˆã€‚

```python
import numpy as np
import torch
from transformers import CLIPModel, CLIPProcessor
from towhee import pipe, ops, DataCollection, register
from towhee.operator import PyOperator
from pymilvus import connections, Collection, utility, FieldSchema, CollectionSchema, DataType
import time
import csv
import os

# ==============================
# Step 0: ç¡®ä¿ Milvus å·²è¿æ¥å¹¶åˆ›å»ºé›†åˆï¼ˆå…ˆè¿è¡Œä¸€æ¬¡ï¼‰
# ==============================


# # åˆ›å»ºé›†åˆ
collection = create_milvus_collection('text_image_search', 512)
# collection.load()  # åŠ è½½åˆ°å†…å­˜


# ==============================
# Step 1: è¯»å– CSV æ–‡ä»¶
# ==============================
def read_csv(csv_path, encoding='utf-8-sig'):
    with open(csv_path, 'r', encoding=encoding) as f:
        reader = csv.DictReader(f)
        for row in reader:
            yield int(row['id']), row['path']


# ==============================
# Step 2: è‡ªå®šä¹‰ CLIP ç¼–ç  Operator
# ==============================
@register(name='custom_clip_encoder')
class CustomClipOperator(PyOperator):
    def __init__(self, model_path='./model', device=0):
        self.device = "cuda" if device >= 0 and torch.cuda.is_available() else "cpu"
        print(f"Loading model on {self.device}...")
        self.model = CLIPModel.from_pretrained(model_path).to(self.device)
        self.processor = CLIPProcessor.from_pretrained(model_path)
        self.model.eval()

    def __call__(self, img_path: str):
        if not os.path.exists(img_path):
            raise FileNotFoundError(f"Image not found: {img_path}")

        import cv2
        img = cv2.imread(img_path)
        if img is None:
            raise ValueError("cv2 could not decode image")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        inputs = self.processor(images=img, return_tensors="pt", padding=True)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = self.model.get_image_features(**inputs)

        vec = outputs.cpu().numpy()[0]
        return vec / np.linalg.norm(vec)


# ==============================
# Step 3: æ„å»º Towhee Pipeline
# ==============================
p3 = (
    pipe.input('csv_file')  # è¾“å…¥å­—æ®µå
         .flat_map('csv_file', ('id', 'path'), read_csv)
         .map('path', 'vec', CustomClipOperator(model_path='./model', device=0))
         .output('id', 'vec')  # è¾“å‡º id å’Œå‘é‡
)

# ==============================
# Step 4: æ‰§è¡Œç®¡é“å¹¶æ’å…¥ Milvus
# ==============================
start = time.time()
success_count = 0

try:
    # ä½¿ç”¨ DataCollection æ¥å¤„ç†ç®¡é“ç»“æœ
    dc = DataCollection(p3('./reverse_image_search.csv'))
    
    batch_ids = []
    batch_vecs = []

    for result in dc:
        if result is None:
            continue
        id_val = result['id']
        vec = result['vec']

        batch_ids.append(id_val)
        batch_vecs.append(vec)

        # æ‰¹é‡æ’å…¥ï¼ˆæå‡æ€§èƒ½ï¼‰
        if len(batch_ids) >= 100:  # æ¯ 100 æ¡æ’å…¥ä¸€æ¬¡
            collection.insert([batch_ids, batch_vecs])
            success_count += len(batch_ids)
            print(f"Inserted batch of {len(batch_ids)} records.")
            batch_ids, batch_vecs = [], []

    # æ’å…¥å‰©ä½™æ•°æ®
    if batch_ids:
        collection.insert([batch_ids, batch_vecs])
        success_count += len(batch_ids)
        print(f"Inserted final batch of {len(batch_ids)} records.")
        

except Exception as e:
    print("Pipeline execution error:", str(e))
    import traceback
    traceback.print_exc()
# ==============================
# Step 5: ç»Ÿè®¡ç»“æœ
# ==============================
print(f"æ’å…¥å®Œæˆ! æˆåŠŸ: {success_count} æ¡è®°å½•")
print(f"è€—æ—¶: {time.time() - start:.2f} ç§’")
print(f"é›†åˆä¸­çš„å®ä½“æ•°é‡: {collection.num_entities}")
```

```python
collection.flush()

collection.load()

print('Total number of inserted data is {}.'.format(collection.num_entities))
```

### å¼€å§‹å‘é‡åŒ–æ£€ç´¢

ç°åœ¨ï¼Œå€™é€‰å›¾åƒçš„åµŒå…¥å‘é‡å·²ç»æ’å…¥åˆ° Milvus ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹å…¶è¿›è¡Œæœ€è¿‘é‚»æŸ¥è¯¢ã€‚åŒæ ·ï¼Œæˆ‘ä»¬ä½¿ç”¨ Towhee æ¥åŠ è½½è¾“å…¥æ–‡æœ¬ã€è®¡ç®—åµŒå…¥å‘é‡ï¼Œå¹¶å°†è¯¥å‘é‡ä½œä¸º Milvus çš„æŸ¥è¯¢æ¡ä»¶ã€‚ç”±äº Milvus ä»…è¿”å›å›¾åƒ ID å’Œè·ç¦»å€¼ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ª `read_images` å‡½æ•°ï¼Œæ ¹æ® ID è·å–åŸå§‹å›¾åƒå¹¶è¿›è¡Œå±•ç¤ºã€‚

```python
import pandas as pd
import cv2

def read_image(image_ids):
    df = pd.read_csv('reverse_image_search.csv')
    id_img = df.set_index('id')['path'].to_dict()
    imgs = []
    decode = ops.image_decode.cv2('rgb')
    for image_id in image_ids:
        path = id_img[image_id]
        imgs.append(decode(path))
    return imgs


p4 = (
    pipe.input('text')
    .map('text', 'vec', ops.image_text_embedding.clip(model_name='model', modality='text'))
    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))
    .map('vec', 'result', ops.ann_search.milvus_client(host='127.0.0.1', port='19530', collection_name='text_image_search', limit=5))
    .map('result', 'image_ids', lambda x: [item[0] for item in x])
    .map('image_ids', 'images', read_image)
    .output('text', 'images')
)

DataCollection(p4("A white dog")).show()
DataCollection(p4("A black dog")).show()
```
## ä½¿ç”¨Gradioæ„å»ºä¸€ä¸ªåº”ç”¨
```python
search_pipeline = (
    pipe.input('text')
    .map('text', 'vec', ops.image_text_embedding.clip(model_name='model', modality='text'))
    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))
    .map('vec', 'result', ops.ann_search.milvus_client(host='127.0.0.1', port='19530', collection_name='text_image_search', limit=5))
    .map('result', 'image_ids', lambda x: [item[0] for item in x])
    .output('image_ids')
)

def search(text):
    df = pd.read_csv('reverse_image_search.csv')
    id_img = df.set_index('id')['path'].to_dict()
    imgs = []
    image_ids = search_pipeline(text).to_list()[0][0]
    return [id_img[image_id] for image_id in image_ids]

```

åœ¨é«˜ç‰ˆæœ¬çš„gradioä¸­ï¼Œå·²ç»ä¸æ”¯æŒgradio.inputs.xxxå’Œgradio.outputs.xxxï¼Œå¯ç›´æ¥ä½¿ç”¨gradio.TextBoxæˆ–è€…gradio.Image
ä½ å¯ä»¥ä½¿ç”¨å¦‚ä¸‹ä»£ç æ›´æ–°ä¸€ä¸‹ä½ çš„gradio

```shell
! pip install --upgrade gradio
```

```python
import gradio

interface = gradio.Interface(search, 
                             gradio.Textbox(lines=1),
                             [gradio.Image(type="filepath", label=None) for _ in range(5)]
                            )
# è®°å¾—æœç´¢çš„æ—¶å€™ç”¨è‹±æ–‡ï¼æ¯”å¦‚æˆ‘è¦æœç´¢è“è‰²çš„å¤©ç©ºï¼Œé‚£æˆ‘å°±è¾“å…¥blue sky
interface.launch(inline=True, share=True)
```



