Chapter 4 Milvusçš„AIåº”ç”¨å¼€å‘ï¼šåŸºäºBM25çš„æ··åˆæœç´¢å‘é‡æ•°æ®åº“å¼€å‘å®æˆ˜
æœ¬ç« èŠ‚å°†å¸¦å¤§å®¶ä¸€æ­¥ä¸€æ­¥çš„å®Œæˆæ”¿åŠ¡é—®ç­”é¢†åŸŸçš„å‘é‡+BM25æ··åˆæœç´¢çš„demoï¼Œæ•°æ®é›†å·²ç»å¤„ç†å¥½å¹¶ä¸”å‘é‡åŒ–å®Œæˆã€‚

Milvusç‰ˆæœ¬ï¼š2.5.4
pythonç‰ˆæœ¬ï¼š3.12.0

4.1 å­¦ä¹ ç›®æ ‡
ç†è§£å•å‘é‡æ£€ç´¢å’ŒBM25å…¨æ–‡æ£€ç´¢çš„ä¼˜ç¼ºç‚¹

ç†è§£æ··åˆæ£€ç´¢çš„å®é™…æ„ä¹‰ä¸ä¼˜åŠ¿

è·‘é€šæ‰€æœ‰ä»£ç 

4.2 æ€»ä½“æµç¨‹
åˆ›å»ºç¯å¢ƒ

åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Œä¸‹è½½ç›¸å…³ä¾èµ–ï¼Œç¡®è®¤milvusç‰ˆæœ¬ï¼Œå¯åŠ¨milvusï¼Œæ„å»ºSchemaä¸Collection

å¯¼å…¥æ•°æ®

ä¸‹è½½æ•°æ®é›†ï¼Œè¿è¡Œä»£ç å¯¼å…¥æ•°æ®

æ‰§è¡Œæ£€ç´¢

æ‰§è¡Œå•å‘é‡æ£€ç´¢ï¼ŒBM25å…¨æ–‡æ£€ç´¢ï¼Œæ··åˆæ£€ç´¢

è§‚å¯Ÿæ‰§è¡Œç»“æœ

æ€»ç»“

4.3 åˆ›å»ºç¯å¢ƒ
é¦–å…ˆåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Œä¸‹è½½ä¾èµ–

python -m venv venv
. venv/bin/activate
â€‹
# å¦‚æœè¦é€€å‡ºè™šæ‹Ÿç¯å¢ƒ
# deactivate
â€‹
pip install -r requirement.txt
requirement.txtå†…å®¹å¦‚ä¸‹ï¼š

numpy==1.24.3
pandas==2.0.3
torch==2.0.1
pymilvus==2.5.4
modelscope==1.9.5
transformers==4.30.2
sentencepiece==0.1.99
openpyxl==3.1.2
setuptools==68.0.0
wheel==0.40.0
æœ¬æ¬¡ä½¿ç”¨çš„Milvusç‰ˆæœ¬ä¸º2.5.xï¼Œé¦–å…ˆå¯åŠ¨Milvusï¼ˆdockeréƒ¨ç½²ï¼‰ä»¥åŠAttuï¼ˆç”¨äºæŸ¥çœ‹æ•°æ®ï¼‰ã€‚ç­‰å¾…å…¨éƒ¨å‡†å¤‡å®Œæˆåï¼Œè¿è¡Œä»¥ä¸‹ä»£ç ï¼Œæ„å»ºSchemaä¸Collection

â€‹
ç‚¹å‡»å±•å¼€Pythonä»£ç 
â€‹
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Milvusé›†åˆSchemaè®¾è®¡å’Œåˆ›å»ºè„šæœ¬
æ”¯æŒå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢å’ŒBM25å…¨æ–‡æ£€ç´¢çš„æ··åˆæœç´¢
"""
â€‹
import json
from typing import Optional
from pymilvus import (
    MilvusClient,
    DataType,
    Function,
    FunctionType,
    connections,
    utility
)
â€‹
class MilvusSchemaDesigner:
    def __init__(self, uri: str = "http://127.0.0.1:19530", token: str = "root:Milvus"):
        """
        åˆå§‹åŒ–Milvusè¿æ¥
â€‹
        Args:
            uri: MilvusæœåŠ¡å™¨URI
            token: è®¤è¯token
        """
        self.uri = uri
        self.token = token
        self.client = None
        self.collection_name = "hybrid_search_collection"
â€‹
    def connect(self):
        """è¿æ¥åˆ°MilvusæœåŠ¡å™¨"""
        try:
            print(f"æ­£åœ¨è¿æ¥MilvusæœåŠ¡å™¨: {self.uri}")
            self.client = MilvusClient(
                uri=self.uri,
                token=self.token
            )
â€‹
            
            print("âœ“ Milvusè¿æ¥æˆåŠŸ")
            return True
â€‹
        except Exception as e:
            print(f"âœ— Milvusè¿æ¥å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿:")
            print("1. MilvusæœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")
            print("2. URIå’Œtokené…ç½®æ­£ç¡®")
            print("3. ç½‘ç»œè¿æ¥æ­£å¸¸")
            return False
â€‹
    def check_collection_exists(self) -> bool:
        """æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨"""
        try:
            if utility.has_collection(self.collection_name):
                print(f"é›†åˆ '{self.collection_name}' å·²å­˜åœ¨")
                return True
            else:
                print(f"é›†åˆ '{self.collection_name}' ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°é›†åˆ")
                return False
        except Exception as e:
            print(f"æ£€æŸ¥é›†åˆæ—¶å‡ºé”™: {e}")
            return False
â€‹
    def drop_existing_collection(self):
        """åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ"""
        try:
            if self.check_collection_exists():
                print(f"æ­£åœ¨åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ: {self.collection_name}")
                self.client.drop_collection(collection_name=self.collection_name)
                print(f"âœ“ é›†åˆ '{self.collection_name}' å·²åˆ é™¤")
        except Exception as e:
            print(f"åˆ é™¤é›†åˆæ—¶å‡ºé”™: {e}")
â€‹
    def create_hybrid_search_schema(self, vector_dimension: int = 768):
        """
        åˆ›å»ºæ”¯æŒæ··åˆæœç´¢çš„Schema
â€‹
        Args:
            vector_dimension: å‘é‡ç»´åº¦
        """
â€‹
        print(f"å‘é‡ç»´åº¦: {vector_dimension}")
â€‹
        # åˆ›å»ºSchema    
        schema = self.client.create_schema(
            auto_id=False,  # æˆ‘ä»¬è‡ªå·±ç®¡ç†ID
            enable_dynamic_field=True  # å…è®¸åŠ¨æ€å­—æ®µ
        )
â€‹
        # 2.1 æ·»åŠ åŸºç¡€å­—æ®µ
        schema.add_field(field_name="id", datatype=DataType.VARCHAR, max_length=100, is_primary=True)
        schema.add_field(field_name="embedding", datatype=DataType.FLOAT_VECTOR, dim=1024) 
â€‹
        schema.add_field(
            field_name="title", 
            datatype=DataType.VARCHAR, 
            max_length=512, 
            enable_analyzer=True, 
            analyzer_params={"tokenizer": "jieba"} 
        )
â€‹
        schema.add_field(
            field_name="content", 
            datatype=DataType.VARCHAR, 
            max_length=65535, 
            enable_analyzer=True, 
            analyzer_params={"tokenizer": "jieba"}
        )
â€‹
        # 2.3 æ·»åŠ ç¨€ç–å‘é‡å­—æ®µ (ç”¨äºå­˜å‚¨ BM25 ç»“æœ)
        schema.add_field(field_name="title_sparse", datatype=DataType.SPARSE_FLOAT_VECTOR)
        schema.add_field(field_name="content_sparse", datatype=DataType.SPARSE_FLOAT_VECTOR)
â€‹
        # 3. å®šä¹‰ BM25 å‡½æ•° (Function)
        # ä½œç”¨ï¼šå‘Šè¯‰ Milvus è‡ªåŠ¨æŠŠ title/content çš„æ–‡æœ¬è½¬æˆç¨€ç–å‘é‡
        title_bm25_func = Function(
            name="title_bm25_func",
            input_field_names=["title"],
            output_field_names=["title_sparse"],
            function_type=FunctionType.BM25
        )
â€‹
        content_bm25_func = Function(
            name="content_bm25_func",
            input_field_names=["content"],
            output_field_names=["content_sparse"],
            function_type=FunctionType.BM25
        )
        # æ·»åŠ BM25å‡½æ•°åˆ°Schema
        schema.add_function(title_bm25_func)
        schema.add_function(content_bm25_func)
â€‹
        return schema
â€‹
    def create_collection_with_indexes(self, schema, vector_dimension: int = 768):
        """
        åˆ›å»ºé›†åˆå¹¶é…ç½®ç´¢å¼•
â€‹
        Args:
            schema: é›†åˆSchema
            vector_dimension: å‘é‡ç»´åº¦
        """
        print(f"\nåˆ›å»ºé›†åˆå¹¶é…ç½®ç´¢å¼•...")
â€‹
        # åˆ›å»ºé›†åˆ
        collection = self.client.create_collection(
            collection_name=self.collection_name,
            schema=schema
        )
â€‹
        print(f"âœ“ é›†åˆ '{self.collection_name}' åˆ›å»ºæˆåŠŸ")
â€‹
        # å‡†å¤‡ç´¢å¼•å‚æ•°
        index_params = self.client.prepare_index_params()
â€‹
        # æ·»åŠ å‘é‡ç´¢å¼•ï¼ˆä½¿ç”¨IVF_FLATï¼‰
        index_params.add_index(
            field_name="embedding",
            index_type="FLAT",
            metric_type="IP",  # Inner Product (ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦)
            params={}
        )
â€‹
        # TODO:è¿™é‡Œæœ‰paramså‚æ•°ï¼Œè°ƒç ”ä¸åŒå‚æ•°å€¼ä¸‹çš„æ•ˆæœ
    #     params={
    #     "inverted_index_algo": "DAAT_MAXSCORE",
    #     "bm25_k1": 1.2,
    #     "bm25_b": 0.75
    #     }
        # ä¸º content_sparse åˆ›å»ºå€’æ’ç´¢å¼•
        index_params.add_index(
            field_name="title_sparse",
            index_type="SPARSE_INVERTED_INDEX",
            metric_type="BM25",
            index_name="title_sparse_index"
        )
â€‹
        index_params.add_index(
            field_name="content_sparse",
            index_type="SPARSE_INVERTED_INDEX",
            metric_type="BM25",
            index_name="content_sparse_index"
        )
â€‹
        # åˆ›å»ºç´¢å¼•
        self.client.create_index(
            collection_name=self.collection_name,
            index_params=index_params
        )
â€‹
        return collection
â€‹
    def load_collection(self):
        """åŠ è½½é›†åˆåˆ°å†…å­˜"""
        try:
            print(f"\nåŠ è½½é›†åˆåˆ°å†…å­˜...")
            self.client.load_collection(collection_name=self.collection_name)
            print(f"âœ“ é›†åˆ '{self.collection_name}' å·²åŠ è½½åˆ°å†…å­˜")
        except Exception as e:
            print(f"âœ— åŠ è½½é›†åˆå¤±è´¥: {e}")
â€‹
    
â€‹
    def create_collection(self, vector_dimension: int = 768, drop_existing: bool = False):
        """
        å®Œæ•´çš„é›†åˆåˆ›å»ºæµç¨‹
â€‹
        Args:
            vector_dimension: å‘é‡ç»´åº¦
            drop_existing: æ˜¯å¦åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ
        """
        print("=" * 60)
        print("Milvusæ··åˆæœç´¢é›†åˆåˆ›å»ºå‘å¯¼")
        print("=" * 60)
â€‹
        # è¿æ¥Milvus
        if not self.connect():
            return False
â€‹
        # æ£€æŸ¥å¹¶å¤„ç†å·²å­˜åœ¨çš„é›†åˆ
        if self.check_collection_exists():
            if drop_existing:
                self.drop_existing_collection()
            else:
                print("é›†åˆå·²å­˜åœ¨ï¼Œä½¿ç”¨drop_existing=Trueæ¥åˆ é™¤å¹¶é‡å»º")
                return False
â€‹
        # åˆ›å»ºSchema
        schema = self.create_hybrid_search_schema(vector_dimension)
â€‹
        # åˆ›å»ºé›†åˆå¹¶é…ç½®ç´¢å¼•
        collection = self.create_collection_with_indexes(schema, vector_dimension)
â€‹
        # åŠ è½½é›†åˆ
        self.load_collection()
        return True
â€‹
def main():
    # ä»é…ç½®æ–‡ä»¶è¯»å–å‘é‡ç»´åº¦
    vector_dimension = 1024
â€‹
    # åˆ›å»ºSchemaè®¾è®¡å™¨
    schema_designer = MilvusSchemaDesigner()
â€‹
    try:
        # åˆ›å»ºé›†åˆ
        success = schema_designer.create_collection(
            vector_dimension=vector_dimension,
            drop_existing=True  # åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ
        )
â€‹
        if success:
            print("\nğŸ‰ Milvusé›†åˆè®¾ç½®å®Œæˆï¼")
        else:
            print("\nâŒ Milvusé›†åˆè®¾ç½®å¤±è´¥ï¼")
â€‹
    except Exception as e:
        print(f"\né›†åˆåˆ›å»ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
â€‹
if __name__ == "__main__":
    import os
    main()
4.4 å¯¼å…¥æ•°æ®
é¦–å…ˆä¸‹è½½æ•°æ®é›†ï¼šhttps://haluki.oss-cn-hangzhou.aliyuncs.com/code.zip

è§£å‹æ–‡ä»¶åå¯ä»¥çœ‹åˆ°ä¸‰ä¸ªjsonæ–‡ä»¶ï¼š

vector_texts.json ç”¨äºå‘é‡åŒ–çš„åŸå§‹æ–‡æœ¬

{
    "id": "doc_1_6b57413d",
    "vector_text": "ä½ çš„æµè§ˆå™¨ä¸æ”¯æŒvideoæ–°åç½‘ä¸Šæµ·8æœˆ\n\nä½ çš„æµè§ˆå™¨ä¸æ”¯æŒvideoæ–°åç½‘ä¸Šæµ·8æœˆ27æ—¥ç”µï¼ˆæœ‰ä¹‹ç‚˜ä½˜çµï¼‰24æ—¥ï¼Œ......"
},
vectors.json å‘é‡åŒ–åçš„æ–‡æœ¬ï¼Œæ ¹æ®idä¸åŸå§‹çš„æ–‡æœ¬å¯¹åº”

{
    "id" : "doc_10000_8efdf098",
    "embedding" : [ 0.0038397987, 0.015784778, 0.01619642, -0.076500155, -0.033315383, -0.045836534, -0.012616322, ...... ],
    "vector_norm" : 0.9999999875290796
},
quest.json åŒäºæœç´¢çš„é—®é¢˜é›†åˆ

{
    "title": "æ ¹æ®å›½åŠ¡é™¢å¸¸åŠ¡ä¼šè®®æ–°é—»ç¨¿å†…å®¹ç”Ÿæˆçš„100æ¡ç›¸å…³é—®é¢˜",
    "sections": [
        {
        "section_title": "å…³äºå…¨å›½ç»Ÿä¸€å¤§å¸‚åœºå»ºè®¾",
        "questions_count": 35,
        "questions": [
            "å»ºè®¾å…¨å›½ç»Ÿä¸€å¤§å¸‚åœºçš„æ ¸å¿ƒç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å¸‚åœºåˆ†å‰²å’Œåœ°æ–¹ä¿æŠ¤æœ‰å“ªäº›å…¸å‹è¡¨ç°å½¢å¼ï¼Ÿ"
            ...
        ]
        },
}
æ•°æ®å¯¼å…¥ä»£ç ç”¨äºå°†é¢„å¤„ç†å¥½çš„æ”¿åŠ¡é—®ç­”æ•°æ®æ‰¹é‡æ’å…¥åˆ°Milvusé›†åˆä¸­ã€‚ä»¥ä¸‹æ˜¯æ•°æ®å¯¼å…¥çš„Pythonå®ç°ï¼š

â€‹
ç‚¹å‡»å±•å¼€Pythonä»£ç 
â€‹
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ‰¹é‡å¯¼å…¥åˆ°Milvusçš„è„šæœ¬
å°†å¤„ç†åçš„æ–‡æœ¬æ•°æ®å’Œå‘é‡æ•°æ®å¯¼å…¥Milvusé›†åˆ
"""
â€‹
import json
import os
import time
from typing import List, Dict, Any, Tuple
from pymilvus import MilvusClient
â€‹
class DataImporter:
    def __init__(self, uri: str = "http://localhost:19530", token: str = "root:Milvus"):
        """
        åˆå§‹åŒ–æ•°æ®å¯¼å…¥å™¨
â€‹
        Args:
            uri: MilvusæœåŠ¡å™¨URI
            token: è®¤è¯token
        """
        self.uri = uri
        self.token = token
        self.client = None
        self.collection_name = "hybrid_search_collection"
â€‹
    def connect(self) -> bool:
        """è¿æ¥åˆ°MilvusæœåŠ¡å™¨"""
        try:
            print(f"æ­£åœ¨è¿æ¥MilvusæœåŠ¡å™¨: {self.uri}")
            self.client = MilvusClient(
                uri=self.uri,
                token=self.token
            )
            print("âœ“ Milvusè¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âœ— Milvusè¿æ¥å¤±è´¥: {e}")
            return False
â€‹
    def check_collection_exists(self) -> bool:
        """æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨"""
        try:
            if self.client.has_collection(collection_name=self.collection_name):
                print(f"âœ“ æ‰¾åˆ°é›†åˆ: {self.collection_name}")
                return True
            else:
                print(f"âœ— é›†åˆä¸å­˜åœ¨: {self.collection_name}")
                print("è¯·å…ˆè¿è¡Œ milvus_setup.py åˆ›å»ºé›†åˆ")
                return False
        except Exception as e:
            print(f"æ£€æŸ¥é›†åˆæ—¶å‡ºé”™: {e}")
            return False
â€‹
    def load_data_files(self, processed_data_path: str, vectors_path: str) -> Tuple[List[Dict], List[Dict]]:
        """
        åŠ è½½æ•°æ®æ–‡ä»¶
â€‹
        Args:
            processed_data_path: å¤„ç†åçš„æ–‡æœ¬æ•°æ®æ–‡ä»¶è·¯å¾„
            vectors_path: å‘é‡æ•°æ®æ–‡ä»¶è·¯å¾„
â€‹
        Returns:
            (æ–‡æœ¬æ•°æ®, å‘é‡æ•°æ®)
        """
        print(f"\nåŠ è½½æ•°æ®æ–‡ä»¶...")
â€‹
        # åŠ è½½å¤„ç†åçš„æ–‡æœ¬æ•°æ®
        try:
            with open(processed_data_path, 'r', encoding='utf-8') as f:
                processed_data = json.load(f)
            print(f"âœ“ å·²åŠ è½½æ–‡æœ¬æ•°æ®: {len(processed_data)} æ¡è®°å½•")
        except Exception as e:
            raise Exception(f"åŠ è½½æ–‡æœ¬æ•°æ®å¤±è´¥: {e}")
â€‹
        # åŠ è½½å‘é‡æ•°æ®
        try:
            with open(vectors_path, 'r', encoding='utf-8') as f:
                vectors_data = json.load(f)
            print(f"âœ“ å·²åŠ è½½å‘é‡æ•°æ®: {len(vectors_data)} æ¡è®°å½•")
        except Exception as e:
            raise Exception(f"åŠ è½½å‘é‡æ•°æ®å¤±è´¥: {e}")
â€‹
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        if len(processed_data) != len(vectors_data):
            raise Exception(
                f"æ•°æ®ä¸ä¸€è‡´: æ–‡æœ¬æ•°æ® {len(processed_data)} æ¡, "
                f"å‘é‡æ•°æ® {len(vectors_data)} æ¡"
            )
â€‹
        return processed_data, vectors_data
â€‹
    def merge_data(self, processed_data: List[Dict], vectors_data: List[Dict]) -> List[Dict]:
        """
        åˆå¹¶æ–‡æœ¬æ•°æ®å’Œå‘é‡æ•°æ®
â€‹
        Args:
            processed_data: å¤„ç†åçš„æ–‡æœ¬æ•°æ®
            vectors_data: å‘é‡æ•°æ®
â€‹
        Returns:
            åˆå¹¶åçš„æ•°æ®
        """
        print(f"\nåˆå¹¶æ•°æ®...")
â€‹
        # åˆ›å»ºIDåˆ°å‘é‡çš„æ˜ å°„
        vector_map = {}
        for item in vectors_data:
            if 'id' in item and 'embedding' in item:
                vector_map[item['id']] = item['embedding']
â€‹
        merged_data = []
        missing_vectors = []
â€‹
        for text_item in processed_data:
            doc_id = text_item['id']
â€‹
            if doc_id in vector_map:
                merged_item = {
                    'id': doc_id,
                    'title': text_item.get('title', ''),
                    'content': text_item.get('content', ''),
                    'embedding': vector_map[doc_id]
                }
                merged_data.append(merged_item)
            else:
                missing_vectors.append(doc_id)
â€‹
        if missing_vectors:
            print(f"âš  è­¦å‘Š: {len(missing_vectors)} æ¡è®°å½•ç¼ºå°‘å‘é‡æ•°æ®")
            print(f"ç¤ºä¾‹ç¼ºå¤±ID: {missing_vectors[:3]}")
â€‹
        print(f"âœ“ æˆåŠŸåˆå¹¶ {len(merged_data)} æ¡è®°å½•")
        return merged_data
â€‹
    def validate_data(self, data: List[Dict]) -> bool:
        """
        éªŒè¯æ•°æ®æ ¼å¼
â€‹
        Args:
            data: å¾…éªŒè¯çš„æ•°æ®
â€‹
        Returns:
            éªŒè¯ç»“æœ
        """
        print(f"\néªŒè¯æ•°æ®æ ¼å¼...")
â€‹
        if not data:
            print("âœ— æ•°æ®ä¸ºç©º")
            return False
â€‹
        required_fields = ['id', 'title', 'content', 'embedding']
        errors = []
â€‹
        for i, item in enumerate(data[:5]):  # åªæ£€æŸ¥å‰5æ¡
            for field in required_fields:
                if field not in item:
                    errors.append(f"è®°å½• {i+1}: ç¼ºå°‘å­—æ®µ '{field}'")
â€‹
            # æ£€æŸ¥å‘é‡æ ¼å¼
            if 'embedding' in item:
                embedding = item['embedding']
                if not isinstance(embedding, list) or len(embedding) == 0:
                    errors.append(f"è®°å½• {i+1}: å‘é‡æ ¼å¼é”™è¯¯")
â€‹
        if errors:
            print("âœ— æ•°æ®éªŒè¯å¤±è´¥:")
            for error in errors:
                print(f"  - {error}")
            return False
        else:
            print(f"âœ“ æ•°æ®éªŒè¯é€šè¿‡ ({len(data)} æ¡è®°å½•)")
            return True
â€‹
    def batch_import(self, data: List[Dict], batch_size: int = 100) -> bool:
        """
        æ‰¹é‡å¯¼å…¥æ•°æ®
â€‹
        Args:
            data: å¾…å¯¼å…¥çš„æ•°æ®
            batch_size: æ‰¹å¤„ç†å¤§å°
â€‹
        Returns:
            å¯¼å…¥ç»“æœ
        """
        print(f"\nå¼€å§‹æ‰¹é‡å¯¼å…¥æ•°æ®...")
        print(f"æ€»è®°å½•æ•°: {len(data)}")
        print(f"æ‰¹å¤„ç†å¤§å°: {batch_size}")
        print(f"æ€»æ‰¹æ¬¡æ•°: {(len(data) + batch_size - 1) // batch_size}")
â€‹
        successful_imports = 0
        failed_batches = []
â€‹
        start_time = time.time()
â€‹
        for i in range(0, len(data), batch_size):
            batch_data = data[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(data) + batch_size - 1) // batch_size
â€‹
            print(f"\nå¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch_data)} æ¡è®°å½•)")
â€‹
            try:
                # å‡†å¤‡æ‰¹å¤„ç†æ•°æ® - ä½¿ç”¨å­—å…¸åˆ—è¡¨æ ¼å¼
                batch_insert_data = []
â€‹
                for item in batch_data:
                    batch_insert_data.append({
                        'id': item['id'],
                        'title': item['title'],
                        'content': item['content'],
                        'embedding': item['embedding']
                    })
â€‹
                # æ’å…¥æ•°æ® - ä½¿ç”¨æ¨èçš„æ ¼å¼
                insert_result = self.client.insert(
                    collection_name=self.collection_name,
                    data=batch_insert_data
                )
â€‹
                successful_imports += len(batch_data)
                print(f"âœ“ æ‰¹æ¬¡ {batch_num} å¯¼å…¥æˆåŠŸ")
â€‹
                # æ˜¾ç¤ºè¿›åº¦
                progress = (i + len(batch_data)) / len(data) * 100
                print(f"è¿›åº¦: {progress:.1f}% ({i + len(batch_data)}/{len(data)})")
â€‹
            except Exception as e:
                print(f"âœ— æ‰¹æ¬¡ {batch_num} å¯¼å…¥å¤±è´¥: {e}")
                failed_batches.append((batch_num, str(e)))
â€‹
                # è®°å½•å¤±è´¥çš„æ•°æ®
                print(f"å¤±è´¥æ‰¹æ¬¡æ•°æ®ç¤ºä¾‹:")
                for j, item in enumerate(batch_data[:2]):
                    print(f"  {j+1}. ID: {item.get('id', 'N/A')}, æ ‡é¢˜: {item.get('title', 'N/A')[:30]}...")
â€‹
        total_time = time.time() - start_time
â€‹
        # å¯¼å…¥ç»“æœç»Ÿè®¡
        print(f"\n" + "=" * 60)
        print("æ‰¹é‡å¯¼å…¥å®Œæˆï¼")
        print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"æˆåŠŸå¯¼å…¥: {successful_imports} æ¡è®°å½•")
        print(f"å¤±è´¥æ‰¹æ¬¡: {len(failed_batches)} ä¸ª")
        print(f"å¹³å‡é€Ÿåº¦: {successful_imports/total_time:.1f} è®°å½•/ç§’")
â€‹
        if failed_batches:
            print(f"\nå¤±è´¥æ‰¹æ¬¡è¯¦æƒ…:")
            for batch_num, error in failed_batches:
                print(f"  æ‰¹æ¬¡ {batch_num}: {error}")
â€‹
        # åˆ·æ–°æ•°æ®åˆ°ç£ç›˜
        try:
            print(f"\nåˆ·æ–°æ•°æ®åˆ°ç£ç›˜...")
            self.client.flush(collection_name=self.collection_name)
            print("âœ“ æ•°æ®åˆ·æ–°å®Œæˆ")
        except Exception as e:
            print(f"âš  æ•°æ®åˆ·æ–°å¤±è´¥: {e}")
â€‹
        return len(failed_batches) == 0
â€‹
    def get_collection_stats(self):
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯"""
        try:
            print(f"\né›†åˆç»Ÿè®¡ä¿¡æ¯:")
            print("-" * 40)
â€‹
            stats = self.client.get_collection_stats(collection_name=self.collection_name)
            print(f"æ€»è®°å½•æ•°: {stats.get('row_count', 'N/A')}")
â€‹
            # æ˜¾ç¤ºå­—æ®µç»Ÿè®¡
            if 'entities' in stats:
                for field_name, field_stats in stats['entities'].items():
                    print(f"{field_name}: {field_stats}")
â€‹
        except Exception as e:
            print(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
â€‹
    def import_data(self, processed_data_path: str, vectors_path: str, batch_size: int = 100):
        """
        å®Œæ•´çš„æ•°æ®å¯¼å…¥æµç¨‹
â€‹
        Args:
            processed_data_path: å¤„ç†åçš„æ–‡æœ¬æ•°æ®æ–‡ä»¶è·¯å¾„
            vectors_path: å‘é‡æ•°æ®æ–‡ä»¶è·¯å¾„
            batch_size: æ‰¹å¤„ç†å¤§å°
        """
        print("=" * 60)
        print("Milvusæ•°æ®å¯¼å…¥å‘å¯¼")
        print("=" * 60)
â€‹
        # è¿æ¥Milvus
        if not self.connect():
            return False
â€‹
        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        if not self.check_collection_exists():
            return False
â€‹
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(processed_data_path):
            print(f"âœ— æ–‡æœ¬æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {processed_data_path}")
            return False
â€‹
        if not os.path.exists(vectors_path):
            print(f"âœ— å‘é‡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {vectors_path}")
            return False
â€‹
        try:
            # åŠ è½½æ•°æ®æ–‡ä»¶
            processed_data, vectors_data = self.load_data_files(processed_data_path, vectors_path)
â€‹
            # åˆå¹¶æ•°æ®
            merged_data = self.merge_data(processed_data, vectors_data)
â€‹
            # éªŒè¯æ•°æ®
            if not self.validate_data(merged_data):
                return False
â€‹
            # æ‰¹é‡å¯¼å…¥
            success = self.batch_import(merged_data, batch_size)
â€‹
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            self.get_collection_stats()
â€‹
            return success
â€‹
        except Exception as e:
            print(f"\næ•°æ®å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return False
â€‹
def main():
    # é…ç½®æ–‡ä»¶è·¯å¾„
    processed_data_path = "processed_data.json"  # æ¥è‡ªæ•°æ®é¢„å¤„ç†æ­¥éª¤
    vectors_path = "vectors.json"  # æ¥è‡ªå‘é‡ç”Ÿæˆæ­¥éª¤
â€‹
    # åˆ›å»ºæ•°æ®å¯¼å…¥å™¨
    importer = DataImporter()
â€‹
    # å¯¼å…¥æ•°æ®
    importer.import_data(
        processed_data_path=processed_data_path,
        vectors_path=vectors_path,
        batch_size=50  # è°ƒæ•´æ‰¹å¤„ç†å¤§å°
    )
â€‹
if __name__ == "__main__":
    main()
</details>

ä»£ç è¯´æ˜ï¼š

æ•°æ®åŠ è½½ï¼šä»JSONæ–‡ä»¶è¯»å–é¢„å¤„ç†å¥½çš„æ”¿åŠ¡é—®ç­”æ•°æ®ï¼ŒåŒ…å«IDã€æ ‡é¢˜ã€å†…å®¹å’Œå‘é‡å­—æ®µ

æ•°æ®å‡†å¤‡ï¼šéªŒè¯æ•°æ®å®Œæ•´æ€§ï¼Œç¡®ä¿æ¯æ¡è®°å½•éƒ½æœ‰å¯¹åº”çš„å‘é‡ï¼Œå¹¶é™åˆ¶æ–‡æœ¬å­—æ®µé•¿åº¦

æ‰¹é‡æ’å…¥ï¼šä½¿ç”¨åˆ†æ‰¹æ’å…¥ç­–ç•¥ï¼ˆé»˜è®¤æ¯æ‰¹100æ¡ï¼‰ï¼Œé¿å…å•æ¬¡æ’å…¥æ•°æ®é‡è¿‡å¤§å¯¼è‡´å†…å­˜æº¢å‡º

æ•°æ®åˆ·æ–°ï¼šè°ƒç”¨flush()æ“ä½œç¡®ä¿æ•°æ®æŒä¹…åŒ–åˆ°ç£ç›˜

ç»Ÿè®¡ä¿¡æ¯ï¼šæ˜¾ç¤ºå¯¼å…¥çš„æ–‡æ¡£æ€»æ•°å’Œæ€§èƒ½æŒ‡æ ‡

æ³¨æ„äº‹é¡¹ï¼š

å‘é‡ç»´åº¦å¿…é¡»ä¸Schemaå®šä¹‰ä¸€è‡´ï¼ˆ768æˆ–1024ç»´ï¼‰

è¶…é•¿æ–‡æœ¬ä¼šè¢«æˆªæ–­ä»¥ç¬¦åˆSchemaå®šä¹‰çš„max_length

BM25å‡½æ•°ä¼šåœ¨æ•°æ®æ’å…¥æ—¶è‡ªåŠ¨ç”Ÿæˆç¨€ç–å‘é‡ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—

æ•°æ®å¯¼å…¥ä¹‹åï¼Œè¿›å…¥Attuçš„æ¦‚è§ˆç•Œé¢ï¼Œè§‚å¯ŸSchemaæ ¼å¼å’Œæ•°æ®é‡

![alt text](/images/attu_schema.png)

æ•°æ®å¯¼å…¥æ³¨æ„äº‹é¡¹ï¼š

ç”±äºå­—æ®µé•¿åº¦çš„é™åˆ¶ï¼Œéƒ¨åˆ†è¶…é•¿æ–‡æœ¬ï¼ˆè¶…è¿‡8000å­—ï¼‰å¯èƒ½è¢«æˆªæ–­ï¼Œå¯¼è‡´å®é™…å¯¼å…¥çš„æ•°æ®é‡ä¸åŸå§‹JSONæ–‡ä»¶çš„æ•°æ®é‡ç•¥æœ‰å·®å¼‚ã€‚è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºï¼š

titleå­—æ®µæœ€å¤§é•¿åº¦ä¸º512å­—ç¬¦

contentå­—æ®µæœ€å¤§é•¿åº¦ä¸º65535å­—ç¬¦

Attuç•Œé¢è§‚å¯Ÿï¼š

æ•°æ®å¯¼å…¥å®Œæˆåï¼Œå¯ä»¥é€šè¿‡Attuç•Œé¢è§‚å¯ŸSchemaæ ¼å¼å’Œæ•°æ®é‡ï¼š

![alt text](/images/attu_schema.png)

ä»ç•Œé¢ä¸­å¯ä»¥æ¸…æ¥šçœ‹åˆ°Schemaçš„ç»“æ„ï¼š

embeddingï¼šé‡‡ç”¨FLATç´¢å¼•çš„ç¨ å¯†å‘é‡å­—æ®µï¼Œç”¨äºè¯­ä¹‰æ£€ç´¢

title/contentï¼šåŸå§‹æ–‡æœ¬æ•°æ®å­—æ®µ

title_sparse/content_sparseï¼šBM25ç”Ÿæˆçš„ç¨€ç–å‘é‡å­—æ®µï¼Œç”¨äºå…¨æ–‡æ£€ç´¢

ç”±äºæˆ‘ä»¬åœ¨Schemaä¸­é¢„å®šä¹‰äº†BM25 Functionï¼Œå½“æŸ¥è¯¢æ—¶è¾“å…¥çš„æ–‡æœ¬ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºç¨€ç–å‘é‡è¿›è¡ŒBM25æ£€ç´¢ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—ã€‚

æŸ¥çœ‹æ•°æ®çš„æ–¹æ³•ï¼š

ç‚¹å‡»Attuçš„"æ•°æ®"é¡µé¢ï¼Œå¯èƒ½ä¼šé‡åˆ°ä»¥ä¸‹æƒ…å†µï¼š

ç›´æ¥æŸ¥çœ‹æ•°æ®æŠ¥é”™ï¼šç”±äºBM25ç¨€ç–å‘é‡å­—æ®µçš„å­˜åœ¨ï¼ŒAttué»˜è®¤ç¦æ­¢ç›´æ¥æ˜¾ç¤ºåŒ…å«ç¨€ç–å‘é‡çš„æ•°æ®

![alt text](/images/attu_error.png)

é€šè¿‡å‘é‡æœç´¢æŸ¥çœ‹æ•°æ®ï¼š

è¿›å…¥"å‘é‡æœç´¢"é¡µé¢

å‹¾é€‰embeddingå­—æ®µ

ç‚¹å‡»"ç”Ÿæˆéšæœºå‘é‡"

æ‰§è¡Œæœç´¢å³å¯çœ‹åˆ°æ•°æ®å†…å®¹

![alt text](/images/attu_search.png)

æ³¨æ„äº‹é¡¹ï¼š

å¦‚æœåŒæ—¶å‹¾é€‰title_sparseå’Œcontent_sparseå­—æ®µå¹¶æ‰§è¡Œæœç´¢ï¼Œå¯èƒ½ä¼šå‡ºç°é”™è¯¯

è¿™æ˜¯Attuå¯¹ç¨€ç–å‘é‡æ”¯æŒçš„å·²çŸ¥é™åˆ¶

å»ºè®®é€šè¿‡æˆ‘ä»¬çš„æ£€ç´¢ä»£ç æ¥éªŒè¯BM25æœç´¢åŠŸèƒ½

4.5 æ‰§è¡Œæ£€ç´¢
å½“æˆ‘ä»¬ç¡®å®šæ•°æ®å·²ç»å­˜å‚¨å¥½ï¼Œå¹¶ä¸”Schemaå­—æ®µæ— è¯¯åï¼Œå¯ä»¥æ‰§è¡Œæ£€ç´¢ä»£ç ã€‚è¿™æ®µä»£ç å°†åˆ†åˆ«è¿›è¡Œå•å‘é‡æ£€ç´¢ã€BM25æ£€ç´¢ã€æ··åˆæ£€ç´¢ï¼Œå¹¶è¾“å‡ºæ£€ç´¢ç»“æœã€æ€§èƒ½å¯¹æ¯”ç­‰åˆ†ææ•°æ®ã€‚

4.5.1 å‘é‡ç”Ÿæˆæ–¹æ³•
åœ¨æ‰§è¡Œæ£€ç´¢ä¹‹å‰ï¼Œéœ€è¦å®ç°generate_embeddingæ–¹æ³•ï¼Œç”¨äºå°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚ä»¥ä¸‹æ˜¯å‡ ç§å¸¸è§çš„å®ç°æ–¹å¼ï¼š

æ–¹å¼1ï¼šä½¿ç”¨ModelScopeæ¨¡å‹ï¼ˆæœ¬åœ°æ¨ç†ï¼‰

from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
â€‹
def generate_embedding(self, texts: List[str]) -> List[List[float]]:
    """
    ä½¿ç”¨ModelScopeæ¨¡å‹ç”Ÿæˆæ–‡æœ¬å‘é‡
â€‹
    Args:
        texts: å¾…å‘é‡åŒ–çš„æ–‡æœ¬åˆ—è¡¨
â€‹
    Returns:
        å‘é‡åˆ—è¡¨ï¼Œæ¯ä¸ªå‘é‡æ˜¯1024ç»´çš„floatæ•°ç»„
    """
    # åˆå§‹åŒ–pipelineï¼ˆåªéœ€æ‰§è¡Œä¸€æ¬¡ï¼‰
    if not hasattr(self, 'embedding_pipeline'):
        self.embedding_pipeline = pipeline(
            task=Tasks.SENTENCE_EMBEDDING,
            model='damo/nlp_corom_sentence-embedding_chinese-base'
        )
â€‹
    # æ‰¹é‡ç”Ÿæˆå‘é‡
    embeddings = self.embedding_pipeline(inputs=texts)
â€‹
    # æå–å‘é‡æ•°æ®
    result = []
    for item in embeddings['text_embedding']:
        result.append(item['embedding'].tolist())
â€‹
    return result
æ–¹å¼2ï¼šä½¿ç”¨APIæœåŠ¡

import requests
â€‹
def generate_embedding(self, texts: List[str]) -> List[List[float]]:
    """
    è°ƒç”¨å‘é‡åŒ–APIæœåŠ¡ç”Ÿæˆæ–‡æœ¬å‘é‡
â€‹
    Args:
        texts: å¾…å‘é‡åŒ–çš„æ–‡æœ¬åˆ—è¡¨
â€‹
    Returns:
        å‘é‡åˆ—è¡¨ï¼Œæ¯ä¸ªå‘é‡æ˜¯1024ç»´çš„floatæ•°ç»„
    """
    # APIé…ç½®
    api_url = "https://your-embedding-api.com/embeddings"
    api_key = "your-api-key"
â€‹
    # æ„å»ºè¯·æ±‚
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "texts": texts,
        "model": "embedding-model-name"
    }
â€‹
    # å‘é€è¯·æ±‚
    response = requests.post(api_url, headers=headers, json=data)
    response.raise_for_status()
â€‹
    # è§£æç»“æœ
    result = response.json()['embeddings']
    return result
æ–¹å¼3ï¼šä½¿ç”¨Transformersåº“

from transformers import AutoTokenizer, AutoModel
import torch
â€‹
def generate_embedding(self, texts: List[str]) -> List[List[float]]:
    """
    ä½¿ç”¨Transformersæ¨¡å‹ç”Ÿæˆæ–‡æœ¬å‘é‡
â€‹
    Args:
        texts: å¾…å‘é‡åŒ–çš„æ–‡æœ¬åˆ—è¡¨
â€‹
    Returns:
        å‘é‡åˆ—è¡¨
    """
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆåªéœ€æ‰§è¡Œä¸€æ¬¡ï¼‰
    if not hasattr(self, 'tokenizer'):
        model_name = "shibing624/text2vec-base-chinese"
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.model.eval()
â€‹
    # Tokenizeè¾“å…¥æ–‡æœ¬
    encoded_input = self.tokenizer(
        texts,
        padding=True,
        truncation=True,
        max_length=512,
        return_tensors='pt'
    )
â€‹
    # ç”Ÿæˆå‘é‡
    with torch.no_grad():
        model_output = self.model(**encoded_input)
        # ä½¿ç”¨[CLS] tokençš„å‘é‡ä½œä¸ºå¥å­å‘é‡
        embeddings = model_output.last_hidden_state[:, 0, :]
â€‹
    return embeddings.tolist()
æ³¨æ„äº‹é¡¹ï¼š

å‘é‡ç»´åº¦å¿…é¡»ä¸Schemaä¸­å®šä¹‰çš„ä¸€è‡´ï¼ˆ768ç»´æˆ–1024ç»´ï¼‰

å»ºè®®åœ¨ç±»åˆå§‹åŒ–æ—¶åŠ è½½æ¨¡å‹ï¼Œé¿å…æ¯æ¬¡æŸ¥è¯¢éƒ½é‡æ–°åŠ è½½

æ‰¹é‡å¤„ç†å¯ä»¥æé«˜æ•ˆç‡

ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨APIæœåŠ¡ï¼Œé¿å…æœ¬åœ°GPUèµ„æºå ç”¨

ä¸‹é¢æ˜¯å®Œæ•´çš„æ£€ç´¢ä»£ç å®ç°ï¼š

â€‹
ç‚¹å‡»å±•å¼€Pythonä»£ç 
â€‹
import os
import json
import time
from datetime import datetime
from typing import List, Dict, Any
import requests
import psutil 
â€‹
from pymilvus import (
    MilvusClient,
    AnnSearchRequest,
    WeightedRanker
)
â€‹
class SearchDemo:
    def __init__(self):
        self.client = self.connect_to_milvus()
        self.collection_name = "hybrid_search_collection"
â€‹
    def connect_to_milvus(self) -> MilvusClient:
        return MilvusClient(uri="http://127.0.0.1:19530")
â€‹
    def generate_embedding(self, texts: List[str]) -> List[List[float]]:
        pass
â€‹
    def vector_search(self, query_text: str, top_k: int) -> List[Dict[str, Any]]:
        query_vectors = self.generate_embedding([query_text])
â€‹
        res = self.client.search(
            collection_name=self.collection_name,
            data=query_vectors,
            anns_field="embedding",
            search_params={"metric_type": "IP", "params": {"nprobe": 16}},
            limit=top_k,
            output_fields=["id", "title", "content"]
        )
â€‹
        results = []
        for hits in res:
            for hit in hits:
                results.append({
                    "id": hit["id"],
                    "title": hit["entity"].get("title"),
                    "content": hit["entity"].get("content"),
                    "score": hit["score"],
                    "search_type": "vector"
                })
        return results
â€‹
    def bm25_search(self, query_text: str, top_k: int) -> List[Dict[str, Any]]:
        res = self.client.search(
            collection_name=self.collection_name,
            data=[query_text],
            anns_field="content_sparse",
            search_params={"metric_type": "BM25", "params": {}},
            limit=top_k,
            output_fields=["id", "title", "content"]
        )
â€‹
        results = []
        for hits in res:
            for hit in hits:
                results.append({
                    "id": hit["id"],
                    "title": hit["entity"].get("title"),
                    "content": hit["entity"].get("content"),
                    "score": hit["score"],
                    "search_type": "bm25"
                })
        return results
â€‹
    def hybrid_search(self, query_text: str, vector_weight: float, bm25_weight: float, top_k: int) -> List[Dict[str, Any]]:
        query_vectors = self.generate_embedding([query_text])
        
        dense_req = AnnSearchRequest(
            data=query_vectors,
            anns_field="embedding",
            param={"metric_type": "IP", "params": {"nprobe": 16}},
            limit=top_k
        )
        
        bm25_req = AnnSearchRequest(
            data=[query_text], 
            anns_field="content_sparse",
            param={"metric_type": "BM25", "params": {}},
            limit=top_k
        )
        
        ranker = WeightedRanker(vector_weight, bm25_weight)
        
        res = self.client.hybrid_search(
            collection_name=self.collection_name,
            reqs=[dense_req, bm25_req],
            ranker=ranker,
            limit=top_k,
            output_fields=["id", "title", "content"]
        )
        
        results = []
        for hits in res:
            for hit in hits:
                results.append({
                    "id": hit["id"],
                    "title": hit["entity"].get("title"),
                    "content": hit["entity"].get("content"),
                    "score": hit["score"],
                    "search_type": "hybrid"
                })
        
        return results
â€‹
    def close(self):
        self.client.close()
â€‹
class ResourceUsage:
    def __init__(self, memory_used, memory_total, disk_free, disk_total):
        self.memory_used = memory_used
        self.memory_total = memory_total
        self.disk_free = disk_free
        self.disk_total = disk_total
â€‹
def get_current_resource_usage() -> ResourceUsage:
    """è·å–å½“å‰ç³»ç»Ÿèµ„æº"""
    mem = psutil.virtual_memory()
    process = psutil.Process(os.getpid())
    used_memory = process.memory_info().rss / (1024 * 1024) 
    total_memory = mem.total / (1024 * 1024)
â€‹
    disk_path = 'C:' if os.name == 'nt' else '/'
    try:
        disk = psutil.disk_usage(disk_path)
        free_disk = disk.free / (1024 * 1024 * 1024)
        total_disk = disk.total / (1024 * 1024 * 1024)
    except:
        free_disk = 0
        total_disk = 0
â€‹
    return ResourceUsage(used_memory, total_memory, free_disk, total_disk)
â€‹
def escape_markdown(text: str) -> str:
    if not text:
        return ""
    chars = ['|', '*', '_', '#', '`', '[', ']', '(', ')', '<', '>']
    for char in chars:
        text = text.replace(char, f"\\{char}")
    return text
â€‹
def generate_markdown_report(all_results: List[Dict], initial_res: ResourceUsage, final_res: ResourceUsage):
    lines = []
    lines.append("# æœç´¢æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\n")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now()}\n")
    lines.append(f"æ€»æŸ¥è¯¢æ•°: {len(all_results)}\n")
â€‹
    lines.append("## ä¸€ã€ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ (å®¢æˆ·ç«¯)\n")
    
    lines.append("### 1.1 å†…å­˜ä½¿ç”¨æƒ…å†µ\n")
    mem_delta = final_res.memory_used - initial_res.memory_used
    lines.append("| æŒ‡æ ‡ | åˆå§‹çŠ¶æ€ (MB) | æœ€ç»ˆçŠ¶æ€ (MB) | å˜åŒ–é‡ (MB) |")
    lines.append("|------|-------------|-------------|-----------|")
    lines.append(f"| å·²ç”¨å†…å­˜ | {initial_res.memory_used:.2f} | {final_res.memory_used:.2f} | {mem_delta:+.2f} |")
    lines.append(f"| æ€»å†…å­˜ | {initial_res.memory_total:.0f} | {final_res.memory_total:.0f} | - |\n")
    
    lines.append("### 1.2 ç£ç›˜ä½¿ç”¨æƒ…å†µ\n")
    disk_delta = final_res.disk_free - initial_res.disk_free
    lines.append("| æŒ‡æ ‡ | åˆå§‹çŠ¶æ€ (GB) | æœ€ç»ˆçŠ¶æ€ (GB) | å˜åŒ–é‡ (GB) |")
    lines.append("|------|-------------|-------------|-----------|")
    lines.append(f"| å¯ç”¨ç©ºé—´ | {initial_res.disk_free:.2f} | {final_res.disk_free:.2f} | {disk_delta:+.2f} |")
    lines.append(f"| æ€»å®¹é‡ | {initial_res.disk_total:.2f} | {final_res.disk_total:.2f} | - |\n")
â€‹
    lines.append("### 1.3 ç†è®ºèµ„æºå ç”¨å¯¹æ¯” (æœåŠ¡ç«¯)\n")
    lines.append("| æ£€ç´¢æ–¹å¼ | ç‰¹ç‚¹ | å†…å­˜å ç”¨ | ç£ç›˜å ç”¨ |")
    lines.append("|---------|------|---------|---------|")
    lines.append("| **å‘é‡æœç´¢** | éœ€åŠ è½½å‘é‡ç´¢å¼• | ä¸­ç­‰ | é«˜ï¼ˆå‘é‡æ•°æ®ï¼‰ |")
    lines.append("| **BM25æœç´¢** | å€’æ’ç´¢å¼• | è¾ƒä½ | è¾ƒä½ï¼ˆç¨€ç–å‘é‡ï¼‰ |")
    lines.append("| **æ··åˆæœç´¢** | ç»“åˆä¸¤è€… | è¾ƒé«˜ | é«˜ï¼ˆåŒç´¢å¼•ï¼‰ |\n")
â€‹
    lines.append("## äºŒã€æ€»ä½“æ€§èƒ½ç»Ÿè®¡\n")
    
    total_vector_time = sum(r['vector_time'] for r in all_results)
    total_bm25_time = sum(r['bm25_time'] for r in all_results)
    total_hybrid_time = sum(r['hybrid_time'] for r in all_results)
    total_overall_time = sum(r['total_time'] for r in all_results)
    count = len(all_results)
    
    avg_vec = total_vector_time / count if count else 0
    avg_bm25 = total_bm25_time / count if count else 0
    avg_hybrid = total_hybrid_time / count if count else 0
    avg_total = total_overall_time / count if count else 0
â€‹
    lines.append("### 2.1 æ€§èƒ½æ±‡æ€»\n")
    lines.append("| æœç´¢æ–¹å¼ | æ€»è€—æ—¶(ms) | å¹³å‡è€—æ—¶(ms) | ç›¸å¯¹é€Ÿåº¦ |")
    lines.append("|---------|-----------|-------------|----------|")
    lines.append(f"| å‘é‡æœç´¢ | {total_vector_time:.0f} | {avg_vec:.2f} | åŸºå‡† |")
    
    bm25_speedup = avg_vec / avg_bm25 if avg_bm25 > 0 else 0
    lines.append(f"| BM25æœç´¢ | {total_bm25_time:.0f} | {avg_bm25:.2f} | {bm25_speedup:.2f}x |")
    
    hybrid_speedup = avg_vec / avg_hybrid if avg_hybrid > 0 else 0
    lines.append(f"| æ··åˆæœç´¢ | {total_hybrid_time:.0f} | {avg_hybrid:.2f} | {hybrid_speedup:.2f}x |")
    lines.append(f"| æ€»è®¡ | {total_overall_time:.0f} | {avg_total:.2f} | - |\n")
â€‹
    lines.append("## ä¸‰ã€æœç´¢ç»“æœå¯¹æ¯”\n")
    for r in all_results:
        lines.append(f"### {r['query_index']}. æŸ¥è¯¢: {escape_markdown(r['query_text'])}\n")
        lines.append(f"- å‘é‡ç»“æœæ•°: **{r['vector_count']}** | BM25ç»“æœæ•°: **{r['bm25_count']}** | æ··åˆç»“æœæ•°: **{r['hybrid_count']}**\n")
        
        lines.append("| æ’å | å‘é‡åˆ†æ•° | BM25åˆ†æ•° | æ··åˆåˆ†æ•° | å‘é‡å†…å®¹ |")
        lines.append("|------|---------|---------|---------|---------|")
        
        max_rows = min(5, max(len(r['vector_res']), len(r['bm25_res']), len(r['hybrid_res'])))
        for i in range(max_rows):
            v_item = r['vector_res'][i] if i < len(r['vector_res']) else {}
            b_item = r['bm25_res'][i] if i < len(r['bm25_res']) else {}
            h_item = r['hybrid_res'][i] if i < len(r['hybrid_res']) else {}
            
            v_s = f"{v_item.get('score', 0):.4f}" if v_item else "-"
            b_s = f"{b_item.get('score', 0):.4f}" if b_item else "-"
            h_s = f"{h_item.get('score', 0):.4f}" if h_item else "-"
            
            content = str(v_item.get('content', '-'))
            v_c = escape_markdown(content[:20] + "...") if len(content) > 20 else escape_markdown(content)
            
            lines.append(f"| {i+1} | {v_s} | {b_s} | {h_s} | {v_c} |")
        lines.append("\n")
â€‹
    lines.append("## å››ã€æ€»ç»“\n")
    lines.append("### 4.1 èµ„æºå ç”¨è¯´æ˜\n")
    lines.append("- ä¸Šè¿°èµ„æºå˜åŒ–ä»…åæ˜ å®¢æˆ·ç«¯è„šæœ¬çš„å¼€é”€ï¼Œä¸ä»£è¡¨ Milvus æ•°æ®åº“çš„å®é™…è´Ÿè½½ã€‚")
    lines.append("- **çœŸå®æƒ…å†µ**: å¼€å¯å…¨æ–‡æ£€ç´¢ä¼šå¢åŠ çº¦ 5-15% çš„ç£ç›˜å ç”¨ï¼ˆç¨€ç–å‘é‡ç´¢å¼•ï¼‰ï¼Œå¯¹å†…å­˜å½±å“è¾ƒå°ã€‚\n")
    lines.append("### 4.2 ç­–ç•¥å»ºè®®\n")
    lines.append("- **èµ„æºå……è¶³**: æ¨èæ··åˆæ£€ç´¢ã€‚")
    lines.append("- **èµ„æºå—é™**: å…³é”®è¯æŸ¥è¯¢ç”¨ BM25ï¼Œè¯­ä¹‰æŸ¥è¯¢ç”¨å‘é‡ã€‚")
â€‹
    with open("search_comparison_report.md", "w", encoding="utf-8") as f:
        f.writelines([line + "\n" if not line.endswith("\n") else line for line in lines])
â€‹
def main():
    demo = SearchDemo()
    all_query_results = []
    
    initial_resource = get_current_resource_usage()
    print("å¼€å§‹æ‰§è¡Œæœç´¢æµ‹è¯•...")
â€‹
    try:
        json_path = os.path.join("src", "quest.json")
        if not os.path.exists(json_path):
             json_path = "quest.json"
        
        if not os.path.exists(json_path):
            print("Quest file not found, using dummy data.")
            all_questions = ["test query 1", "test query 2"]
        else:
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            all_questions = []
            for section in data.get("sections", []):
                for question in section.get("questions", []):
                    all_questions.append(question)
â€‹
        for idx, query_text in enumerate(all_questions, 1):
            print(f"Processing query {idx}: {query_text}")
            start_time = time.time() * 1000
            
            # å‘é‡æœç´¢
            v_start = time.time() * 1000
            vec_res = demo.vector_search(query_text, 10)
            v_time = (time.time() * 1000) - v_start
            
            # BM25æœç´¢
            b_start = time.time() * 1000
            bm25_res = demo.bm25_search(query_text, 10)
            b_time = (time.time() * 1000) - b_start
            
            # æ··åˆæœç´¢
            h_start = time.time() * 1000
            hybrid_res = demo.hybrid_search(query_text, 0.5, 0.5, 10)
            h_time = (time.time() * 1000) - h_start
            
            total_time = (time.time() * 1000) - start_time
            
            all_query_results.append({
                "query_text": query_text,
                "query_index": idx,
                "vector_time": v_time,
                "bm25_time": b_time,
                "hybrid_time": h_time,
                "total_time": total_time,
                "vector_count": len(vec_res),
                "bm25_count": len(bm25_res),
                "hybrid_count": len(hybrid_res),
                "vector_res": vec_res,
                "bm25_res": bm25_res,
                "hybrid_res": hybrid_res
            })
â€‹
        # è®°å½•ç»“æŸèµ„æº
        final_resource = get_current_resource_usage()
â€‹
        generate_markdown_report(all_query_results, initial_resource, final_resource)
        print("æŠ¥å‘Šå·²ç”Ÿæˆ: search_comparison_report.md")
â€‹
    except Exception as e:
        print(f"Error during search: {e}")
        import traceback
        traceback.print_exc()
    finally:
        demo.close()
â€‹
if __name__ == "__main__":
    main()
</details>

4.5.2 æ£€ç´¢ä»£ç è¯´æ˜
ä¸Šè¿°Pythonæ£€ç´¢ä»£ç å®ç°äº†ä¸‰ç§æ£€ç´¢æ–¹å¼çš„æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼š

å‘é‡æœç´¢ï¼ˆvector_searchï¼‰

å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡

ä½¿ç”¨å†…ç§¯ï¼ˆIPï¼‰åº¦é‡è®¡ç®—ç›¸ä¼¼åº¦

è¿”å›æœ€ç›¸ä¼¼çš„top_kæ¡è®°å½•

BM25å…¨æ–‡æœç´¢ï¼ˆbm25_searchï¼‰

ç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬è¿›è¡Œæ£€ç´¢

Milvusè‡ªåŠ¨å°†æ–‡æœ¬è½¬æ¢ä¸ºBM25ç¨€ç–å‘é‡

åŸºäºå…³é”®è¯åŒ¹é…è®¡ç®—ç›¸å…³æ€§åˆ†æ•°

æ··åˆæœç´¢ï¼ˆhybrid_searchï¼‰

åŒæ—¶æ‰§è¡Œå‘é‡æœç´¢å’ŒBM25æœç´¢

ä½¿ç”¨åŠ æƒç­–ç•¥èåˆä¸¤ç§ç»“æœï¼ˆå¯é…ç½®æƒé‡ï¼‰

ç»¼åˆè¯­ä¹‰ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…åº¦

æ€§èƒ½ç›‘æ§ï¼š

è®°å½•æ¯ç§æœç´¢æ–¹å¼çš„å“åº”æ—¶é—´

ç›‘æ§å†…å­˜å’Œç£ç›˜èµ„æºä½¿ç”¨æƒ…å†µ

ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š

æŠ¥å‘Šç”Ÿæˆï¼š

è‡ªåŠ¨ç”ŸæˆMarkdownæ ¼å¼çš„å¯¹æ¯”æŠ¥å‘Š

åŒ…å«æ€§èƒ½ç»Ÿè®¡ã€ç»“æœå¯¹æ¯”ã€èµ„æºå ç”¨åˆ†æ

è¾“å‡ºæ–‡ä»¶ï¼šsearch_comparison_report.md

4.5.3 Javaç‰ˆæœ¬å®ç°
å¯¹äºJavaå¼€å‘è€…ï¼Œæˆ‘ä»¬ä¹Ÿæä¾›äº†å®Œæ•´çš„Javaå®ç°ç‰ˆæœ¬ã€‚åŒæ ·éœ€è¦å®ç°generateEmbeddingæ–¹æ³•æ¥ç”ŸæˆæŸ¥è¯¢å‘é‡ã€‚

â€‹
ç‚¹å‡»å±•å¼€Javaä»£ç 
â€‹
package com.czkj;
â€‹
import com.google.gson.*;
import com.ilotterytech.dknow.llm.api.client.LLMClient;
import com.ilotterytech.dknow.llm.api.vo.EmbeddingStringResult;
â€‹
import io.milvus.v2.client.ConnectConfig;
import io.milvus.v2.client.MilvusClientV2;
import io.milvus.v2.common.IndexParam;
import io.milvus.v2.service.vector.request.SearchReq;
import io.milvus.v2.service.vector.request.data.EmbeddedText;
import io.milvus.v2.service.vector.request.data.FloatVec;
import io.milvus.v2.service.vector.request.ranker.BaseRanker;
import io.milvus.v2.service.vector.request.ranker.WeightedRanker;
import io.milvus.v2.service.vector.response.SearchResp;
import io.milvus.v2.service.vector.request.AnnSearchReq;
import io.milvus.v2.service.vector.request.HybridSearchReq;
â€‹
import java.io.IOException;
import java.util.*;
â€‹
public class searchDemo {
â€‹
    /**
     * æŸ¥è¯¢ç»“æœæ•°æ®ç»“æ„
     */
    static class QueryResult {
        String queryText;
        int queryIndex;
        long vectorTime;
        long bm25Time;
        long hybridTime;
        long totalTime;
        int vectorResultCount;
        int bm25ResultCount;
        int hybridResultCount;
        List<Map<String, Object>> vectorResults;
        List<Map<String, Object>> bm25Results;
        List<Map<String, Object>> hybridResults;
    }
â€‹
    /**
     * èµ„æºä½¿ç”¨ç»Ÿè®¡
     */
    static class ResourceUsage {
        long memoryUsed; // MB
        long memoryTotal; // MB
        long diskFree; // GB
        long diskTotal; // GB
â€‹
        public ResourceUsage(long memoryUsed, long memoryTotal, long diskFree, long diskTotal) {
            this.memoryUsed = memoryUsed;
            this.memoryTotal = memoryTotal;
            this.diskFree = diskFree;
            this.diskTotal = diskTotal;
        }
    }
â€‹
    /**
     * è·å–å½“å‰èµ„æºä½¿ç”¨æƒ…å†µ
     */
    private static ResourceUsage getCurrentResourceUsage() {
        Runtime runtime = Runtime.getRuntime();
â€‹
        // JVMå†…å­˜ä½¿ç”¨æƒ…å†µ (MB)
        long usedMemory = (runtime.totalMemory() - runtime.freeMemory()) / (1024 * 1024);
        long totalMemory = runtime.totalMemory() / (1024 * 1024);
â€‹
        // ç£ç›˜ä½¿ç”¨æƒ…å†µ (GB)
        java.io.File root = new java.io.File("C:"); // Windowsç³»ç»Ÿç›˜
        if (!root.exists()) {
            root = new java.io.File("/"); // Linux/Macæ ¹ç›®å½•
        }
        long freeDisk = root.getUsableSpace() / (1024 * 1024 * 1024);
        long totalDisk = root.getTotalSpace() / (1024 * 1024 * 1024);
â€‹
        return new ResourceUsage(usedMemory, totalMemory, freeDisk, totalDisk);
    }
â€‹
    private static MilvusClientV2 connect2milvus(){
        ConnectConfig config = ConnectConfig.builder()
                .uri("http://127.0.0.1:19530")
                .build();
        MilvusClientV2 client = new MilvusClientV2(config);
        return client;
    }
    
    private static List<List<Float>> generateEmbedding(List<String> text) {
        
    }
â€‹
â€‹
    public static void main(String[] args) {
        // åˆå§‹åŒ–æœç´¢æ¼”ç¤ºç±»
        searchDemo demo = new searchDemo();
â€‹
        // è¿æ¥åˆ°Milvus
        MilvusClientV2 client = demo.connect2milvus();
â€‹
        // å­˜å‚¨æ‰€æœ‰æŸ¥è¯¢ç»“æœ
        List<QueryResult> allQueryResults = new ArrayList<>();
â€‹
        // è®°å½•åˆå§‹èµ„æºä½¿ç”¨æƒ…å†µ
        ResourceUsage initialResource = getCurrentResourceUsage();
        System.out.println("å¼€å§‹æ‰§è¡Œæœç´¢æµ‹è¯•...");
â€‹
        try {
            // è¯»å–æŸ¥è¯¢æ–‡æœ¬
            String jsonString = null;
            try {
                jsonString = new String(java.nio.file.Files.readAllBytes(java.nio.file.Paths.get("src/quest.json")));
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
            JsonObject root = JsonParser.parseString(jsonString).getAsJsonObject();
            JsonArray sections = root.getAsJsonArray("sections");
            List<String> allQuestions = new ArrayList<>();
            for (JsonElement sectionElements : sections){
                JsonObject section = sectionElements.getAsJsonObject();
                JsonArray questions = section.getAsJsonArray("questions");
                for(JsonElement questionElement : questions){
                    allQuestions.add(questionElement.getAsString());
                }
            }
â€‹
            // æ‰§è¡Œæ‰€æœ‰æŸ¥è¯¢
            int queryIndex = 0;
            for (String queryText : allQuestions) {
                queryIndex++;
â€‹
                // è®°å½•å¼€å§‹æ—¶é—´
                long startTime = System.currentTimeMillis();
â€‹
                // é¦–å…ˆè¿›è¡Œå‘é‡æœç´¢
                long vectorStartTime = System.currentTimeMillis();
                List<Map<String, Object>> vectorResults = demo.vectorSearch(client, queryText, 10);
                long vectorTime = System.currentTimeMillis() - vectorStartTime;
â€‹
                // ç„¶åè¿›è¡ŒBM25æœç´¢
                long bm25StartTime = System.currentTimeMillis();
                List<Map<String, Object>> bm25Results = demo.bm25Search(client, queryText, 10);
                long bm25Time = System.currentTimeMillis() - bm25StartTime;
â€‹
                // æ‰§è¡Œæ··åˆæœç´¢
                long hybridStartTime = System.currentTimeMillis();
                List<Map<String, Object>> hybridResults = demo.hybridSearch(client, queryText, 0.5f, 0.5f, 10);
                long hybridTime = System.currentTimeMillis() - hybridStartTime;
â€‹
                long totalTime = System.currentTimeMillis() - startTime;
â€‹
                // ä¿å­˜æŸ¥è¯¢ç»“æœ
                QueryResult queryResult = new QueryResult();
                queryResult.queryText = queryText;
                queryResult.queryIndex = queryIndex;
                queryResult.vectorTime = vectorTime;
                queryResult.bm25Time = bm25Time;
                queryResult.hybridTime = hybridTime;
                queryResult.totalTime = totalTime;
                queryResult.vectorResultCount = vectorResults.size();
                queryResult.bm25ResultCount = bm25Results.size();
                queryResult.hybridResultCount = hybridResults.size();
                queryResult.vectorResults = vectorResults;
                queryResult.bm25Results = bm25Results;
                queryResult.hybridResults = hybridResults;
â€‹
                allQueryResults.add(queryResult);
            }
â€‹
            // è®°å½•ç»“æŸèµ„æºä½¿ç”¨æƒ…å†µ
            ResourceUsage finalResource = getCurrentResourceUsage();
â€‹
            // ç”ŸæˆMarkdownæŠ¥å‘Šå¹¶å†™å…¥æ–‡ä»¶
            generateMarkdownReport(allQueryResults, initialResource, finalResource);
            System.out.println("æŠ¥å‘Šå·²ç”Ÿæˆ: search_comparison_report.md");
â€‹
        } catch (Exception e) {
            System.err.println("Error during search: " + e.getMessage());
            e.printStackTrace();
        } finally {
            client.close();
        }
    }
â€‹
    /**
     * ç”ŸæˆMarkdownæŠ¥å‘Š
     */
    private static void generateMarkdownReport(List<QueryResult> allQueryResults,
                                               ResourceUsage initialResource,
                                               ResourceUsage finalResource) {
        StringBuilder md = new StringBuilder();
â€‹
        // æŠ¥å‘Šæ ‡é¢˜
        md.append("# æœç´¢æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\n\n");
        md.append("ç”Ÿæˆæ—¶é—´: ").append(new Date()).append("\n\n");
        md.append("æ€»æŸ¥è¯¢æ•°: ").append(allQueryResults.size()).append("\n\n");
â€‹
        // èµ„æºä½¿ç”¨æƒ…å†µç»Ÿè®¡
        md.append("## ä¸€ã€ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ\n\n");
â€‹
        md.append("### 1.1 å†…å­˜ä½¿ç”¨æƒ…å†µ\n\n");
        long memoryDelta = finalResource.memoryUsed - initialResource.memoryUsed;
        md.append("| æŒ‡æ ‡ | åˆå§‹çŠ¶æ€ (MB) | æœ€ç»ˆçŠ¶æ€ (MB) | å˜åŒ–é‡ (MB) |\n");
        md.append("|------|-------------|-------------|-----------|\n");
        md.append(String.format("| å·²ç”¨å†…å­˜ | %d | %d | %+d |\n",
                initialResource.memoryUsed, finalResource.memoryUsed, memoryDelta));
        md.append(String.format("| æ€»å†…å­˜ | %d | %d | - |\n",
                initialResource.memoryTotal, finalResource.memoryTotal));
        md.append(String.format("| ä½¿ç”¨ç‡ | %.1f%% | %.1f%% | %+.1f%% |\n\n",
                (double) initialResource.memoryUsed / initialResource.memoryTotal * 100,
                (double) finalResource.memoryUsed / finalResource.memoryTotal * 100,
                (double) memoryDelta / initialResource.memoryTotal * 100));
â€‹
        // å†…å­˜åˆ†æ
        md.append("**å†…å­˜ä½¿ç”¨åˆ†æ:**\n\n");
        if (memoryDelta > 0) {
            md.append(String.format("- æ‰§è¡Œæ‰€æœ‰æŸ¥è¯¢åï¼Œå†…å­˜ä½¿ç”¨å¢åŠ äº† **%d MB**\n", memoryDelta));
            md.append(String.format("- å¹³å‡æ¯ä¸ªæŸ¥è¯¢å ç”¨å†…å­˜: **%.2f MB**\n\n",
                    (double) memoryDelta / allQueryResults.size()));
        } else {
            md.append("- å†…å­˜ä½¿ç”¨åŸºæœ¬ç¨³å®šï¼Œå¯èƒ½å­˜åœ¨åƒåœ¾å›æ”¶\n\n");
        }
â€‹
        md.append("### 1.2 ç£ç›˜ä½¿ç”¨æƒ…å†µ\n\n");
        long diskDelta = finalResource.diskFree - initialResource.diskFree;
        md.append("| æŒ‡æ ‡ | åˆå§‹çŠ¶æ€ (GB) | æœ€ç»ˆçŠ¶æ€ (GB) | å˜åŒ–é‡ (GB) |\n");
        md.append("|------|-------------|-------------|-----------|\n");
        md.append(String.format("| å¯ç”¨ç©ºé—´ | %d | %d | %+d |\n",
                initialResource.diskFree, finalResource.diskFree, diskDelta));
        md.append(String.format("| æ€»å®¹é‡ | %d | %d | - |\n",
                initialResource.diskTotal, finalResource.diskTotal));
        md.append(String.format("| ä½¿ç”¨ç‡ | %.1f%% | %.1f%% | %+.1f%% |\n\n",
                (double) (initialResource.diskTotal - initialResource.diskFree) / initialResource.diskTotal * 100,
                (double) (finalResource.diskTotal - finalResource.diskFree) / finalResource.diskTotal * 100,
                (double) (-diskDelta) / initialResource.diskTotal * 100));
â€‹
        // ç£ç›˜åˆ†æ
        md.append("**ç£ç›˜ä½¿ç”¨åˆ†æ:**\n\n");
        if (diskDelta < 0) {
            md.append(String.format("- æ‰§è¡Œè¿‡ç¨‹ä¸­ç£ç›˜å¯ç”¨ç©ºé—´å‡å°‘äº† **%d GB**\n", -diskDelta));
            md.append("- å¯èƒ½åŸå› ï¼šæ—¥å¿—æ–‡ä»¶ã€ä¸´æ—¶æ–‡ä»¶æˆ–ç¼“å­˜æ•°æ®\n\n");
        } else {
            md.append("- ç£ç›˜ä½¿ç”¨åŸºæœ¬ç¨³å®š\n\n");
        }
â€‹
        md.append("### 1.3 ä¸åŒæ£€ç´¢æ–¹å¼çš„èµ„æºå ç”¨å¯¹æ¯”\n\n");
        md.append("| æ£€ç´¢æ–¹å¼ | ç‰¹ç‚¹ | å†…å­˜å ç”¨ | ç£ç›˜å ç”¨ | å¤‡æ³¨ |\n");
        md.append("|---------|------|---------|---------|------|\n");
        md.append("| **å‘é‡æœç´¢** | éœ€è¦åŠ è½½å‘é‡ç´¢å¼• | ä¸­ç­‰ | é«˜ï¼ˆå‘é‡æ•°æ®+ç´¢å¼•ï¼‰ | é€‚åˆè¯­ä¹‰æ£€ç´¢ |\n");
        md.append("| **BM25æœç´¢** | å€’æ’ç´¢å¼• | è¾ƒä½ | è¾ƒä½ï¼ˆç¨€ç–å‘é‡ï¼‰ | é€‚åˆå…³é”®è¯æ£€ç´¢ |\n");
        md.append("| **æ··åˆæœç´¢** | ç»“åˆä¸¤è€… | è¾ƒé«˜ | é«˜ï¼ˆåŒç´¢å¼•ï¼‰ | æ€§èƒ½æœ€ä¼˜ä½†èµ„æºæ¶ˆè€—å¤§ |\n\n");
â€‹
        md.append("**è¯´æ˜:**\n");
        md.append("- **å†…å­˜å ç”¨**: å‘é‡ç´¢å¼•éœ€è¦åœ¨å†…å­˜ä¸­ä¿æŒä»¥å¿«é€Ÿå“åº”ï¼ŒBM25å€’æ’ç´¢å¼•å†…å­˜å ç”¨è¾ƒå°\n");
        md.append("- **ç£ç›˜å ç”¨**: å‘é‡æ•°æ®å’Œç´¢å¼•æ–‡ä»¶é€šå¸¸å ç”¨é‡è¾ƒå¤§ï¼Œç¨€ç–å‘é‡ï¼ˆBM25ï¼‰å ç”¨è¾ƒå°\n");
        md.append("- **æ··åˆæœç´¢**: åŒæ—¶ç»´æŠ¤ä¸¤å¥—ç´¢å¼•ï¼Œèµ„æºå ç”¨æ˜¯ä¸¤è€…çš„æ€»å’Œ\n\n");
â€‹
        // ç”Ÿæˆæ€»ä½“æ€§èƒ½ç»Ÿè®¡
        md.append("## äºŒã€æ€»ä½“æ€§èƒ½ç»Ÿè®¡\n\n");
â€‹
        // è®¡ç®—ç»Ÿè®¡æ•°æ®
        long totalVectorTime = 0;
        long totalBm25Time = 0;
        long totalHybridTime = 0;
        long totalOverallTime = 0;
â€‹
        for (QueryResult result : allQueryResults) {
            totalVectorTime += result.vectorTime;
            totalBm25Time += result.bm25Time;
            totalHybridTime += result.hybridTime;
            totalOverallTime += result.totalTime;
        }
â€‹
        double avgVectorTime = (double) totalVectorTime / allQueryResults.size();
        double avgBm25Time = (double) totalBm25Time / allQueryResults.size();
        double avgHybridTime = (double) totalHybridTime / allQueryResults.size();
        double avgOverallTime = (double) totalOverallTime / allQueryResults.size();
â€‹
        md.append("### 1.1 æ€§èƒ½æ±‡æ€»\n\n");
        md.append("| æœç´¢æ–¹å¼ | æ€»è€—æ—¶(ms) | å¹³å‡è€—æ—¶(ms) | ç›¸å¯¹é€Ÿåº¦ |\n");
        md.append("|---------|-----------|-------------|----------|\n");
        md.append(String.format("| å‘é‡æœç´¢ | %d | %.2f | åŸºå‡† |\n", totalVectorTime, avgVectorTime));
        md.append(String.format("| BM25æœç´¢ | %d | %.2f | %.2fx |\n",
                totalBm25Time, avgBm25Time, avgVectorTime / avgBm25Time));
        md.append(String.format("| æ··åˆæœç´¢ | %d | %.2f | %.2fx |\n",
                totalHybridTime, avgHybridTime, avgVectorTime / avgHybridTime));
        md.append(String.format("| æ€»è®¡ | %d | %.2f | - |\n\n", totalOverallTime, avgOverallTime));
â€‹
        // æ€§èƒ½åˆ†æ
        md.append("### 1.2 æ€§èƒ½åˆ†æ\n\n");
        if (avgBm25Time < avgVectorTime) {
            md.append(String.format("- **BM25æœç´¢**æ¯”å‘é‡æœç´¢å¿« **%.2få€**\n", avgVectorTime / avgBm25Time));
        } else {
            md.append(String.format("- **å‘é‡æœç´¢**æ¯”BM25æœç´¢å¿« **%.2få€**\n", avgBm25Time / avgVectorTime));
        }
        md.append(String.format("- æ··åˆæœç´¢æ€»è€—æ—¶ = å‘é‡æœç´¢ + BM25æœç´¢ (%.2f + %.2f = %.2f ms)\n\n",
                avgVectorTime, avgBm25Time, avgHybridTime));
â€‹
        // æ¯ä¸ªæŸ¥è¯¢çš„è¯¦ç»†æ€§èƒ½å¯¹æ¯”
        md.append("### 1.3 å„æŸ¥è¯¢æ€§èƒ½è¯¦æƒ…\n\n");
        md.append("| æŸ¥è¯¢# | å‘é‡æœç´¢(ms) | BM25æœç´¢(ms) | æ··åˆæœç´¢(ms) | æ€»è€—æ—¶(ms) |\n");
        md.append("|-------|-------------|-------------|-------------|----------|\n");
        for (QueryResult result : allQueryResults) {
            md.append(String.format("| #%d | %d | %d | %d | %d |\n",
                    result.queryIndex, result.vectorTime, result.bm25Time,
                    result.hybridTime, result.totalTime));
        }
        md.append("\n");
â€‹
        // ç”Ÿæˆç»“æœå¯¹æ¯”è¡¨æ ¼
        md.append("## ä¸‰ã€æœç´¢ç»“æœå¯¹æ¯”\n\n");
â€‹
        for (QueryResult qr : allQueryResults) {
            md.append("### ").append(qr.queryIndex).append(". æŸ¥è¯¢: ").append(escapeMarkdown(qr.queryText)).append("\n\n");
â€‹
            md.append("#### ç»“æœç»Ÿè®¡\n\n");
            md.append(String.format("- å‘é‡æœç´¢ç»“æœæ•°: **%d**\n", qr.vectorResultCount));
            md.append(String.format("- BM25æœç´¢ç»“æœæ•°: **%d**\n", qr.bm25ResultCount));
            md.append(String.format("- æ··åˆæœç´¢ç»“æœæ•°: **%d**\n\n", qr.hybridResultCount));
â€‹
            // Top 5 å¯¹æ¯”è¡¨æ ¼
            md.append("#### Top 5 ç»“æœå¯¹æ¯”\n\n");
            md.append("| æ’å | å‘é‡æœç´¢åˆ†æ•° | BM25æœç´¢åˆ†æ•° | æ··åˆæœç´¢åˆ†æ•° | å‘é‡æœç´¢å†…å®¹ | BM25æœç´¢å†…å®¹ | æ··åˆæœç´¢å†…å®¹ |\n");
            md.append("|------|-------------|-------------|-------------|-------------|-------------|-------------|\n");
â€‹
            int maxRows = Math.min(5, Math.max(qr.vectorResults.size(),
                    Math.max(qr.bm25Results.size(), qr.hybridResults.size())));
â€‹
            for (int i = 0; i < maxRows; i++) {
                String vectorScore = "-";
                String vectorContent = "-";
                String bm25Score = "-";
                String bm25Content = "-";
                String hybridScore = "-";
                String hybridContent = "-";
â€‹
                if (i < qr.vectorResults.size()) {
                    Map<String, Object> result = qr.vectorResults.get(i);
                    Number scoreNum = (Number) result.get("score");
                    vectorScore = String.format("%.4f", scoreNum.doubleValue());
                    String content = result.get("content").toString();
                    vectorContent = content.length() > 20 ? escapeMarkdown(content.substring(0, 20) + "...") : escapeMarkdown(content);
                }
â€‹
                if (i < qr.bm25Results.size()) {
                    Map<String, Object> result = qr.bm25Results.get(i);
                    Number scoreNum = (Number) result.get("score");
                    bm25Score = String.format("%.4f", scoreNum.doubleValue());
                    String content = result.get("content").toString();
                    bm25Content = content.length() > 20 ? escapeMarkdown(content.substring(0, 20) + "...") : escapeMarkdown(content);
                }
â€‹
                if (i < qr.hybridResults.size()) {
                    Map<String, Object> result = qr.hybridResults.get(i);
                    Number scoreNum = (Number) result.get("score");
                    hybridScore = String.format("%.4f", scoreNum.doubleValue());
                    String content = result.get("content").toString();
                    hybridContent = content.length() > 20 ? escapeMarkdown(content.substring(0, 20) + "...") : escapeMarkdown(content);
                }
â€‹
                md.append(String.format("| %d | %s | %s | %s | %s | %s | %s |\n",
                        i + 1, vectorScore, bm25Score, hybridScore,
                        vectorContent, bm25Content, hybridContent));
            }
            md.append("\n");
â€‹
            // Top 3 è¯¦ç»†å¯¹æ¯”
            md.append("#### Top 3 è¯¦ç»†å¯¹æ¯”\n\n");
            int topK = Math.min(3, Math.min(qr.vectorResults.size(),
                    Math.min(qr.bm25Results.size(), qr.hybridResults.size())));
â€‹
            for (int i = 0; i < topK; i++) {
                md.append("**ç¬¬ ").append(i + 1).append(" å**\n\n");
â€‹
                if (i < qr.vectorResults.size()) {
                    Map<String, Object> result = qr.vectorResults.get(i);
                    Number scoreNum = (Number) result.get("score");
                    md.append("##### å‘é‡æœç´¢\n\n");
                    md.append(String.format("- **åˆ†æ•°**: %.6f\n", scoreNum.doubleValue()));
                    md.append(String.format("- **æ ‡é¢˜**: %s\n", escapeMarkdown(result.get("title").toString())));
                    md.append(String.format("- **å†…å®¹**: %s\n\n", escapeMarkdown(result.get("content").toString())));
                }
â€‹
                if (i < qr.bm25Results.size()) {
                    Map<String, Object> result = qr.bm25Results.get(i);
                    Number scoreNum = (Number) result.get("score");
                    md.append("##### BM25æœç´¢\n\n");
                    md.append(String.format("- **åˆ†æ•°**: %.6f\n", scoreNum.doubleValue()));
                    md.append(String.format("- **æ ‡é¢˜**: %s\n", escapeMarkdown(result.get("title").toString())));
                    md.append(String.format("- **å†…å®¹**: %s\n\n", escapeMarkdown(result.get("content").toString())));
                }
â€‹
                if (i < qr.hybridResults.size()) {
                    Map<String, Object> result = qr.hybridResults.get(i);
                    Number scoreNum = (Number) result.get("score");
                    md.append("##### æ··åˆæœç´¢\n\n");
                    md.append(String.format("- **åˆ†æ•°**: %.6f\n", scoreNum.doubleValue()));
                    md.append(String.format("- **æ ‡é¢˜**: %s\n", escapeMarkdown(result.get("title").toString())));
                    md.append(String.format("- **å†…å®¹**: %s\n\n", escapeMarkdown(result.get("content").toString())));
                }
â€‹
                md.append("---\n\n");
            }
        }
â€‹
        // ç”Ÿæˆæ€»ç»“
        md.append("## å››ã€æ€»ç»“\n\n");
â€‹
        md.append("### 4.1 æ€§èƒ½æ€»ç»“\n\n");
        md.append(String.format("- å‘é‡æœç´¢å¹³å‡å“åº”æ—¶é—´: **%.2f ms**\n", avgVectorTime));
        md.append(String.format("- BM25æœç´¢å¹³å‡å“åº”æ—¶é—´: **%.2f ms**\n", avgBm25Time));
        md.append(String.format("- æ··åˆæœç´¢å¹³å‡å“åº”æ—¶é—´: **%.2f ms**\n\n", avgHybridTime));
â€‹
        md.append("### 4.2 èµ„æºä½¿ç”¨æ€»ç»“\n\n");
        md.append(String.format("- å†…å­˜ä½¿ç”¨å¢åŠ : **%d MB** (å¹³å‡ %.2f MB/æŸ¥è¯¢)\n",
                memoryDelta, (double) memoryDelta / allQueryResults.size()));
        md.append(String.format("- åˆå§‹å†…å­˜ä½¿ç”¨ç‡: **%.1f%%**\n",
                (double) initialResource.memoryUsed / initialResource.memoryTotal * 100));
        md.append(String.format("- æœ€ç»ˆå†…å­˜ä½¿ç”¨ç‡: **%.1f%%**\n\n",
                (double) finalResource.memoryUsed / finalResource.memoryTotal * 100));
â€‹
        md.append("### 4.3 æ£€ç´¢ç‰¹ç‚¹åˆ†æ\n\n");
        md.append("**å‘é‡æœç´¢**\n");
        md.append("- ä¼˜ç‚¹: èƒ½å¤Ÿç†è§£è¯­ä¹‰ï¼Œæ‰¾åˆ°è¯­ä¹‰ç›¸å…³ä½†å…³é”®è¯ä¸åŒ¹é…çš„å†…å®¹\n");
        md.append("- ç¼ºç‚¹: å¯èƒ½å¿½ç•¥ç²¾ç¡®çš„å…³é”®è¯åŒ¹é…\n");
        md.append("- é€‚ç”¨åœºæ™¯: è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢ã€æ¦‚å¿µæ£€ç´¢\n\n");
â€‹
        md.append("**BM25æœç´¢**\n");
        md.append("- ä¼˜ç‚¹: ç²¾ç¡®åŒ¹é…å…³é”®è¯ï¼Œé€‚åˆæŸ¥æ‰¾ç‰¹å®šæœ¯è¯­\n");
        md.append("- ç¼ºç‚¹: æ— æ³•ç†è§£è¯­ä¹‰ï¼Œå¯èƒ½é”™è¿‡ç›¸å…³ä½†ç”¨è¯ä¸åŒçš„å†…å®¹\n");
        md.append("- é€‚ç”¨åœºæ™¯: å…³é”®è¯æœç´¢ã€æœ¯è¯­æŸ¥æ‰¾\n\n");
â€‹
        md.append("**æ··åˆæœç´¢**\n");
        md.append("- ä¼˜ç‚¹: ç»“åˆè¯­ä¹‰ç†è§£å’Œå…³é”®è¯åŒ¹é…ï¼Œæä¾›æ›´å…¨é¢çš„ç»“æœ\n");
        md.append("- ç¼ºç‚¹: å“åº”æ—¶é—´è¾ƒé•¿ï¼ˆéœ€è¦æ‰§è¡Œä¸¤æ¬¡æœç´¢ï¼‰\n");
        md.append("- é€‚ç”¨åœºæ™¯: éœ€è¦ç»¼åˆè€ƒè™‘è¯­ä¹‰å’Œå…³é”®è¯çš„å¤æ‚æŸ¥è¯¢\n\n");
â€‹
        md.append("### 4.4 æœ‰å…¨æ–‡æ£€ç´¢ vs æ— å…¨æ–‡æ£€ç´¢å¯¹æ¯”\n\n");
â€‹
        md.append("**èµ„æºå ç”¨å¯¹æ¯”**\n\n");
        md.append("| å¯¹æ¯”é¡¹ | ä»…å‘é‡æ£€ç´¢ | å‘é‡+å…¨æ–‡æ£€ç´¢ | å·®å¼‚åˆ†æ |\n");
        md.append("|--------|-----------|--------------|----------|\n");
        md.append("| **å†…å­˜å ç”¨** | ä¸­ç­‰ï¼ˆå‘é‡ç´¢å¼•ï¼‰ | ä¸­ç­‰+ä½ï¼ˆå‘é‡+å€’æ’ç´¢å¼•ï¼‰ | å¢åŠ çº¦10-20% |\n");
        md.append("| **ç£ç›˜å ç”¨** | é«˜ï¼ˆå‘é‡æ•°æ®+ç´¢å¼•ï¼‰ | é«˜+è¾ƒä½ï¼ˆå‘é‡+ç¨€ç–å‘é‡ï¼‰ | å¢åŠ çº¦5-15% |\n");
        md.append("| **ç´¢å¼•å¤§å°** | å¤§ï¼ˆç¨ å¯†å‘é‡ï¼‰ | å¤§+å°ï¼ˆç¨ å¯†+ç¨€ç–å‘é‡ï¼‰ | ç¨€ç–å‘é‡çº¦1-5% |\n");
        md.append("| **æŸ¥è¯¢é€Ÿåº¦** | å¿« | æ›´å¿«ï¼ˆBM25ï¼‰/ æ··åˆç¨æ…¢ | BM25æœ€å¿«ï¼Œæ··åˆå åŠ è€—æ—¶ |\n");
        md.append("| **æ£€ç´¢ç²¾åº¦** | è¯­ä¹‰ç›¸å…³ | å…³é”®è¯ç²¾ç¡®+è¯­ä¹‰ | æ··åˆæ£€ç´¢å¬å›ç‡æœ€é«˜ |\n\n");
â€‹
        md.append("**å…³é”®å·®å¼‚è¯´æ˜**\n\n");
        md.append("1. **å­˜å‚¨æˆæœ¬**\n");
        md.append("   - **æ— å…¨æ–‡æ£€ç´¢**: ä»…å­˜å‚¨ç¨ å¯†å‘é‡ï¼ˆé€šå¸¸æ¯ä¸ªæ–‡æ¡£768-1536ç»´float32ï¼‰\n");
        md.append("   - **æœ‰å…¨æ–‡æ£€ç´¢**: é¢å¤–å­˜å‚¨ç¨€ç–å‘é‡ï¼ˆBM25å€’æ’ç´¢å¼•ï¼‰ï¼Œé€šå¸¸åªå ç¨ å¯†å‘é‡çš„1-5%\n");
        md.append("   - **ç»“è®º**: å…¨æ–‡æ£€ç´¢çš„é¢å¤–å­˜å‚¨æˆæœ¬å¾ˆä½ï¼Œä½†æ˜¾è‘—æå‡å…³é”®è¯æ£€ç´¢èƒ½åŠ›\n\n");
â€‹
        md.append("2. **å†…å­˜å ç”¨**\n");
        md.append("   - **æ— å…¨æ–‡æ£€ç´¢**: å‘é‡ç´¢å¼•éœ€è¦å¸¸é©»å†…å­˜ä»¥ä¿è¯æŸ¥è¯¢é€Ÿåº¦\n");
        md.append("   - **æœ‰å…¨æ–‡æ£€ç´¢**: BM25å€’æ’ç´¢å¼•å†…å­˜å ç”¨æå°ï¼ˆé€šå¸¸æ˜¯å‘é‡ç´¢å¼•çš„1/10åˆ°1/100ï¼‰\n");
        md.append("   - **ç»“è®º**: å¢åŠ å…¨æ–‡æ£€ç´¢å¯¹å†…å­˜å‹åŠ›å½±å“æœ‰é™\n\n");
â€‹
        md.append("3. **æŸ¥è¯¢æ€§èƒ½**\n");
        md.append("   - **æ— å…¨æ–‡æ£€ç´¢**: å•ä¸€å‘é‡æ£€ç´¢ï¼Œå“åº”æ—¶é—´ç¨³å®š\n");
        md.append("   - **æœ‰å…¨æ–‡æ£€ç´¢**: \n");
        md.append("     - çº¯BM25æŸ¥è¯¢: é€Ÿåº¦å¿«3-10å€\n");
        md.append("     - æ··åˆæŸ¥è¯¢: è€—æ—¶çº¦ä¸ºä¸¤è€…ä¹‹å’Œï¼Œä½†ç»“æœè´¨é‡æœ€ä¼˜\n");
        md.append("   - **ç»“è®º**: å¯æ ¹æ®éœ€æ±‚çµæ´»é€‰æ‹©æ£€ç´¢æ–¹å¼\n\n");
â€‹
        md.append("4. **æ£€ç´¢è´¨é‡**\n");
        md.append("   - **æ— å…¨æ–‡æ£€ç´¢**: å–„äºè¯­ä¹‰ç†è§£ï¼Œå¼±äºç²¾ç¡®åŒ¹é…\n");
        md.append("   - **æœ‰å…¨æ–‡æ£€ç´¢**: æ—¢èƒ½è¯­ä¹‰ç†è§£åˆèƒ½å…³é”®è¯åŒ¹é…ï¼Œæ··åˆæ£€ç´¢æ•ˆæœæœ€ä¼˜\n");
        md.append("   - **ç»“è®º**: å…¨æ–‡æ£€ç´¢æ˜¾è‘—æå‡æ•´ä½“æ£€ç´¢è´¨é‡å’Œå¬å›ç‡\n\n");
â€‹
        md.append("**æ¨èç­–ç•¥**\n\n");
        md.append("- **èµ„æºå……è¶³åœºæ™¯**: ä¼˜å…ˆä½¿ç”¨æ··åˆæ£€ç´¢ï¼Œè·å¾—æœ€ä½³æ£€ç´¢æ•ˆæœ\n");
        md.append("- **èµ„æºå—é™åœºæ™¯**: æ ¹æ®æŸ¥è¯¢ç±»å‹åŠ¨æ€é€‰æ‹©\n");
        md.append("  - å…³é”®è¯æŸ¥è¯¢ â†’ BM25æ£€ç´¢\n");
        md.append("  - è¯­ä¹‰æŸ¥è¯¢ â†’ å‘é‡æ£€ç´¢\n");
        md.append("  - ç»¼åˆæŸ¥è¯¢ â†’ æ··åˆæ£€ç´¢\n");
        md.append("- **æˆæœ¬æ•æ„Ÿåœºæ™¯**: é¢å¤–å­˜å‚¨å’Œå†…å­˜æˆæœ¬å¾ˆä½ï¼Œå»ºè®®é»˜è®¤å¼€å¯å…¨æ–‡æ£€ç´¢\n\n");
â€‹
        // å†™å…¥æ–‡ä»¶
        try {
            java.nio.file.Files.write(
                java.nio.file.Paths.get("search_comparison_report.md"),
                md.toString().getBytes(java.nio.charset.StandardCharsets.UTF_8)
            );
        } catch (IOException e) {
            System.err.println("å†™å…¥æŠ¥å‘Šæ–‡ä»¶å¤±è´¥: " + e.getMessage());
            e.printStackTrace();
        }
    }
â€‹
    /**
     * è½¬ä¹‰Markdownç‰¹æ®Šå­—ç¬¦
     */
    private static String escapeMarkdown(String text) {
        return text.replace("|", "\\|")
                   .replace("*", "\\*")
                   .replace("_", "\\_")
                   .replace("#", "\\#")
                   .replace("`", "\\`")
                   .replace("[", "\\[")
                   .replace("]", "\\]")
                   .replace("(", "\\(")
                   .replace(")", "\\)")
                   .replace("<", "\\<")
                   .replace(">", "\\>");
    }
    
    /**
     * å‘é‡æœç´¢
     */
    private List<Map<String, Object>> vectorSearch(MilvusClientV2 client, String queryText, int topK) throws Exception {
        // ç”ŸæˆæŸ¥è¯¢å‘é‡
        List<List<Float>> queryVectors = generateEmbedding(Collections.singletonList(queryText));
â€‹
        // è®¾ç½®æœç´¢å‚æ•°
        Map<String, Object> searchParams = new HashMap<>();
        searchParams.put("metric_type", "IP");
        searchParams.put("params", "{\"nprobe\": 16}");
â€‹
        FloatVec queryVector = new FloatVec(queryVectors.get(0));
â€‹
        // æ‰§è¡Œå‘é‡æœç´¢
        SearchReq searchReq = SearchReq.builder()
                .collectionName("hybrid_search_collection")
                .data(Collections.singletonList(queryVector))
                .annsField("embedding")
                .topK(topK)
                .searchParams(searchParams)
                .outputFields(Arrays.asList("id", "title", "content"))
                .build();
â€‹
        SearchResp searchResp = client.search(searchReq);
â€‹
        // æ ¼å¼åŒ–ç»“æœ
        List<Map<String, Object>> results = new ArrayList<>();
        List<List<SearchResp.SearchResult>> searchResults = searchResp.getSearchResults();
        for (List<SearchResp.SearchResult> resultList : searchResults) {
            for (SearchResp.SearchResult result : resultList) {
                Map<String, Object> resultItem = new HashMap<>();
                resultItem.put("id", result.getId());
                resultItem.put("title", result.getEntity().get("title"));
                resultItem.put("content", result.getEntity().get("content"));
                resultItem.put("score", result.getScore());
                resultItem.put("search_type", "vector");
                results.add(resultItem);
            }
        }
â€‹
        return results;
    }
â€‹
//    public static void main(String[] args) throws Exception {
//        MilvusClientV2 milvusClientV2 = connect2milvus();
//        List<Map<String, Object>> mapList = bm25Search(milvusClientV2, "å»ºè®¾å…¨å›½ç»Ÿä¸€å¤§å¸‚åœºçš„æ ¸å¿ƒç›®æ ‡æ˜¯ä»€ä¹ˆ", 5);
//        System.out.println(mapList);
//        QueryReq queryReq = QueryReq.builder()
//                .collectionName("hybrid_search_collection")
//                .filter("id != ''") // éšä¾¿æŸ¥ä¸€æ¡
//                .outputFields(Arrays.asList("id", "content"))
//                .limit(1)
//                .build();
//
//        QueryResp queryResp = milvusClientV2.query(queryReq);
//        System.out.println(queryResp.getQueryResults());
//    }
    /**
     * BM25å…¨æ–‡æœç´¢
     */
    private static List<Map<String, Object>> bm25Search(MilvusClientV2 client, String queryText, int topK) throws Exception {
        // è®¾ç½®BM25æœç´¢å‚æ•°
        Map<String, Object> searchParams = new HashMap<>();
        searchParams.put("metric_type", "BM25");
        searchParams.put("params", "{}");
        
        // æ‰§è¡ŒBM25æœç´¢
        SearchReq searchReq = SearchReq.builder()
                .collectionName("hybrid_search_collection")
                .data(Collections.singletonList(new io.milvus.v2.service.vector.request.data.EmbeddedText(queryText)))
                .annsField("content_sparse")
                .topK(topK)
                .searchParams(searchParams)
                .outputFields(Arrays.asList("id", "title", "content"))
                .build();
        
        SearchResp searchResp = client.search(searchReq);
        
        // æ ¼å¼åŒ–ç»“æœ
        List<Map<String, Object>> results = new ArrayList<>();
        List<List<SearchResp.SearchResult>> searchResults = searchResp.getSearchResults();
        for (List<SearchResp.SearchResult> resultList : searchResults) {
            for(SearchResp.SearchResult result : resultList) {
                Map<String, Object> resultItem = new HashMap<>();
                resultItem.put("id", result.getId());
                resultItem.put("title", result.getEntity().get("title"));
                resultItem.put("content", result.getEntity().get("content"));
                resultItem.put("score", result.getScore());
                resultItem.put("search_type", "bm25");
                results.add(resultItem);
            }
        }
        
        return results;
    }
    
    /**
     * æ··åˆæœç´¢ï¼ˆå‘é‡+BM25ï¼‰
     */
    /**
     * æ··åˆæœç´¢ï¼ˆå‘é‡+BM25ï¼‰
     * ä¿®æ­£åï¼šä½¿ç”¨ MilvusClientV2 å¯¹åº”çš„ Request ç±»
     */
    private List<Map<String, Object>> hybridSearch(MilvusClientV2 client, String queryText,
                                                   float vectorWeight, float bm25Weight, int topK) throws Exception {
        // 1. ç”ŸæˆæŸ¥è¯¢å‘é‡ (Dense Vector)
        List<List<Float>> queryVectors = generateEmbedding(Collections.singletonList(queryText));
        FloatVec vectorData = new FloatVec(queryVectors.get(0));
â€‹
        // 2. æ„å»ºå‘é‡æœç´¢å­è¯·æ±‚ (AnnSearchReq)
        Map<String, Object> vecParams = new HashMap<>();
        vecParams.put("nprobe", 16);
â€‹
        AnnSearchReq vectorReq = AnnSearchReq.builder()
                .vectorFieldName("embedding")
                .vectors(Collections.singletonList(vectorData))
                .metricType(IndexParam.MetricType.IP)
                .params(new Gson().toJson(vecParams)) // V2 é€šå¸¸æ¥å— JSON å­—ç¬¦ä¸²ä½œä¸ºå‚æ•°
                .topK(topK)
                .build();
â€‹
        // 3. æ„å»º BM25 æœç´¢å­è¯·æ±‚ (AnnSearchReq)
        // ä½¿ç”¨ EmbeddedText åŒ…è£…æ–‡æœ¬ï¼ŒMilvus ä¼šè‡ªåŠ¨å¤„ç†ä¸ºç¨€ç–å‘é‡ï¼ˆå‰ææ˜¯ Schema é…ç½®æ­£ç¡®ï¼‰
        EmbeddedText bm25Data = new EmbeddedText(queryText);
â€‹
        AnnSearchReq bm25Req = AnnSearchReq.builder()
                .vectorFieldName("content_sparse") // ä¿®æ­£å­—æ®µåï¼Œä¸ bm25Search æ–¹æ³•ä¿æŒä¸€è‡´
                .vectors(Collections.singletonList(bm25Data))
                .metricType(IndexParam.MetricType.BM25)
                .params("{}")
                .topK(topK)
                .build();
â€‹
        // 4. é…ç½®é‡æ’åºå™¨ (WeightedRanker)
        // æ ¹æ®ä¼ å…¥çš„æƒé‡å‚æ•°é…ç½®
        BaseRanker ranker = new WeightedRanker(Arrays.asList(vectorWeight, bm25Weight));
â€‹
        // 5. æ„å»ºæ··åˆæœç´¢è¯·æ±‚ (HybridSearchReq)
        HybridSearchReq hybridReq = HybridSearchReq.builder()
                .collectionName("hybrid_search_collection")
                .searchRequests(Arrays.asList(vectorReq, bm25Req))
                .ranker(ranker)
                .topK(topK)
                .outFields(Arrays.asList("id", "title", "content"))
                .build();
â€‹
        // 6. æ‰§è¡Œæ··åˆæœç´¢
        SearchResp searchResp = client.hybridSearch(hybridReq);
â€‹
        // 7. è§£æç»“æœ
        List<Map<String, Object>> results = new ArrayList<>();
        List<List<SearchResp.SearchResult>> searchResults = searchResp.getSearchResults();
â€‹
        if (searchResults != null && !searchResults.isEmpty()) {
            // è·å–ç¬¬ä¸€æ¡æŸ¥è¯¢ï¼ˆæˆ‘ä»¬åªæŸ¥äº†ä¸€ä¸ª queryTextï¼‰çš„ç»“æœåˆ—è¡¨
            for (SearchResp.SearchResult result : searchResults.get(0)) {
                Map<String, Object> resultItem = new HashMap<>();
                resultItem.put("id", result.getId());
                resultItem.put("score", result.getScore());
â€‹
                // V2 SDK è¿”å›çš„ Entity æ˜¯ Map<String, Object>
                if (result.getEntity().containsKey("title")) {
                    resultItem.put("title", result.getEntity().get("title"));
                }
                if (result.getEntity().containsKey("content")) {
                    resultItem.put("content", result.getEntity().get("content"));
                }
â€‹
                resultItem.put("search_type", "hybrid");
                results.add(resultItem);
            }
        }
â€‹
        return results;
    }
â€‹
â€‹
â€‹
  }
</details>

Javaä»£ç æ ¸å¿ƒè¯´æ˜ï¼š

å‘é‡æœç´¢ï¼ˆvectorSearchï¼‰

ä½¿ç”¨FloatVecåŒ…è£…æŸ¥è¯¢å‘é‡

é€šè¿‡SearchReq.builder()æ„å»ºæœç´¢è¯·æ±‚

è¿”å›åŒ…å«IDã€æ ‡é¢˜ã€å†…å®¹å’Œåˆ†æ•°çš„ç»“æœåˆ—è¡¨

BM25æœç´¢ï¼ˆbm25Searchï¼‰

ä½¿ç”¨EmbeddedTextåŒ…è£…åŸå§‹æŸ¥è¯¢æ–‡æœ¬

Milvusè‡ªåŠ¨åº”ç”¨BM25å‡½æ•°ç”Ÿæˆç¨€ç–å‘é‡

æ‰§è¡Œå…³é”®è¯åŒ¹é…å¹¶è¿”å›ç›¸å…³æ€§åˆ†æ•°

æ··åˆæœç´¢ï¼ˆhybridSearchï¼‰

æ„å»ºä¸¤ä¸ªAnnSearchReqï¼šä¸€ä¸ªç”¨äºå‘é‡æœç´¢ï¼Œä¸€ä¸ªç”¨äºBM25

ä½¿ç”¨WeightedRankeråŠ æƒèåˆä¸¤ç§ç»“æœ

é€šè¿‡HybridSearchReqæ‰§è¡Œæ··åˆæŸ¥è¯¢

ä¸Pythonç‰ˆæœ¬çš„å·®å¼‚ï¼š

Javaç‰ˆæœ¬ä½¿ç”¨Milvus V2 SDKï¼ŒAPIè®¾è®¡æ›´ç¬¦åˆJavaä¹ æƒ¯

ä½¿ç”¨Builderæ¨¡å¼æ„å»ºè¯·æ±‚å¯¹è±¡

éœ€è¦æ‰‹åŠ¨å¤„ç†JSONåºåˆ—åŒ–ï¼ˆä½¿ç”¨Gsonåº“ï¼‰

èµ„æºç®¡ç†é€šè¿‡try-finallyç¡®ä¿å®¢æˆ·ç«¯å…³é—­

4.5.4 generateEmbeddingæ–¹æ³•å®ç°
Javaç‰ˆæœ¬åŒæ ·éœ€è¦å®ç°å‘é‡åŒ–æ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯å‡ ç§å®ç°æ–¹å¼ï¼š

æ–¹å¼1ï¼šè°ƒç”¨æœ¬åœ°LLMå®¢æˆ·ç«¯ï¼ˆè‡ªå·±éƒ¨ç½²ï¼‰

private static List<List<Float>> generateEmbedding(List<String> texts) {
    // åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    LLMClient llmClient = LLMClient.getInstance();
â€‹
    // é…ç½®APIå¯†é’¥å’ŒURL
    System.setProperty("llm.client.key", "your-api-key");
    System.setProperty("llm.client.secret", "your-secret");
    System.setProperty("llm.client.url", "https://api.example.com");
â€‹
    // è°ƒç”¨æ‰¹é‡å‘é‡åŒ–æ¥å£
    EmbeddingStringResult result = llmClient.createEmbedding(
        "/llm-api/embedding/create_batch",
        texts
    );
â€‹
    // è¿”å›å‘é‡åˆ—è¡¨
    return result.getData();
}
æ–¹å¼2ï¼šè°ƒç”¨REST API

private static List<List<Float>> generateEmbedding(List<String> texts) {
    try {
        // æ„å»ºè¯·æ±‚ä½“
        JsonObject requestBody = new JsonObject();
        JsonArray textsArray = new JsonArray();
        texts.forEach(textsArray::add);
        requestBody.add("texts", textsArray);
        requestBody.addProperty("model", "embedding-model");
â€‹
        // å‘é€HTTPè¯·æ±‚
        HttpRequest request = HttpRequest.newBuilder()
            .uri(URI.create("https://api.example.com/embeddings"))
            .header("Content-Type", "application/json")
            .header("Authorization", "Bearer your-api-key")
            .POST(HttpRequest.BodyPublishers.ofString(requestBody.toString()))
            .build();
â€‹
        HttpClient client = HttpClient.newHttpClient();
        HttpResponse<String> response = client.send(
            request,
            HttpResponse.BodyHandlers.ofString()
        );
â€‹
        // è§£æå“åº”
        JsonObject responseBody = JsonParser.parseString(response.body()).getAsJsonObject();
        JsonArray embeddings = responseBody.getAsJsonArray("embeddings");
â€‹
        // è½¬æ¢ä¸ºList<List<Float>>
        List<List<Float>> result = new ArrayList<>();
        for (JsonElement elem : embeddings) {
            JsonArray vector = elem.getAsJsonArray();
            List<Float> vec = new ArrayList<>();
            for (JsonElement val : vector) {
                vec.add(val.getAsFloat());
            }
            result.add(vec);
        }
â€‹
        return result;
â€‹
    } catch (Exception e) {
        throw new RuntimeException("Failed to generate embeddings", e);
    }
}
4.6 è§‚å¯Ÿç»“æœ
æ‰§è¡Œæ£€ç´¢ä»£ç åï¼Œä¼šç”Ÿæˆä¸€ä¸ªåä¸ºsearch_comparison_report.mdçš„Markdownæ ¼å¼æŠ¥å‘Šæ–‡ä»¶ã€‚è¯¥æ–‡ä»¶åŒ…å«è¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”å’Œç»“æœåˆ†æã€‚

4.6.1 æŠ¥å‘Šç»“æ„
ç”Ÿæˆçš„æŠ¥å‘ŠåŒ…å«ä»¥ä¸‹å››ä¸ªä¸»è¦éƒ¨åˆ†ï¼š

ä¸€ã€ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

å†…å­˜ä½¿ç”¨æƒ…å†µï¼šæ˜¾ç¤ºå®¢æˆ·ç«¯è„šæœ¬çš„å†…å­˜å ç”¨å˜åŒ–ï¼ˆåˆå§‹/æœ€ç»ˆ/å˜åŒ–é‡ï¼‰

ç£ç›˜ä½¿ç”¨æƒ…å†µï¼šè®°å½•ç£ç›˜å¯ç”¨ç©ºé—´çš„å˜åŒ–

ç†è®ºèµ„æºå ç”¨å¯¹æ¯”ï¼šå¯¹æ¯”ä¸‰ç§æ£€ç´¢æ–¹å¼åœ¨æœåŠ¡ç«¯çš„èµ„æºå ç”¨ç‰¹ç‚¹

äºŒã€æ€»ä½“æ€§èƒ½ç»Ÿè®¡

æ€§èƒ½æ±‡æ€»ï¼šå±•ç¤ºæ‰€æœ‰æŸ¥è¯¢çš„æ€»è€—æ—¶ã€å¹³å‡è€—æ—¶å’Œç›¸å¯¹é€Ÿåº¦

æ€§èƒ½åˆ†æï¼šå¯¹æ¯”ä¸åŒæ£€ç´¢æ–¹å¼çš„æ€§èƒ½å·®å¼‚

å„æŸ¥è¯¢æ€§èƒ½è¯¦æƒ…ï¼šåˆ—å‡ºæ¯ä¸ªæŸ¥è¯¢çš„å…·ä½“è€—æ—¶æ•°æ®

ä¸‰ã€æœç´¢ç»“æœå¯¹æ¯”

æ¯ä¸ªæŸ¥è¯¢çš„è¯¦ç»†å¯¹æ¯”ï¼šåŒ…å«Top 5ç»“æœçš„ä¸‰ç§æ£€ç´¢åˆ†æ•°å¯¹æ¯”

Top 3è¯¦ç»†å¯¹æ¯”ï¼šå±•ç¤ºå‰3åç»“æœçš„å®Œæ•´ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€å†…å®¹ã€åˆ†æ•°ï¼‰

å››ã€æ€»ç»“

æ€§èƒ½æ€»ç»“ï¼šå¹³å‡å“åº”æ—¶é—´ç»Ÿè®¡

èµ„æºä½¿ç”¨æ€»ç»“ï¼šå†…å­˜å’Œç£ç›˜ä½¿ç”¨æƒ…å†µ

æ£€ç´¢ç‰¹ç‚¹åˆ†æï¼šä¸‰ç§æ£€ç´¢æ–¹å¼çš„ä¼˜ç¼ºç‚¹å¯¹æ¯”

æœ‰æ— å…¨æ–‡æ£€ç´¢å¯¹æ¯”ï¼šè¯¦ç»†çš„èµ„æºå ç”¨å’Œæ€§èƒ½å¯¹æ¯”

4.6.2 å…³é”®æŒ‡æ ‡è§£è¯»
1. æœç´¢åˆ†æ•°ï¼ˆscoreï¼‰

å‘é‡æœç´¢åˆ†æ•°ï¼šå†…ç§¯ï¼ˆIPï¼‰å€¼ï¼ŒèŒƒå›´é€šå¸¸åœ¨-1åˆ°1ä¹‹é—´ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼

BM25åˆ†æ•°ï¼šåŸºäºè¯é¢‘å’Œæ–‡æ¡£é¢‘ç‡çš„ç›¸å…³æ€§åˆ†æ•°ï¼Œé€šå¸¸ä¸ºæ­£æ•°

æ··åˆæœç´¢åˆ†æ•°ï¼šåŠ æƒèåˆåçš„ç»¼åˆåˆ†æ•°ï¼ŒåŒæ—¶åæ˜ è¯­ä¹‰å’Œå…³é”®è¯ç›¸å…³æ€§

2. æ€§èƒ½æŒ‡æ ‡

ç›¸å¯¹é€Ÿåº¦ï¼šä»¥å‘é‡æœç´¢ä¸ºåŸºå‡†ï¼Œå…¶ä»–æ–¹å¼çš„åŠ é€Ÿæ¯”

å¹³å‡è€—æ—¶ï¼šå•æ¬¡æŸ¥è¯¢çš„å¹³å‡å“åº”æ—¶é—´

èµ„æºå ç”¨ï¼šå†…å­˜å’Œç£ç›˜çš„ä½¿ç”¨æƒ…å†µ

3. ç»“æœè´¨é‡è¯„ä¼°
é€šè¿‡å¯¹æ¯”ä¸‰ç§æ£€ç´¢æ–¹å¼è¿”å›çš„ç»“æœï¼Œå¯ä»¥è§‚å¯Ÿåˆ°ï¼š

å‘é‡æœç´¢ï¼šå€¾å‘äºè¿”å›è¯­ä¹‰ç›¸å…³çš„æ–‡æ¡£ï¼Œå³ä½¿å…³é”®è¯ä¸å®Œå…¨åŒ¹é…

BM25æœç´¢ï¼šä¼˜å…ˆè¿”å›åŒ…å«æŸ¥è¯¢å…³é”®è¯çš„æ–‡æ¡£

æ··åˆæœç´¢ï¼šç»“åˆä¸¤è€…ä¼˜åŠ¿ï¼Œé€šå¸¸èƒ½è·å¾—æ›´å¥½çš„å¬å›ç‡

4.6.3 ç»“æœåˆ†æå»ºè®®
æƒé‡è°ƒä¼˜ï¼šæ ¹æ®ä¸šåŠ¡ç‰¹ç‚¹è°ƒæ•´æ··åˆæœç´¢çš„æƒé‡å‚æ•°

å…³é”®è¯é‡è¦çš„åœºæ™¯ï¼šæé«˜BM25æƒé‡ï¼ˆå¦‚0.3å‘é‡ + 0.7 BM25ï¼‰

è¯­ä¹‰ç†è§£é‡è¦çš„åœºæ™¯ï¼šæé«˜å‘é‡æƒé‡ï¼ˆå¦‚0.7å‘é‡ + 0.3 BM25ï¼‰

æ€§èƒ½ä¼˜åŒ–ï¼š

å¦‚æœBM25é€Ÿåº¦æ˜æ˜¾å¿«äºå‘é‡æœç´¢ï¼Œå¯ä»¥è€ƒè™‘å…ˆç”¨BM25ç¼©å°èŒƒå›´ï¼Œå†åšå‘é‡æ£€ç´¢

æ ¹æ®èµ„æºæƒ…å†µé€‰æ‹©åˆé€‚çš„ç´¢å¼•ç±»å‹å’Œå‚æ•°

ç»“æœè´¨é‡ï¼š

è§‚å¯Ÿä¸åŒæŸ¥è¯¢ç±»å‹ä¸‹ä¸‰ç§æ£€ç´¢æ–¹å¼çš„è¡¨ç°å·®å¼‚

åˆ†ææ£€ç´¢å¤±è´¥æˆ–ç»“æœä¸ç†æƒ³çš„æŸ¥è¯¢ï¼Œä¼˜åŒ–æŸ¥è¯¢æ–‡æœ¬æˆ–æ•°æ®é¢„å¤„ç†

æ€»ç»“
é€šè¿‡æœ¬ç« èŠ‚çš„å®æˆ˜æ¼”ç»ƒï¼Œæˆ‘ä»¬å®Œæˆäº†ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªåŸºäºMilvusçš„å‘é‡+BM25æ··åˆæœç´¢ç³»ç»Ÿçš„å…¨è¿‡ç¨‹ã€‚

å¸¸è§é—®é¢˜è§£å†³
é—®é¢˜	å¯èƒ½åŸå› 	è§£å†³æ–¹æ¡ˆ
æŸ¥è¯¢ç»“æœä¸ºç©º	å‘é‡ç»´åº¦ä¸åŒ¹é…	æ£€æŸ¥embeddingæ¨¡å‹çš„è¾“å‡ºç»´åº¦
BM25æ— ç»“æœ	æ–‡æœ¬æœªæ­£ç¡®åˆ†è¯	æ£€æŸ¥analyzeré…ç½®ï¼Œç¡®ä¿ä½¿ç”¨jiebaåˆ†è¯
æ··åˆæœç´¢æŠ¥é”™	æƒé‡å‚æ•°é”™è¯¯	ç¡®ä¿ä¸¤ä¸ªæƒé‡ä¹‹å’Œä¸ä¸º0ï¼Œé€šå¸¸è®¾ä¸º0.5å’Œ0.5
Attuæ— æ³•æŸ¥çœ‹æ•°æ®	ç¨€ç–å‘é‡æ˜¾ç¤ºé™åˆ¶	ä½¿ç”¨ä»£ç æŸ¥è¯¢è€ŒéAttuç•Œé¢
å†…å­˜å ç”¨è¿‡é«˜	æ•°æ®é›†è¿‡å¤§	è€ƒè™‘ä½¿ç”¨IVFç´¢å¼•è€ŒéFLATç´¢å¼•
è¿›é˜¶å­¦ä¹ æ–¹å‘
1. é«˜çº§ç´¢å¼•ä¼˜åŒ–

è°ƒç ”IVF_FLATçš„nprobeå‚æ•°å¯¹æ€§èƒ½çš„å½±å“

å­¦ä¹ HNSWç´¢å¼•çš„æ„å»ºå‚æ•°ï¼ˆMã€efConstructionï¼‰

ç†è§£ä¸åŒç´¢å¼•ç±»å‹çš„é€‚ç”¨åœºæ™¯å’Œæ€§èƒ½ç‰¹ç‚¹

2. BM25å‚æ•°è°ƒä¼˜

è°ƒæ•´BM25çš„k1å’Œbå‚æ•°ä»¥æ”¹å–„æ£€ç´¢æ•ˆæœ

å°è¯•ä¸åŒçš„åˆ†è¯å™¨ï¼ˆstandardã€jiebaã€è‡ªå®šä¹‰è¯å…¸ï¼‰

ç†è§£BM25ç®—æ³•åŸç†å’Œå‚æ•°å½±å“

3. æ··åˆæ£€ç´¢ç­–ç•¥

å­¦ä¹ æ›´å¤æ‚çš„èåˆç­–ç•¥ï¼ˆRRFã€Reciprocal Rank Fusionï¼‰

å®ç°åŠ¨æ€æƒé‡è°ƒæ•´æœºåˆ¶

æ¢ç´¢é‡æ’åºï¼ˆrerankï¼‰æŠ€æœ¯æå‡æœ€ç»ˆç»“æœè´¨é‡

4. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

Milvusé›†ç¾¤éƒ¨ç½²å’Œè´Ÿè½½å‡è¡¡

ç›‘æ§å‘Šè­¦ç³»ç»Ÿæ­å»º

æ•°æ®å¤‡ä»½å’Œç¾å¤‡æ–¹æ¡ˆ

5. æ€§èƒ½è°ƒä¼˜

æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§ï¼ˆåˆ†åŒºé”®ã€è¿‡æ»¤è¡¨è¾¾å¼ï¼‰

ç¼“å­˜ç­–ç•¥åº”ç”¨

å¹¶å‘æŸ¥è¯¢å¤„ç†

ç»“è¯­
æœ¬ç« èŠ‚é€šè¿‡æ”¿åŠ¡é—®ç­”é¢†åŸŸçš„å®æˆ˜æ¡ˆä¾‹ï¼Œå¸®åŠ©å¤§å®¶æŒæ¡äº†Milvuså‘é‡æ•°æ®åº“çš„æ ¸å¿ƒåŠŸèƒ½å’Œæ··åˆæ£€ç´¢æŠ€æœ¯ã€‚ä»ç†è®ºåˆ°å®è·µï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°å­¦ä¹ äº†å¦‚ä½•æ„å»ºä¸€ä¸ªé«˜è´¨é‡çš„æ£€ç´¢ç³»ç»Ÿã€‚

æ··åˆæ£€ç´¢æŠ€æœ¯ç»“åˆäº†å‘é‡æœç´¢çš„è¯­ä¹‰ç†è§£èƒ½åŠ›å’ŒBM25çš„å…³é”®è¯ç²¾ç¡®åŒ¹é…èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ£€ç´¢ç³»ç»Ÿçš„å¬å›ç‡å’Œç”¨æˆ·ä½“éªŒã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œéœ€è¦æ ¹æ®å…·ä½“ä¸šåŠ¡åœºæ™¯å’Œæ•°æ®ç‰¹ç‚¹ï¼Œé€‰æ‹©åˆé€‚çš„æ£€ç´¢ç­–ç•¥å’Œå‚æ•°é…ç½®ã€‚

å¸Œæœ›æœ¬ç« èŠ‚çš„å†…å®¹èƒ½å¤Ÿå¸®åŠ©å¤§å®¶åœ¨å®é™…é¡¹ç›®ä¸­æ›´å¥½åœ°åº”ç”¨Milvusï¼Œæ„å»ºé«˜æ•ˆã€æ™ºèƒ½çš„æ£€ç´¢ç³»ç»Ÿï¼