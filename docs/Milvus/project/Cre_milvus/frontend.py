import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import time
import json

# python -m streamlit run frontend.py
st.set_page_config(page_title="DataWhale-easyVectorDB", layout="wide", page_icon="ğŸ”")
st.title("ğŸ” DataWhale-easyVectorDB")
st.markdown("---")

# æ„å»ºåˆ†å—é…ç½®çš„è¾…åŠ©å‡½æ•°
def build_chunking_config(strategy, chunk_length, ppl_threshold, confidence_threshold, similarity_threshold, overlap):
    """æ ¹æ®ç­–ç•¥æ„å»ºåˆ†å—é…ç½®"""
    config = {
        "strategy": strategy,
        "chunk_length": chunk_length,
        "language": "zh"
    }
    
    if strategy == "meta_ppl":
        config["ppl_threshold"] = ppl_threshold
    elif strategy == "msp":
        config["confidence_threshold"] = confidence_threshold
    elif strategy == "semantic":
        config["similarity_threshold"] = similarity_threshold
        config["min_chunk_size"] = 100
        config["max_chunk_size"] = chunk_length
    elif strategy == "traditional":
        config["overlap"] = overlap
    
    return config

# è‡ªå®šä¹‰æŒ‡æ ‡å¡ç‰‡æ ·å¼
def style_metric_cards(background_color="#FFFFFF", border_left_color="#0078ff"):
    st.markdown(
        f"""
        <style>
        div[data-testid="metric-container"] {{
            background-color: {background_color};
            border: 1px solid #e0e0e0;
            border-radius: 10px;
            padding: 15px;
            border-left: 5px solid {border_left_color};
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            transition: transform 0.2s;
        }}
        div[data-testid="metric-container"]:hover {{
            transform: translateY(-3px);
            box-shadow: 0 6px 8px rgba(0,0,0,0.1);
        }}
        div[data-testid="metric-container"] > label[data-testid="stMetricLabel"] {{
            color: #555;
            font-weight: 600;
        }}
        div[data-testid="metric-container"] > div[data-testid="stMetricValue"] {{
            color: #0078ff;
            font-size: 1.8rem;
            font-weight: 700;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "config" not in st.session_state:
    st.session_state.config = {
        "milvus": {
            "host": "127.0.0.1",
            "port": "19530",
            "vector_name": "default",
            "collection_name": "Test_one",
            "index_name": "IVF_FLAT",
            "replica_num": 1,
            "index_device": "cpu"
        },
        "system": {
            "url_split": False
        },
        "search": {
            "top_k": 20,
            "col_choice": "hdbscan",
            "reorder_strategy": "distance"
        },
        "data": {
            "data_location": ""
        }
    }

if "last_search" not in st.session_state:
    st.session_state.last_search = None

# é…ç½®å‚æ•°è®¾ç½®
with st.expander("âš™ï¸ é…ç½®å‚æ•°è®¾ç½®", expanded=True):
    with st.form("config_form"):
        st.subheader("Milvus é…ç½®")
        col1, col2, col3 = st.columns(3)
        with col1:
            milvus_host = st.text_input("Milvus Host", value=st.session_state.config["milvus"]["host"])
            vector_name = st.text_input("Vector DB Name", value=st.session_state.config["milvus"]["vector_name"])
            insert_mode = st.selectbox(
                "æ•°æ®æ’å…¥æ¨¡å¼",
                ["è¦†ç›–ï¼ˆåˆ é™¤åŸæœ‰æ•°æ®ï¼‰", "è¿½åŠ ï¼ˆä¿ç•™åŸæœ‰æ•°æ®ï¼‰"],
                index=0  # é»˜è®¤è¦†ç›–
            )
        with col2:
            milvus_port = st.text_input("Milvus Port", value=st.session_state.config["milvus"]["port"])
            collection_name = st.text_input("Collection Name", value=st.session_state.config["milvus"]["collection_name"])
            url_split = st.selectbox(
                "æ˜¯å¦å¯ç”¨URLåˆ‡åˆ†", 
                ["True", "False"],
                index=0 if st.session_state.config["system"]["url_split"] else 1
            )
        with col3:
            index_name = st.selectbox(
                "Index Name", 
                ["IVF_FLAT", "HNSW", "HNSW_SQ8"],
                index=["IVF_FLAT", "HNSW", "HNSW_SQ8"].index(st.session_state.config["milvus"]["index_name"])
            )
            replica_num = st.number_input(
                "Replica Num", 
                value=st.session_state.config["milvus"]["replica_num"], 
                min_value=1
            )
            index_device = st.selectbox(
                "Index Device", 
                ["cpu", "gpu"],
                index=0 if st.session_state.config["milvus"]["index_device"] == "cpu" else 1
            )

        st.subheader("æ£€ç´¢å‚æ•°")
        col4, col5 = st.columns(2)
        with col4:
            search_top_k = st.number_input(
                "Search Top K", 
                value=st.session_state.config["search"]["top_k"], 
                min_value=1
            )
            search_col_choice = st.selectbox(
                "Search Col Choice", 
                ["hdbscan", "kmeans"],
                index=0 if st.session_state.config["search"]["col_choice"] == "hdbscan" else 1,
                key="search_col_choice_unique"
            )
        with col5:
            search_reorder_strategy = st.selectbox(
                "Search Reorder Strategy", 
                ["distance", "cluster_size", "cluster_center"],
                index=["distance", "cluster_size", "cluster_center"].index(
                    st.session_state.config["search"]["reorder_strategy"]
                )
            )

        st.subheader("æ–‡æœ¬åˆ‡åˆ†é…ç½®")
        col6, col7, col8 = st.columns(3)
        with col6:
            chunking_strategy = st.selectbox(
                "åˆ‡åˆ†ç­–ç•¥",
                ["traditional", "meta_ppl", "margin_sampling", "msp", "semantic"],
                index=["traditional", "meta_ppl", "margin_sampling", "msp", "semantic"].index(
                    st.session_state.config.get("chunking", {}).get("strategy", "traditional")
                ),
                help="é€‰æ‹©æ–‡æœ¬åˆ‡åˆ†ç­–ç•¥ï¼š\n- traditional: å›ºå®šé•¿åº¦åˆ‡åˆ†\n- meta_ppl: PPLå›°æƒ‘åº¦åˆ‡åˆ†\n- margin_sampling: è¾¹é™…é‡‡æ ·åˆ‡åˆ†\n- msp: MSPé«˜çº§åˆ‡åˆ†\n- semantic: è¯­ä¹‰åˆ‡åˆ†"
            )
        with col7:
            chunk_length = st.number_input(
                "å—é•¿åº¦",
                value=st.session_state.config.get("chunking", {}).get("chunk_length", 512),
                min_value=100,
                max_value=2048,
                help="æ–‡æœ¬å—çš„æœ€å¤§é•¿åº¦"
            )
        
        # åˆå§‹åŒ–æ‰€æœ‰å¯èƒ½çš„å‚æ•°å˜é‡
        ppl_threshold = st.session_state.config.get("chunking", {}).get("ppl_threshold", 0.3)
        confidence_threshold = st.session_state.config.get("chunking", {}).get("confidence_threshold", 0.7)
        similarity_threshold = st.session_state.config.get("chunking", {}).get("similarity_threshold", 0.8)
        overlap = st.session_state.config.get("chunking", {}).get("overlap", 50)
        
        with col8:
            if chunking_strategy == "meta_ppl":
                ppl_threshold = st.slider(
                    "PPLé˜ˆå€¼",
                    min_value=0.0,
                    max_value=1.0,
                    value=ppl_threshold,
                    step=0.1,
                    help="PPLå›°æƒ‘åº¦åˆ‡åˆ†çš„é˜ˆå€¼",
                    key="ppl_threshold_slider"
                )
            elif chunking_strategy == "msp":
                confidence_threshold = st.slider(
                    "ç½®ä¿¡åº¦é˜ˆå€¼",
                    min_value=0.5,
                    max_value=0.95,
                    value=confidence_threshold,
                    step=0.05,
                    help="MSPåˆ‡åˆ†çš„ç½®ä¿¡åº¦é˜ˆå€¼",
                    key="confidence_threshold_slider"
                )
            elif chunking_strategy == "semantic":
                similarity_threshold = st.slider(
                    "ç›¸ä¼¼åº¦é˜ˆå€¼",
                    min_value=0.5,
                    max_value=0.95,
                    value=similarity_threshold,
                    step=0.05,
                    help="è¯­ä¹‰åˆ‡åˆ†çš„ç›¸ä¼¼åº¦é˜ˆå€¼",
                    key="similarity_threshold_slider"
                )
                min_chunk_size = st.number_input(
                    "æœ€å°å—å¤§å°",
                    value=100,
                    min_value=50,
                    max_value=200,
                    key="min_chunk_size_input"
                )
            elif chunking_strategy == "traditional":
                overlap = st.slider(
                    "é‡å é•¿åº¦",
                    min_value=0,
                    max_value=200,
                    value=overlap,
                    step=10,
                    help="ä¼ ç»Ÿåˆ‡åˆ†çš„é‡å é•¿åº¦",
                    key="overlap_slider"
                )

        st.subheader("å¤šæ¨¡æ€é…ç½®")
        col9, col10 = st.columns(2)
        with col9:
            enable_image = st.checkbox(
                "å¯ç”¨å›¾åƒå¤„ç†",
                value=st.session_state.config.get("multimodal", {}).get("enable_image", False)
            )
        with col10:
            clip_model = st.selectbox(
                "CLIPæ¨¡å‹",
                ["ViT-B/32", "ViT-B/16", "ViT-L/14"],
                index=["ViT-B/32", "ViT-B/16", "ViT-L/14"].index(
                    st.session_state.config.get("multimodal", {}).get("clip_model", "ViT-B/32")
                )
            )

        submitted = st.form_submit_button("ğŸ’¾ ä¿å­˜é…ç½®")
        if submitted:
            config_data = {
                "milvus": {
                    "host": milvus_host,
                    "port": milvus_port,
                    "vector_name": vector_name,
                    "collection_name": collection_name,
                    "index_name": index_name,
                    "replica_num": replica_num,
                    "index_device": index_device
                },
                "system": {
                    "url_split": url_split == "True",
                    "insert_mode": "overwrite" if insert_mode == "è¦†ç›–ï¼ˆåˆ é™¤åŸæœ‰æ•°æ®ï¼‰" else "append"
                },
                "search": {
                    "top_k": search_top_k,
                    "col_choice": search_col_choice,
                    "reorder_strategy": search_reorder_strategy
                },
                "chunking": build_chunking_config(
                    chunking_strategy, 
                    chunk_length, 
                    ppl_threshold, 
                    confidence_threshold, 
                    similarity_threshold, 
                    overlap
                ),
                "multimodal": {
                    "enable_image": enable_image,
                    "clip_model": clip_model,
                    "image_formats": ["jpg", "jpeg", "png", "bmp"]
                }
            }
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            st.session_state.config = config_data
            
            # å‘é€åˆ°åç«¯
            try:
                response = requests.post("http://localhost:8507/update_config", json=config_data)
                if response.status_code == 200:
                    st.success("âœ… é…ç½®å·²ä¿å­˜å¹¶ç”Ÿæ•ˆ")
                else:
                    st.error(f"âŒ é…ç½®ä¿å­˜å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            except Exception as e:
                st.error(f"âŒ è¿æ¥åç«¯å¤±è´¥: {str(e)}")

st.markdown("---")

# ä¸Šä¼ æ–‡ä»¶å¤¹
with st.expander("ğŸ“ ä¸Šä¼ æ•°æ®æ–‡ä»¶å¤¹", expanded=True):
    st.info("è¯·å…¨é€‰æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ ï¼Œå¹¶è¾“å…¥ä¸€ä¸ªæ–‡ä»¶å¤¹åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä¿å­˜åˆ°è¯¥ç›®å½•ã€‚")
    folder_name = st.text_input("è¯·è¾“å…¥ç›®æ ‡æ–‡ä»¶å¤¹åï¼ˆå¦‚20240501ï¼‰", key="folder_name")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ï¼ˆæ”¯æŒcsv, md, pdf, txt, jpg, pngï¼‰", 
        accept_multiple_files=True, 
        type=["csv", "md", "pdf", "txt", "jpg", "jpeg", "png"]
    )
    
    if st.button("â¬†ï¸ ä¸Šä¼ å¹¶æ„å»ºå‘é‡åº“", key="upload_btn"):
        if not folder_name:
            st.warning("âš ï¸ è¯·å…ˆè¾“å…¥ç›®æ ‡æ–‡ä»¶å¤¹åã€‚")
        elif not uploaded_files:
            st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶ã€‚")
        else:
            with st.spinner("ä¸Šä¼ æ–‡ä»¶ä¸­ï¼Œè¯·ç¨å€™..."):
                # 1. ä¸Šä¼ æ–‡ä»¶
                files = [("files", (file.name, file, file.type)) for file in uploaded_files]
                try:
                    response = requests.post(
                        "http://localhost:8507/upload",
                        params={"folder_name": folder_name},
                        files=files
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        
                        # æ˜¾ç¤ºä¸Šä¼ ç»“æœ
                        if result.get("status") == "success":
                            if result.get("vectorized", False):
                                st.success(f"âœ… æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶å¹¶å®Œæˆå‘é‡åŒ–å­˜å‚¨")
                                st.info("ğŸ“Š æ•°æ®å·²å‘é‡åŒ–ï¼Œå¯ä»¥è¿›è¡Œæ£€ç´¢æŸ¥è¯¢")
                            else:
                                st.success(f"âœ… æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
                                st.warning("âš ï¸ å‘é‡åŒ–å­˜å‚¨æœªå®Œæˆï¼Œå¯èƒ½å½±å“æ£€ç´¢åŠŸèƒ½")
                            st.balloons()
                        
                        # 2. æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„ data_location å­—æ®µ
                        config_update = {
                            "data": {
                                "data_location": f"./data/upload/{folder_name}"
                            }
                        }
                        st.session_state.config["data"] = config_update["data"]
                        
                        # å‘é€æ›´æ–°è¯·æ±‚
                        update_response = requests.post("http://localhost:8507/update_config", json=config_update)
                        
                        if update_response.status_code != 200:
                            st.error(f"âŒ é…ç½®æ›´æ–°å¤±è´¥: {update_response.text}")
                    else:
                        st.error(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {response.text}")
                except Exception as e:
                    st.error(f"âŒ è¿æ¥åç«¯å¤±è´¥: {str(e)}")

st.markdown("---")

# æ£€ç´¢ä¸å¯è§†åŒ–
with st.expander("ğŸ” æ£€ç´¢ä¸å¯è§†åŒ–", expanded=True):
    question = st.text_input("è¯·è¾“å…¥æ£€ç´¢é—®é¢˜", key="search_question")
    col_choice = st.selectbox(
        "èšç±»ç®—æ³•", 
        ["hdbscan", "kmeans"],
        index=0 if st.session_state.config["search"]["col_choice"] == "hdbscan" else 1,
        key="col_choice"
    )
    
    # æ·»åŠ ç»“æœå±•ç¤ºé€‰é¡¹
    result_display = st.radio("ç»“æœå±•ç¤ºæ–¹å¼", ["æ‘˜è¦è§†å›¾", "è¯¦ç»†è§†å›¾"], index=0, horizontal=True)
    
    if st.button("ğŸš€ å¼€å§‹æ£€ç´¢ä¸å¯è§†åŒ–", key="search_btn", type="primary"):
        if not question:
            st.warning("âš ï¸ è¯·è¾“å…¥æ£€ç´¢é—®é¢˜ï¼")
        else:
            with st.spinner("æ£€ç´¢ä¸­ï¼Œè¯·ç¨å€™..."):
                try:
                    # 1. æ‰§è¡Œæœç´¢
                    search_response = requests.post(
                        "http://localhost:8507/search",
                        json={
                            "question": question, 
                            "col_choice": col_choice,
                            "collection_name": st.session_state.config["milvus"]["collection_name"]
                        }
                    )
                    
                    if search_response.status_code == 200:
                        search_result = search_response.json()
                        st.session_state.last_search = search_result
                        
                        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                        if "clusters" in search_result and search_result["clusters"]:
                            cluster_count = len(search_result["clusters"])
                            doc_count = sum(len(cluster["documents"]) for cluster in search_result["clusters"])
                            st.success(f"âœ… æ£€ç´¢å®Œæˆ: æ‰¾åˆ° {cluster_count} ä¸ªé›†ç¾¤, å…± {doc_count} ä¸ªæ–‡æ¡£")
                            
                            # æ˜¾ç¤ºæ‰€æœ‰å¬å›ç»“æœ
                            st.subheader("æ‰€æœ‰å¬å›ç»“æœ")
                            
                            # åˆ›å»ºé€‰é¡¹å¡å¸ƒå±€
                            tab1, tab2 = st.tabs(["æ–‡æ¡£åˆ—è¡¨", "é›†ç¾¤è§†å›¾"])
                            
                            with tab1:
                                # æŒ‰è·ç¦»æ’åºçš„æ‰€æœ‰æ–‡æ¡£
                                all_docs = []
                                for cluster in search_result["clusters"]:
                                    all_docs.extend(cluster["documents"])
                                all_docs_sorted = sorted(all_docs, key=lambda x: x["distance"])
                                
                                st.write(f"å…±å¬å› {len(all_docs_sorted)} ä¸ªæ–‡æ¡£ï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰:")
                                
                                # åˆ†é¡µæ˜¾ç¤ºç»“æœ
                                page_size = 5
                                max_page = max(1, (len(all_docs_sorted) + page_size - 1) // page_size)
                                page_number = st.number_input("é¡µç ", min_value=1, 
                                                             max_value=max_page, 
                                                             value=1)
                                
                                start_idx = (page_number - 1) * page_size
                                end_idx = min(start_idx + page_size, len(all_docs_sorted))
                                
                                for i in range(start_idx, end_idx):
                                    doc = all_docs_sorted[i]
                                    
                                    # ä½¿ç”¨å®¹å™¨è€Œä¸æ˜¯åµŒå¥—çš„ expander
                                    with st.container():
                                        st.subheader(f"æ–‡æ¡£ #{i+1} (ID: {doc['id']}, è·ç¦»: {doc['distance']:.4f})")
                                        st.markdown(f"**ID:** {doc['id']}")
                                        st.markdown(f"**ç›¸ä¼¼åº¦è·ç¦»:** {doc['distance']:.4f}")
                                        if "url" in doc:
                                            st.markdown(f"**URL:** [{doc['url']}]({doc['url']})")
                                        
                                        content = doc['content']
                                        if result_display == "æ‘˜è¦è§†å›¾":
                                            # æ˜¾ç¤ºæ‘˜è¦
                                            preview = content[:300] + "..." if len(content) > 300 else content
                                            st.markdown(f"**å†…å®¹æ‘˜è¦:**")
                                            st.write(preview)
                                        else:
                                            # æ˜¾ç¤ºå®Œæ•´å†…å®¹
                                            st.markdown(f"**å®Œæ•´å†…å®¹:**")
                                            st.text_area("", value=content, height=200, key=f"full_content_{doc['id']}", label_visibility="collapsed")
                                        
                                        st.markdown("---")
                            
                            with tab2:
                                # æ˜¾ç¤ºé›†ç¾¤æŒ‡æ ‡å¡
                                cluster_count = len(search_result["clusters"])
                                doc_count = sum(len(cluster["documents"]) for cluster in search_result["clusters"])
                                avg_docs = doc_count / cluster_count if cluster_count > 0 else 0
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("é›†ç¾¤æ•°é‡", cluster_count)
                                with col2:
                                    st.metric("æ–‡æ¡£æ€»æ•°", doc_count)
                                with col3:
                                    st.metric("å¹³å‡æ–‡æ¡£æ•°", f"{avg_docs:.1f}")
                                
                                # åº”ç”¨è‡ªå®šä¹‰æ ·å¼
                                style_metric_cards()
                                
                                # æ˜¾ç¤ºæ¯ä¸ªé›†ç¾¤çš„æ–‡æ¡£
                                for cluster in search_result["clusters"]:
                                    st.subheader(f"é›†ç¾¤ #{cluster['cluster_id']} (æ–‡æ¡£æ•°: {len(cluster['documents'])})")
                                    
                                    for doc in cluster["documents"]:
                                        with st.container():
                                            st.markdown(f"**ID:** {doc['id']} | **è·ç¦»:** {doc['distance']:.4f}")
                                            if "url" in doc:
                                                st.markdown(f"**URL:** [{doc['url']}]({doc['url']})")
                                            
                                            content = doc['content']
                                            if result_display == "æ‘˜è¦è§†å›¾":
                                                # æ˜¾ç¤ºæ‘˜è¦
                                                preview = content[:300] + "..." if len(content) > 300 else content
                                                st.markdown(f"**å†…å®¹æ‘˜è¦:**")
                                                st.write(preview)
                                            else:
                                                # æ˜¾ç¤ºå®Œæ•´å†…å®¹
                                                st.markdown(f"**å®Œæ•´å†…å®¹:**")
                                                st.text_area("", value=content, height=200, key=f"cluster_content_{doc['id']}", label_visibility="collapsed")
                                            
                                            st.markdown("---")
                        
                        else:
                            st.info("â„¹ï¸ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                        
                        # 2. æ‰§è¡Œå¯è§†åŒ–ï¼ˆä»…é™HDBSCANï¼‰
                        if col_choice.lower() == "hdbscan" and "clusters" in search_result and search_result["clusters"]:
                            vis_response = requests.post(
                                "http://localhost:8507/visualization",
                                json={"collection_name": st.session_state.config["milvus"]["collection_name"]}
                            )
                            
                            if vis_response.status_code == 200:
                                vis_data = vis_response.json()
                                
                                if isinstance(vis_data, list) and vis_data:
                                    df = pd.DataFrame(vis_data)
                                    
                                    # æ˜¾ç¤ºå¯è§†åŒ–å›¾è¡¨
                                    st.subheader("HDBSCANèšç±»å¯è§†åŒ–ï¼ˆUMAPé™ç»´ï¼‰")
                                    fig = px.scatter(
                                        df, x="x", y="y", color="cluster", 
                                        hover_data=["text"],
                                        title="",
                                        width=1000, height=600,
                                        color_continuous_scale=px.colors.sequential.Viridis
                                    )
                                    fig.update_traces(
                                        marker=dict(size=12, line=dict(width=1, color='DarkSlateGrey')),
                                        selector=dict(mode='markers')
                                    )
                                    fig.update_layout(
                                        hoverlabel=dict(bgcolor="white", font_size=12),
                                        legend_title_text='é›†ç¾¤ID'
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                    # æ˜¾ç¤ºåŸå§‹æ•°æ®
                                    with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®"):
                                        st.dataframe(df)
                                else:
                                    st.info("â„¹ï¸ æ— å¯è§†åŒ–æ•°æ®")
                            else:
                                st.error(f"âŒ å¯è§†åŒ–å¤±è´¥: {vis_response.text}")
                    else:
                        st.error(f"âŒ æ£€ç´¢å¤±è´¥: {search_response.text}")
                except Exception as e:
                    st.error(f"âŒ è¿æ¥åç«¯å¤±è´¥: {str(e)}")

st.markdown("---")

# æ–°å¢åŠŸèƒ½é¢æ¿
with st.expander("ğŸ§ª æ–‡æœ¬åˆ‡åˆ†æµ‹è¯•", expanded=False):
    st.info("æµ‹è¯•ä¸åŒçš„æ–‡æœ¬åˆ‡åˆ†ç­–ç•¥æ•ˆæœ")
    
    test_text = st.text_area("è¾“å…¥æµ‹è¯•æ–‡æœ¬", height=150, key="test_text")
    test_strategy = st.selectbox("é€‰æ‹©åˆ‡åˆ†ç­–ç•¥", ["traditional", "meta_ppl", "margin_sampling", "msp", "semantic"], key="test_strategy")
    
    if st.button("ğŸ”„ æ‰§è¡Œåˆ‡åˆ†æµ‹è¯•", key="chunking_test_btn"):
        if test_text:
            with st.spinner("æ­£åœ¨æ‰§è¡Œæ–‡æœ¬åˆ‡åˆ†..."):
                try:
                    response = requests.post(
                        "http://localhost:8507/chunking/process",
                        json={
                            "text": test_text,
                            "strategy": test_strategy,
                            "params": st.session_state.config["chunking"]
                        }
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        st.success(f"âœ… åˆ‡åˆ†å®Œæˆï¼Œå…±ç”Ÿæˆ {result['chunk_count']} ä¸ªæ–‡æœ¬å—")
                        
                        for i, chunk in enumerate(result['chunks']):
                            st.text_area(f"æ–‡æœ¬å— {i+1}", value=chunk, height=100, key=f"chunk_{i}")
                    else:
                        st.error(f"âŒ åˆ‡åˆ†å¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"âŒ è¿æ¥åç«¯å¤±è´¥: {str(e)}")
        else:
            st.warning("âš ï¸ è¯·è¾“å…¥æµ‹è¯•æ–‡æœ¬")

with st.expander("ğŸ–¼ï¸ æ–‡æœå›¾åŠŸèƒ½", expanded=False):
    st.info("ä½¿ç”¨æ–‡æœ¬æè¿°æœç´¢ç›¸å…³å›¾åƒ")
    
    if st.session_state.config.get("multimodal", {}).get("enable_image", False):
        search_text = st.text_input("è¾“å…¥å›¾åƒæè¿°", key="image_search_text")
        search_top_k = st.number_input("è¿”å›å›¾åƒæ•°é‡", min_value=1, max_value=50, value=10, key="image_search_k")
        
        if st.button("ğŸ” æœç´¢å›¾åƒ", key="image_search_btn"):
            if search_text:
                with st.spinner("æ­£åœ¨æœç´¢å›¾åƒ..."):
                    try:
                        response = requests.post(
                            "http://localhost:8507/multimodal/text_to_image_search",
                            json={
                                "query_text": search_text,
                                "top_k": search_top_k,
                                "collection_name": st.session_state.config["milvus"]["collection_name"]
                            }
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            if result.get("results"):
                                st.success(f"âœ… æ‰¾åˆ° {len(result['results'])} ä¸ªç›¸å…³å›¾åƒ")
                                # æ˜¾ç¤ºå›¾åƒç»“æœ
                                cols = st.columns(3)
                                for i, img_info in enumerate(result["results"]):
                                    with cols[i % 3]:
                                        st.image(img_info["image_path"], caption=f"ç›¸ä¼¼åº¦: {img_info['distance']:.4f}")
                            else:
                                st.info("â„¹ï¸ " + result.get("message", "æœªæ‰¾åˆ°ç›¸å…³å›¾åƒ"))
                        else:
                            st.error(f"âŒ æœç´¢å¤±è´¥: {response.text}")
                            
                    except Exception as e:
                        st.error(f"âŒ è¿æ¥åç«¯å¤±è´¥: {str(e)}")
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥å›¾åƒæè¿°")
    else:
        st.warning("âš ï¸ å›¾åƒå¤„ç†åŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·åœ¨é…ç½®ä¸­å¯ç”¨å¤šæ¨¡æ€åŠŸèƒ½")

with st.expander("ğŸ“Š æ€§èƒ½ç›‘æ§", expanded=False):
    st.info("å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡")
    
    if st.button("ğŸ”„ åˆ·æ–°æ€§èƒ½æ•°æ®", key="refresh_perf_btn"):
        try:
            response = requests.get("http://localhost:8507/performance/current")
            if response.status_code == 200:
                metrics = response.json().get("metrics", {})
                
                if metrics:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("CPUä½¿ç”¨ç‡", f"{metrics.get('cpu', {}).get('percent', 0):.1f}%")
                    with col2:
                        st.metric("å†…å­˜ä½¿ç”¨ç‡", f"{metrics.get('memory', {}).get('percent', 0):.1f}%")
                    with col3:
                        st.metric("ç£ç›˜ä½¿ç”¨ç‡", f"{metrics.get('disk', {}).get('percent', 0):.1f}%")
                else:
                    st.info("æš‚æ— æ€§èƒ½æ•°æ®")
            else:
                st.error("è·å–æ€§èƒ½æ•°æ®å¤±è´¥")
        except Exception as e:
            st.error(f"è¿æ¥å¤±è´¥: {str(e)}")

with st.expander("ğŸ”§ ç³»ç»ŸçŠ¶æ€", expanded=False):
    if st.button("ğŸ“‹ è·å–ç³»ç»ŸçŠ¶æ€", key="system_status_btn"):
        try:
            response = requests.get("http://localhost:8507/system/status")
            if response.status_code == 200:
                status_data = response.json()
                st.success("âœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
                
                status = status_data.get("status", {})
                
                # æ˜¾ç¤ºæ¨¡å—çŠ¶æ€
                st.subheader("æ¨¡å—çŠ¶æ€")
                col_status1, col_status2 = st.columns(2)
                
                with col_status1:
                    st.write("ğŸ” æ€§èƒ½ç›‘æ§:", "âœ… è¿è¡Œä¸­" if status.get("performance_monitor") else "âŒ æœªè¿è¡Œ")
                    st.write("ğŸ§  CLIPç¼–ç å™¨:", "âœ… å·²åŠ è½½" if status.get("clip_encoder") else "âŒ æœªåŠ è½½")
                    st.write("âœ‚ï¸ æ–‡æœ¬åˆ‡åˆ†:", "âœ… å·²åˆå§‹åŒ–" if status.get("chunking_manager") else "âŒ æœªåˆå§‹åŒ–")
                
                with col_status2:
                    st.write("ğŸ“ æ–‡æœ¬å¤„ç†:", "âœ… å·²åˆå§‹åŒ–" if status.get("text_processor") else "âŒ æœªåˆå§‹åŒ–")
                    st.write("ğŸ–¼ï¸ å›¾åƒå¤„ç†:", "âœ… å·²åˆå§‹åŒ–" if status.get("image_processor") else "âŒ æœªåˆå§‹åŒ–")
                
                # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
                st.subheader("é…ç½®ä¿¡æ¯")
                config_info = status.get("config", {})
                st.write(f"Milvusåœ°å€: {config_info.get('milvus_host')}:{config_info.get('milvus_port')}")
                st.write(f"é›†åˆåç§°: {config_info.get('collection_name')}")
                st.write(f"å¤šæ¨¡æ€åŠŸèƒ½: {'âœ… å·²å¯ç”¨' if config_info.get('multimodal_enabled') else 'âŒ æœªå¯ç”¨'}")
                
            else:
                st.error(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {response.text}")
                
        except Exception as e:
            st.error(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")

# æ˜¾ç¤ºå½“å‰é…ç½®ä¿¡æ¯
with st.expander("ğŸ“‹ å½“å‰é…ç½®ä¿¡æ¯", expanded=False):
    st.json(st.session_state.config)

# é¡µè„š
st.markdown("---")
st.caption("Â© 2025 æ™ºèƒ½å‘é‡æ£€ç´¢ç³»ç»Ÿ | ç‰ˆæœ¬ 2.0.0 - æ•´åˆç‰ˆ")