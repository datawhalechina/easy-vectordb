from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
import logging
import asyncio
import concurrent.futures
import time
import threading
import uuid
from .lazy_connection import get_lazy_connection

def test_milvus_connection(host, port, timeout=5):
    """æµ‹è¯•Milvusè¿æ¥æ˜¯å¦å¯ç”¨"""
    import socket
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, int(port)))
        sock.close()
        return result == 0
    except Exception as e:
        logging.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

_connection_lock = threading.Lock()

def cleanup_all_connections():
    """æ¸…ç†æ‰€æœ‰ç°æœ‰è¿æ¥"""
    try:
        existing_connections = connections.list_connections()
        for conn_alias in existing_connections:
            try:
                connections.disconnect(conn_alias)
                logging.info(f"å·²æ–­å¼€è¿æ¥: {conn_alias}")
            except Exception as e:
                logging.warning(f"æ–­å¼€è¿æ¥ {conn_alias} å¤±è´¥: {e}")
        time.sleep(1)  # ç­‰å¾…è¿æ¥å®Œå…¨å…³é—­
    except Exception as e:
        logging.warning(f"æ¸…ç†è¿æ¥æ—¶å‡ºé”™: {e}")

def milvus_connect_with_retry(alias, host, port, max_retries=3, timeout=10):
    """å¸¦é‡è¯•æœºåˆ¶çš„Milvusè¿æ¥ï¼Œä½¿ç”¨çº¿ç¨‹é”é˜²æ­¢å¹¶å‘å†²çª"""
    with _connection_lock:  # ä½¿ç”¨é”ç¡®ä¿è¿æ¥æ“ä½œçš„åŸå­æ€§
        for attempt in range(max_retries):
            try:
                logging.info(f"å°è¯•è¿æ¥Milvus (ç¬¬{attempt + 1}æ¬¡): {host}:{port}")
                
                # å…ˆæµ‹è¯•ç½‘ç»œè¿æ¥
                if not test_milvus_connection(host, port, timeout=5):
                    raise ConnectionError(f"æ— æ³•è¿æ¥åˆ° {host}:{port}")
                
                cleanup_all_connections()
                
                logging.info("å°è¯•å»ºç«‹æ–°è¿æ¥")
                connections.connect(
                    alias=alias,
                    host=host,
                    port=int(port),
                    timeout=timeout
                )
                
                try:
                    collections = utility.list_collections()
                    server_version = utility.get_server_version()
                    logging.info(f"è¿æ¥æˆåŠŸï¼ŒæœåŠ¡å™¨ç‰ˆæœ¬: {server_version}, ç°æœ‰é›†åˆ: {collections}")
                    return True
                except Exception as verify_error:
                    logging.error(f"è¿æ¥éªŒè¯å¤±è´¥: {verify_error}")
                    try:
                        connections.disconnect(alias)
                    except:
                        pass
                    raise verify_error
                
            except Exception as e:
                logging.warning(f"è¿æ¥å°è¯• {attempt + 1} å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    logging.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    raise ConnectionError(f"ç»è¿‡ {max_retries} æ¬¡å°è¯•åä»æ— æ³•è¿æ¥åˆ°Milvus: {e}")

async def milvus_connect_insert_async(CollectionName, IndexParam, ReplicaNum, dataList, url_split, Milvus_host, Milvus_port, insert_mode="è¦†ç›–ï¼ˆåˆ é™¤åŸæœ‰æ•°æ®ï¼‰"):
    """å¼‚æ­¥ç‰ˆæœ¬çš„Milvusè¿æ¥å’Œæ’å…¥"""
    def sync_operation():
        return milvus_connect_insert(CollectionName, IndexParam, ReplicaNum, dataList, url_split, Milvus_host, Milvus_port, insert_mode)
    
    loop = asyncio.get_event_loop()
    with concurrent.futures.ThreadPoolExecutor() as executor:
        result = await loop.run_in_executor(executor, sync_operation)
    return result

def milvus_connect_insert(CollectionName, IndexParam, ReplicaNum, dataList, url_split, Milvus_host, Milvus_port,insert_mode="è¦†ç›–ï¼ˆåˆ é™¤åŸæœ‰æ•°æ®ï¼‰"):
    """ä½¿ç”¨ç®€åŒ–çš„è¿æ¥ç®¡ç†è¿›è¡Œæ•°æ®æ’å…¥ - é¿å…é˜»å¡"""
    
    try:
        logging.info("ğŸš€ è¿›å…¥Insertæ¨¡å—ï¼šä½¿ç”¨ç®€åŒ–è¿æ¥ç®¡ç†")
        logging.info(f"ç›®æ ‡æœåŠ¡å™¨: {Milvus_host}:{Milvus_port}")
        
        # ä½¿ç”¨ç®€åŒ–çš„è¿æ¥ç®¡ç†
        from simple_milvus import get_milvus_connection, connect_milvus
        
        conn = get_milvus_connection()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å»ºç«‹æ–°è¿æ¥
        use_lite = Milvus_host.endswith('.db')
        if not conn.is_connected() or conn.host != Milvus_host or conn.port != int(Milvus_port):
            logging.info(f"ğŸ”„ å»ºç«‹æ–°è¿æ¥: {Milvus_host}:{Milvus_port} (Lite: {use_lite})")
            success = connect_milvus(Milvus_host, int(Milvus_port), use_lite)
            if not success:
                raise ConnectionError(f"æ— æ³•è¿æ¥åˆ°Milvus: {Milvus_host}:{Milvus_port}")
        
        connection_alias = conn.get_connection_alias()
        if not connection_alias:
            raise ConnectionError("æ— æ³•è·å–è¿æ¥åˆ«å")
        
        logging.info(f"âœ… ä½¿ç”¨ç®€åŒ–è¿æ¥: {connection_alias}")
        
        logging.info(f"ğŸ“‹ ç°æœ‰é›†åˆ: {utility.list_collections(using=connection_alias)}")
        if not dataList:
            logging.warning("æ•°æ®åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•å¤„ç†")
            return {"status": "fail", "msg": "æ•°æ®åˆ—è¡¨ä¸ºç©º"}
            
        logging.info(f"ğŸ“Š å‡†å¤‡å¤„ç† {len(dataList)} æ¡æ•°æ®")
        embedding_dim = 1024  # é»˜è®¤ç»´åº¦
        if dataList and len(dataList) > 0:
            first_embedding = dataList[0].get("embedding", [])
            if isinstance(first_embedding, list):  
                embedding_dim = len(first_embedding)
                logging.info(f"ğŸ” æ£€æµ‹åˆ°å‘é‡ç»´åº¦: {embedding_dim}")
        
        collection_name = CollectionName
        if url_split:
            fields = [
                FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
                FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=4096),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),
                FieldSchema(name="url", dtype=DataType.VARCHAR, max_length=1024)
            ]
        else:
            fields = [
                FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
                FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=4096),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim)
            ]
        
        # åˆ›å»ºå¸¦åŠ¨æ€å­—æ®µæ”¯æŒçš„ schema
        schema = CollectionSchema(fields, collection_name, enable_dynamic_field=True)
        
        # æ·»åŠ åŠ¨æ€å­—æ®µæ”¯æŒéªŒè¯
        if utility.has_collection(collection_name, using=connection_alias) and insert_mode != "è¦†ç›–ï¼ˆåˆ é™¤åŸæœ‰æ•°æ®ï¼‰":
            existing_schema = Collection(collection_name, using=connection_alias).schema
            if not existing_schema.enable_dynamic_field:
                raise ValueError("æ— æ³•è¿½åŠ åˆ°ä¸æ”¯æŒåŠ¨æ€å­—æ®µçš„é›†åˆï¼Œè¯·å…ˆåˆ é™¤åŸæœ‰é›†åˆ")
        
        # æ ¹æ®æ’å…¥æ¨¡å¼å†³å®šæ˜¯å¦åˆ é™¤åŸæœ‰ collection
        if insert_mode == "è¦†ç›–ï¼ˆåˆ é™¤åŸæœ‰æ•°æ®ï¼‰":
            if utility.has_collection(collection_name, using=connection_alias):
                utility.drop_collection(collection_name, using=connection_alias)
                logging.info(f"ğŸ—‘ï¸ å·²åˆ é™¤ç°æœ‰é›†åˆ: {collection_name}")
            collection = Collection(name=collection_name, schema=schema, using=connection_alias)
            logging.info(f"ğŸ†• åˆ›å»ºæ–°é›†åˆ: {collection_name}")
        else:  # è¿½åŠ æ¨¡å¼
            if utility.has_collection(collection_name, using=connection_alias):
                existing_col = Collection(collection_name, using=connection_alias)
                if existing_col.schema.fields != schema.fields:  # ç²¾ç¡®æ¯”è¾ƒå­—æ®µ
                    raise ValueError(f"é›†åˆ{collection_name}å·²å­˜åœ¨ä½†å­—æ®µä¸åŒ¹é…")
                logging.info(f"ğŸ“ ä½¿ç”¨ç°æœ‰é›†åˆ: {collection_name}")
            if not utility.has_collection(collection_name, using=connection_alias):
                collection = Collection(name=collection_name, schema=schema, using=connection_alias)
                logging.info(f"ğŸ†• åˆ›å»ºæ–°é›†åˆ: {collection_name}")
            else:
                collection = Collection(name=collection_name, using=connection_alias)
        
        # ç¡®ä¿æ•°æ®å­—æ®µå¯¹é½
        for data in dataList:
            if url_split:
                if "url" not in data or not isinstance(data["url"], str):
                    data["url"] = ""
            else:
                if "url" in data:
                    del data["url"]

        # æ£€æŸ¥ embedding
        embeddings = [data["embedding"] for data in dataList if "embedding" in data and data["embedding"] is not None]
        if not embeddings:
            logging.error("âŒ æ•°æ®ä¸­æ²¡æœ‰å¯ç”¨çš„embeddingï¼Œæ— æ³•å…¥åº“")
            return {"status": "fail", "msg": "æ•°æ®ä¸­æ²¡æœ‰å¯ç”¨çš„embeddingï¼Œæ— æ³•å…¥åº“ã€‚"}
        
        # å‡†å¤‡æ’å…¥æ•°æ® - å­—æ®µé¡ºåºå¿…é¡»ä¸ schema å®Œå…¨ä¸€è‡´
        if url_split:
            # å­—æ®µé¡ºåº: id, content, embedding, url
            entities = [
                [d["id"] for d in dataList],
                [d["content"] for d in dataList],
                [d["embedding"] for d in dataList],
                [d.get("url", "") for d in dataList]
            ]
        else:
            # å­—æ®µé¡ºåº: id, content, embedding
            entities = [
                [d["id"] for d in dataList],
                [d["content"] for d in dataList],
                [d["embedding"] for d in dataList]
            ]
        
        # æ’å…¥æ•°æ®åˆ° Milvus
        logging.info("ğŸ“¥ å¼€å§‹æ’å…¥æ•°æ®...")
        insert_result = collection.insert(entities)
        
        # åˆ·æ–°ç¡®ä¿æ•°æ®å†™å…¥
        logging.info("ğŸ’¾ åˆ·æ–°æ•°æ®...")
        collection.flush()
        
        # åˆ›å»ºç´¢å¼•
        logging.info("ğŸ”— åˆ›å»ºç´¢å¼•...")
        collection.create_index(field_name="embedding", index_params=IndexParam)
        
        # åŠ è½½é›†åˆåˆ°å†…å­˜
        logging.info("ğŸš€ åŠ è½½é›†åˆåˆ°å†…å­˜...")
        collection.load(replica_number=ReplicaNum)
        
        logging.info(f"âœ… æˆåŠŸæ’å…¥ {insert_result.insert_count} æ¡æ•°æ®")
        logging.info(f"ğŸ”§ ç´¢å¼•å‚æ•°: {IndexParam}")
        
        return {
            "status": "success",
            "msg": f"æˆåŠŸæ’å…¥ {len(dataList)} æ¡æ•°æ®",
            "insert_count": insert_result.insert_count
        }
        
    except Exception as e:
        logging.error(f"æ“ä½œå¤±è´¥: {str(e)}", exc_info=True)
        logging.error(f"é”™è¯¯å‘ç”Ÿæ—¶æ•°æ®åˆ—è¡¨é•¿åº¦: {len(dataList) if dataList else 0}")
        if 'dataList' in locals() and dataList:
            logging.error(f"é”™è¯¯å‘ç”Ÿæ—¶ç¬¬ä¸€æ¡æ•°æ®: {dataList[0]}")
        
        # åœ¨å‡ºç°é”™è¯¯æ—¶ï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
        logging.error("Milvusæ“ä½œå‡ºç°é”™è¯¯ï¼Œè¿æ¥å°†è‡ªåŠ¨æ¸…ç†")
            
        return {
            "status": "error",
            "msg": str(e)
        }