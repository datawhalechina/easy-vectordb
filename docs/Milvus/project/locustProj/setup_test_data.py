#!/usr/bin/env python3
"""
ä¸ºLocustæµ‹è¯•å‡†å¤‡Milvusæµ‹è¯•æ•°æ®
"""

import numpy as np
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from sklearn.datasets import make_blobs
from tqdm import tqdm
import logging
import argparse

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_test_collection(collection_name="locust_test_collection", 
                          dimension=256, 
                          num_vectors=100000,
                          batch_size=5000):
    """åˆ›å»ºæµ‹è¯•é›†åˆå¹¶æ’å…¥æ•°æ®"""
    
    # è¿æ¥åˆ°Milvus
    try:
        connections.connect("default", host="localhost", port="19530")
        logger.info("è¿æ¥åˆ°MilvusæˆåŠŸ")
    except Exception as e:
        logger.error(f"è¿æ¥Milvuså¤±è´¥: {e}")
        return False
    
    # åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ
    if utility.has_collection(collection_name):
        utility.drop_collection(collection_name)
        logger.info(f"åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ: {collection_name}")
    
    # å®šä¹‰é›†åˆschema
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=dimension),
        FieldSchema(name="category", dtype=DataType.INT64),  # æ·»åŠ åˆ†ç±»å­—æ®µç”¨äºè¿‡æ»¤æµ‹è¯•
    ]
    
    schema = CollectionSchema(fields, f"Locustæµ‹è¯•é›†åˆï¼Œç»´åº¦: {dimension}")
    collection = Collection(collection_name, schema)
    logger.info(f"åˆ›å»ºé›†åˆæˆåŠŸ: {collection_name}")
    
    # ç”Ÿæˆæµ‹è¯•å‘é‡æ•°æ®
    logger.info(f"ç”Ÿæˆ {num_vectors} ä¸ª {dimension} ç»´æµ‹è¯•å‘é‡")
    
    # ä½¿ç”¨èšç±»æ•°æ®ç”Ÿæˆæ›´çœŸå®çš„å‘é‡åˆ†å¸ƒ
    vectors, labels = make_blobs(
        n_samples=num_vectors,
        centers=20,  # 20ä¸ªèšç±»ä¸­å¿ƒ
        n_features=dimension,
        random_state=42,
        cluster_std=1.0
    )
    
    # å½’ä¸€åŒ–å‘é‡
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    vectors = vectors / norms
    vectors = vectors.astype(np.float32)
    
    # ç”Ÿæˆåˆ†ç±»æ ‡ç­¾
    categories = (labels % 10).astype(np.int64)  # 10ä¸ªåˆ†ç±»
    
    # æ‰¹é‡æ’å…¥æ•°æ®
    logger.info(f"å¼€å§‹æ’å…¥æ•°æ®ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
    
    for i in tqdm(range(0, num_vectors, batch_size), desc="æ’å…¥å‘é‡"):
        batch_end = min(i + batch_size, num_vectors)
        batch_vectors = vectors[i:batch_end].tolist()
        batch_categories = categories[i:batch_end].tolist()
        
        entities = [batch_vectors, batch_categories]
        collection.insert(entities)
    
    # åˆ·æ–°æ•°æ®
    collection.flush()
    logger.info("æ•°æ®æ’å…¥å®Œæˆï¼Œå¼€å§‹åˆ›å»ºç´¢å¼•")
    
    # åˆ›å»ºå‘é‡ç´¢å¼•
    index_params = {
        "metric_type": "L2",
        "index_type": "IVF_FLAT",
        "params": {"nlist": 2048}
    }
    
    collection.create_index("vector", index_params)
    logger.info("å‘é‡ç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    # åˆ›å»ºæ ‡é‡å­—æ®µç´¢å¼•ï¼ˆç”¨äºè¿‡æ»¤æµ‹è¯•ï¼‰
    collection.create_index("category")
    logger.info("åˆ†ç±»ç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    # åŠ è½½é›†åˆ
    collection.load()
    logger.info("é›†åˆåŠ è½½å®Œæˆ")
    
    # éªŒè¯æ•°æ®
    count = collection.num_entities
    logger.info(f"é›†åˆä¸­å…±æœ‰ {count} ä¸ªå‘é‡")
    
    return True

def create_multiple_collections():
    """åˆ›å»ºå¤šä¸ªä¸åŒé…ç½®çš„æµ‹è¯•é›†åˆ"""
    configs = [
        {"name": "locust_small", "dimension": 128, "num_vectors": 50000},
        {"name": "locust_medium", "dimension": 256, "num_vectors": 100000},
        {"name": "locust_large", "dimension": 512, "num_vectors": 200000},
    ]
    
    for config in configs:
        logger.info(f"åˆ›å»ºé›†åˆ: {config['name']}")
        success = create_test_collection(
            collection_name=config["name"],
            dimension=config["dimension"],
            num_vectors=config["num_vectors"]
        )
        if success:
            logger.info(f"âœ… é›†åˆ {config['name']} åˆ›å»ºæˆåŠŸ")
        else:
            logger.error(f"âŒ é›†åˆ {config['name']} åˆ›å»ºå¤±è´¥")

def main():
    parser = argparse.ArgumentParser(description="ä¸ºLocustæµ‹è¯•å‡†å¤‡Milvusæ•°æ®")
    parser.add_argument("--collection", default="locust_test_collection", help="é›†åˆåç§°")
    parser.add_argument("--dimension", type=int, default=256, help="å‘é‡ç»´åº¦")
    parser.add_argument("--num_vectors", type=int, default=100000, help="å‘é‡æ•°é‡")
    parser.add_argument("--batch_size", type=int, default=5000, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--multiple", action="store_true", help="åˆ›å»ºå¤šä¸ªæµ‹è¯•é›†åˆ")
    
    args = parser.parse_args()
    
    print("ğŸš€ Milvus Locustæµ‹è¯•æ•°æ®å‡†å¤‡å·¥å…·")
    print("="*50)
    
    if args.multiple:
        print("åˆ›å»ºå¤šä¸ªæµ‹è¯•é›†åˆ...")
        create_multiple_collections()
    else:
        print(f"åˆ›å»ºå•ä¸ªæµ‹è¯•é›†åˆ: {args.collection}")
        print(f"ç»´åº¦: {args.dimension}, å‘é‡æ•°é‡: {args.num_vectors}")
        
        success = create_test_collection(
            collection_name=args.collection,
            dimension=args.dimension,
            num_vectors=args.num_vectors,
            batch_size=args.batch_size
        )
        
        if success:
            print("âœ… æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆï¼")
            print(f"ç°åœ¨å¯ä»¥è¿è¡Œ: locust -f milvus_locust_test.py")
        else:
            print("âŒ æµ‹è¯•æ•°æ®å‡†å¤‡å¤±è´¥")

if __name__ == "__main__":
    main()