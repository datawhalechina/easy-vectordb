# LSHç®—æ³•

## 1.LSH ç®—æ³•åŸç†åˆ†æ­¥è¯¦è§£

**ğŸ§© LSH ç®—æ³•åŸç†åˆ†æ­¥è¯¦è§£ï¼ˆLocality-Sensitive Hashingï¼‰**

---

### ä¸€ã€æ ¸å¿ƒæ€æƒ³

> **ç›®çš„**ï¼šåœ¨é«˜ç»´ç©ºé—´ä¸­å¿«é€Ÿæ‰¾åˆ°â€œç›¸ä¼¼â€çš„æ•°æ®ç‚¹ã€‚  
> **å…³é”®æ€æƒ³**ï¼šè®©ç›¸ä¼¼çš„æ ·æœ¬åœ¨å“ˆå¸Œå **è½å…¥åŒä¸€ä¸ªæ¡¶ï¼ˆbucketï¼‰** çš„æ¦‚ç‡é«˜ï¼Œä¸ç›¸ä¼¼çš„æ ·æœ¬è½å…¥åŒæ¡¶çš„æ¦‚ç‡ä½ã€‚

ç›¸æ¯”æš´åŠ›æœç´¢ï¼ˆO(N)ï¼‰ï¼ŒLSH é€šè¿‡ **å¤šç»„éšæœºå“ˆå¸Œå‡½æ•°** å°†æœç´¢å¤æ‚åº¦é™ä½åˆ° **äºšçº¿æ€§ï¼ˆsublinearï¼‰**ã€‚

---

### äºŒã€é€‚ç”¨åœºæ™¯

| ç›¸ä¼¼åº¦åº¦é‡ | å¸¸ç”¨ LSH å˜ä½“ | å“ˆå¸Œæ€æƒ³ |
|-------------|----------------|-----------|
| ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆcosine similarityï¼‰ | Random Projection LSH | ç”¨éšæœºè¶…å¹³é¢åˆ’åˆ†ç©ºé—´ |
| æ¬§å¼è·ç¦»ï¼ˆL2 distanceï¼‰ | p-stable LSH | ç”¨éšæœºæŠ•å½± + æ¨¡è¿ç®—è¿‘ä¼¼æ¬§æ°è·ç¦» |
| Jaccard ç›¸ä¼¼åº¦ï¼ˆé›†åˆç›¸ä¼¼åº¦ï¼‰ | MinHash LSH | åˆ©ç”¨æœ€å°å“ˆå¸Œå€¼è¿‘ä¼¼é›†åˆäº¤å¹¶æ¯” |

---

### ä¸‰ã€ç®—æ³•åŸç†åˆ†æ­¥è®²è§£ï¼ˆä»¥ä½™å¼¦ç›¸ä¼¼åº¦ä¸ºä¾‹ï¼‰

#### ç¬¬ 1 æ­¥ï¼šæ„å»ºéšæœºè¶…å¹³é¢ï¼ˆRandom Hyperplanesï¼‰

- åœ¨ d ç»´ç©ºé—´éšæœºç”Ÿæˆ k ä¸ªå‘é‡ï¼Œè¿™äº›å‘é‡å……å½“è¶…å¹³é¢çš„**æ³•å‘é‡ï¼ˆNormal Vectorï¼‰**ã€‚
  $$
  ( r_1, r_2, \ldots, r_k )
  $$
  æ¯ä¸ªå‘é‡çš„åˆ†é‡æœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒ
  $$
   N(0,1) 
  $$
  
- æ¯ä¸ªéšæœºå‘é‡ $r_i$ å”¯ä¸€ç¡®å®šäº†ä¸€ä¸ªç»è¿‡åŸç‚¹ä¸”ä¸å…¶å‚ç›´çš„è¶…å¹³é¢ã€‚æˆ‘ä»¬é€šè¿‡åˆ¤æ–­æ•°æ®ç‚¹ä½äºè¯¥è¶…å¹³é¢çš„å“ªä¸€ä¾§æ¥è¿›è¡Œå“ˆå¸Œç¼–ç ã€‚

---

#### ç¬¬ 2 æ­¥ï¼šè®¡ç®—å“ˆå¸Œç­¾åï¼ˆHash Signatureï¼‰

å¯¹äºä¸€ä¸ªå‘é‡ $x$ï¼Œæˆ‘ä»¬è®¡ç®—å®ƒä¸ $k$ ä¸ªè¶…å¹³é¢çš„æ³•å‘é‡ $r_i$ çš„ç‚¹ç§¯ã€‚æ ¹æ®ç‚¹ç§¯ç»“æœçš„æ­£è´Ÿï¼Œç”Ÿæˆå¯¹åº”çš„äºŒè¿›åˆ¶ä½ï¼š

$$
h_i(x) =
\begin{cases}
1, & \text{if } r_i \cdot x \ge 0 \\
0, & \text{otherwise}
\end{cases}
$$

å°†è¿™ $k$ ä¸ªç»“æœæ‹¼æ¥èµ·æ¥ï¼Œå°±å½¢æˆäº†ä¸€ä¸ªé•¿åº¦ä¸º $k$ çš„äºŒè¿›åˆ¶ä¸²ï¼ˆä¾‹å¦‚ `10100110`ï¼‰ã€‚è¿™ä¸ªäºŒè¿›åˆ¶ä¸²å°±æ˜¯å‘é‡ $x$ çš„ **å“ˆå¸Œç­¾å**ã€‚

> âœ… **ç›´è§‰**ï¼šä¸¤ä¸ªå‘é‡çš„å¤¹è§’è¶Šå°ï¼Œè¢«éšæœºè¶…å¹³é¢åˆ†å¼€çš„æ¦‚ç‡è¶Šä½ï¼ˆæ›´å¯èƒ½åœ¨åŒä¾§ï¼‰ï¼Œå› æ­¤å“ˆå¸Œç­¾åè¶Šç›¸ä¼¼ã€‚

---

#### ç¬¬ 3 æ­¥ï¼šæ„å»ºå¤šä¸ªå“ˆå¸Œè¡¨ï¼ˆMulti-Table Strategyï¼‰

- ä¸ºäº†å‡å°‘ç¢°æ’é”™è¯¯ï¼ˆä¸åŒå‘é‡å“ˆå¸Œç›¸åŒï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šç»„ç‹¬ç«‹å“ˆå¸Œå‡½æ•°ã€‚
- å‡è®¾æœ‰ï¼š
  - æ¯ç»„ k ä¸ªå“ˆå¸Œå‡½æ•°ç»„æˆä¸€ä¸ª **å“ˆå¸Œè¡¨ï¼ˆhash tableï¼‰**ã€‚åœ¨æ¯ä¸ªå“ˆå¸Œè¡¨ä¸­ï¼Œ**å“ˆå¸Œç­¾å**ï¼ˆå³é‚£ä¸ª $k$ ä½äºŒè¿›åˆ¶ä¸²ï¼‰ç›¸åŒçš„å‘é‡ï¼Œä¼šè¢«æ”¾åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªâ€œå“ˆå¸Œæ¡¶â€ã€‚
  - å…± L ä¸ªè¿™æ ·çš„è¡¨ã€‚

æ¯ä¸ªæ ·æœ¬è¢«æ’å…¥åˆ° $L$ ä¸ªå“ˆå¸Œè¡¨å¯¹åº”çš„æ¡¶ä¸­ï¼Œä»è€Œæå‡å¬å›ç‡ã€‚

---

#### ç¬¬ 4 æ­¥ï¼šæŸ¥è¯¢ï¼ˆQueryï¼‰

ç»™å®šæŸ¥è¯¢å‘é‡ $q$ï¼š

1. è®¡ç®— $q$ åœ¨ $L$ ä¸ªå“ˆå¸Œè¡¨ä¸­çš„ç­¾åï¼›
2. æ‰¾å‡ºè¿™ $L$ ä¸ªè¡¨ä¸­æ‰€æœ‰å¯¹åº” **â€œæ¡¶â€** é‡Œçš„å‘é‡ï¼Œåˆå¹¶ä½œä¸ºå€™é€‰é›†ï¼›
3. å¯¹å€™é€‰é›†ä¸­çš„å‘é‡è®¡ç®—çœŸå®ç›¸ä¼¼åº¦ï¼ˆå¦‚ä½™å¼¦æˆ–æ¬§å¼è·ç¦»ï¼‰ï¼›
4. è¿”å›ç›¸ä¼¼åº¦æœ€é«˜çš„ Top-Kã€‚

---

### å››ã€å‚æ•°ä¸æ€§èƒ½æƒè¡¡

| å‚æ•° | å«ä¹‰ | å½±å“ |
|------|------|------|
| k | æ¯ç»„å“ˆå¸Œå‡½æ•°æ•°é‡ | è¶Šå¤§ â†’ æ¡¶æ›´å°ï¼Œå¬å›ç‡ä¸‹é™ä½†ç²¾åº¦æé«˜ |
| L | å“ˆå¸Œè¡¨æ•°é‡ | è¶Šå¤š â†’ å¬å›ç‡ä¸Šå‡ä½†å†…å­˜æ¶ˆè€—å¤§ |
| n | æ ·æœ¬æ•°é‡ | å½±å“æŸ¥è¯¢é€Ÿåº¦ï¼Œè¶Šå¤šæ”¶ç›Šè¶Šæ˜æ˜¾ |

ä¸€èˆ¬ç»éªŒå€¼ï¼š
- **k** = 10ï½20  
- **L** = 20ï½100  

---

### äº”ã€ç®—æ³•å¤æ‚åº¦åˆ†æ

| é˜¶æ®µ | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ |
|------|-------------|-------------|
| å»ºè¡¨ |  $O(nLk)$  |  $O(nL)$  |
| æŸ¥è¯¢ |  $O(L(k + c))$ ï¼Œå…¶ä¸­ c ä¸ºå€™é€‰æ•°é‡ | - |

ç›¸æ¯”æš´åŠ›æœç´¢  $O(n)$ ï¼ŒLSH æŸ¥è¯¢å¤æ‚åº¦å¯è¾¾ **äºšçº¿æ€§çº§ï¼ˆå¦‚ $O(n^{0.5})$ï¼‰**ã€‚

---



## 2.LSHç®—æ³•å®ç°

ğŸ§  LSHç®—æ³•Pythonå®ç°

```python
import numpy as np
from typing import List, Union, Dict


class CosineLSH:
    """
    åŸºäºéšæœºè¶…å¹³é¢æŠ•å½±çš„å±€éƒ¨æ•æ„Ÿå“ˆå¸Œï¼ˆLSHï¼‰ï¼Œé€‚ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦æµ‹é‡ã€‚
    
    å‚æ•°:
        hash_size (int): å•ä¸ªå“ˆå¸Œè¡¨çš„å“ˆå¸Œå‡½æ•°æ•°é‡ï¼ˆå³å“ˆå¸Œç çš„ä½æ•°ï¼‰
        num_tables (int): ä½¿ç”¨çš„å“ˆå¸Œè¡¨æ•°é‡
    """
    
    def __init__(self, hash_size: int = 6, num_tables: int = 5):
        self.hash_size = hash_size  # æ¯ä¸ªå“ˆå¸Œè¡¨çš„ä½æ•°
        self.num_tables = num_tables  # å“ˆå¸Œè¡¨æ•°é‡
        self.hash_tables = [dict() for _ in range(num_tables)]  # åˆå§‹åŒ–å“ˆå¸Œè¡¨
        self.random_planes_list = []  # å­˜å‚¨æ¯ä¸ªå“ˆå¸Œè¡¨çš„éšæœºè¶…å¹³é¢
        self.dimension = None  # æ•°æ®ç»´åº¦ï¼ˆåœ¨æ’å…¥æ•°æ®æ—¶ç¡®å®šï¼‰
        self.data = None  # å­˜å‚¨æ•°æ®å‘é‡ï¼ˆä¾¿äºåç»­ä½¿ç”¨å’Œè°ƒè¯•ï¼‰
    
    def _generate_random_planes(self, dimension: int) -> np.ndarray:
        """ä¸ºå•ä¸ªå“ˆå¸Œè¡¨ç”Ÿæˆéšæœºè¶…å¹³é¢ï¼ˆæ¯ä¸ªè¶…å¹³é¢å¯¹åº”ä¸€ä¸ªå“ˆå¸Œå‡½æ•°ï¼‰"""
        return np.random.randn(self.hash_size, dimension)
    
    def _hash(self, vector: np.ndarray, random_planes: np.ndarray) -> str:
        """è®¡ç®—å•ä¸ªå‘é‡çš„å“ˆå¸Œé”®ï¼ˆäºŒè¿›åˆ¶å­—ç¬¦ä¸²ï¼‰"""
        # è®¡ç®—å‘é‡ä¸æ¯ä¸ªéšæœºè¶…å¹³é¢çš„ç‚¹ç§¯ï¼Œæ ¹æ®ç¬¦å·ç”ŸæˆäºŒè¿›åˆ¶ä½
        projections = np.dot(vector, random_planes.T)
        hash_bits = (projections > 0).astype(int)  # å¤§äº0ä¸º1ï¼Œå¦åˆ™ä¸º0
        return ''.join(hash_bits.astype(str))  # è½¬æ¢ä¸ºäºŒè¿›åˆ¶å­—ç¬¦ä¸²ä½œä¸ºå“ˆå¸Œé”®
    
    def index(self, data: Union[List[List[float]], np.ndarray]) -> None:
        """
        å°†æ•°æ®å‘é‡æ’å…¥LSHç´¢å¼•ä¸­
        
        å‚æ•°:
            data: å¾…ç´¢å¼•çš„å‘é‡åˆ—è¡¨æˆ–æ•°ç»„
        """
        data_array = np.array(data)
        if len(data_array.shape) == 1:
            data_array = data_array.reshape(1, -1)
        
        self.dimension = data_array.shape[1]  # è®¾ç½®æ•°æ®ç»´åº¦
        self.data = data_array  # å­˜å‚¨æ•°æ®ï¼ˆä¾¿äºåç»­ä½¿ç”¨å’Œè°ƒè¯•ï¼‰
        
        # ä¸ºæ¯ä¸ªå“ˆå¸Œè¡¨ç”Ÿæˆéšæœºè¶…å¹³é¢
        self.random_planes_list = [
            self._generate_random_planes(self.dimension) 
            for _ in range(self.num_tables)
        ]
        
        # å°†æ¯ä¸ªå‘é‡æ’å…¥æ‰€æœ‰å“ˆå¸Œè¡¨
        for i, vector in enumerate(data_array):
            for table_idx in range(self.num_tables):
                hash_key = self._hash(vector, self.random_planes_list[table_idx])
                
                # å°†å‘é‡ç´¢å¼•å­˜å…¥å¯¹åº”å“ˆå¸Œæ¡¶
                if hash_key in self.hash_tables[table_idx]:
                    self.hash_tables[table_idx][hash_key].append(i)
                else:
                    self.hash_tables[table_idx][hash_key] = [i]
    
    def query(self, query_vector: Union[List[float], np.ndarray], 
              max_results: int = 10, 
              return_all_candidates: bool = False,
              sort_by_distance: bool = False,
              return_distances: bool = False):
        """
        æŸ¥è¯¢ä¸ç»™å®šå‘é‡ç›¸ä¼¼çš„å‘é‡
        
        å‚æ•°:
            query_vector: æŸ¥è¯¢å‘é‡
            max_results: è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡ï¼ˆå½“return_all_candidates=Falseæ—¶ç”Ÿæ•ˆï¼‰
            return_all_candidates: æ˜¯å¦è¿”å›æ‰€æœ‰å€™é€‰å‘é‡ï¼ˆé»˜è®¤Falseï¼‰
            sort_by_distance: æ˜¯å¦æŒ‰è·ç¦»æ’åºï¼ˆé»˜è®¤Falseï¼‰
            return_distances: æ˜¯å¦è¿”å›è·ç¦»ï¼ˆé»˜è®¤Falseï¼‰
            
        è¿”å›:
            å¦‚æœreturn_distances=False: ç›¸ä¼¼å‘é‡çš„ç´¢å¼•åˆ—è¡¨
            å¦‚æœreturn_distances=True: (ç´¢å¼•åˆ—è¡¨, è·ç¦»æ•°ç»„) çš„å…ƒç»„
        """
        if self.dimension is None:
            raise ValueError("è¯·å…ˆä½¿ç”¨indexæ–¹æ³•æ’å…¥æ•°æ®")
        
        query_vec = np.array(query_vector)
        candidates = set()
        
        # åœ¨æ‰€æœ‰å“ˆå¸Œè¡¨ä¸­æŸ¥æ‰¾å€™é€‰å‘é‡
        for table_idx in range(self.num_tables):
            hash_key = self._hash(query_vec, self.random_planes_list[table_idx])
            if hash_key in self.hash_tables[table_idx]:
                candidates.update(self.hash_tables[table_idx][hash_key])
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å€™é€‰å‘é‡ï¼Œå°è¯•æŸ¥æ‰¾é‚»è¿‘æ¡¶
        if not candidates:
            print("æœªæ‰¾åˆ°ç²¾ç¡®åŒ¹é…çš„å€™é€‰å‘é‡ï¼Œæ­£åœ¨æœç´¢é‚»è¿‘æ¡¶...")
            for table_idx in range(self.num_tables):
                original_key = self._hash(query_vec, self.random_planes_list[table_idx])
                # æŸ¥æ‰¾å“ˆå¸Œç åªæœ‰1ä½ä¸åŒçš„æ¡¶
                for i in range(self.hash_size):
                    neighbor_key = list(original_key)
                    neighbor_key[i] = '1' if neighbor_key[i] == '0' else '0'
                    neighbor_key = ''.join(neighbor_key)
                    if neighbor_key in self.hash_tables[table_idx]:
                        candidates.update(self.hash_tables[table_idx][neighbor_key])
        
        if not candidates:
            if return_distances:
                return np.array([], dtype=int), np.array([])
            return []
        
        cand_ids = np.array(list(candidates), dtype=int)
        
        # å¦‚æœéœ€è¦æ’åºï¼Œè®¡ç®—è·ç¦»å¹¶æ’åº
        if sort_by_distance:
            dists = np.linalg.norm(self.data[cand_ids] - query_vec, axis=1)
            sorted_indices = np.argsort(dists)
            cand_ids = cand_ids[sorted_indices]
            if return_distances:
                dists = dists[sorted_indices]
        
        # å†³å®šè¿”å›å¤šå°‘ä¸ªç»“æœ
        if not return_all_candidates:
            cand_ids = cand_ids[:max_results]
            if sort_by_distance and return_distances:
                dists = dists[:max_results]
        
        if return_distances:
            return cand_ids, dists
        return list(cand_ids)
    
    def get_hash_tables_info(self) -> Dict:
        """è¿”å›å“ˆå¸Œè¡¨çš„ç»Ÿè®¡ä¿¡æ¯"""
        info = {
            'num_tables': self.num_tables,
            'hash_size': self.hash_size,
            'total_buckets': 0,
            'average_bucket_size': 0,
            'table_details': []
        }
        
        total_vectors = 0
        for i, table in enumerate(self.hash_tables):
            num_buckets = len(table)
            vectors_in_table = sum(len(bucket) for bucket in table.values())
            total_vectors += vectors_in_table
            
            avg_size = vectors_in_table / num_buckets if num_buckets > 0 else 0
            info['table_details'].append({
                'table_index': i,
                'num_buckets': num_buckets,
                'total_vectors': vectors_in_table,
                'average_bucket_size': avg_size
            })
        
        info['total_buckets'] = sum(detail['num_buckets'] 
                                  for detail in info['table_details'])
        if info['total_buckets'] > 0:
            info['average_bucket_size'] = (total_vectors / 
                                         info['total_buckets'])
        
        return info
    
    def query_with_topk(self, query_vector: Union[List[float], np.ndarray], k: int = 5):
        """
        æŸ¥è¯¢å¹¶è¿”å›å€™é€‰é›†å’ŒTop-kç»“æœï¼ˆä¾¿æ·æ–¹æ³•ï¼Œç”¨äºå¯è§†åŒ–ï¼‰
        
        å‚æ•°:
            query_vector: æŸ¥è¯¢å‘é‡
            k: è¿”å›çš„Top-kæ•°é‡
            
        è¿”å›:
            (å€™é€‰IDæ•°ç»„, Top-k IDæ•°ç»„) çš„å…ƒç»„
        """
        # è·å–æ‰€æœ‰å€™é€‰å‘é‡
        all_candidates = self.query(query_vector, return_all_candidates=True, sort_by_distance=False)
        
        if len(all_candidates) == 0:
            return np.array([], dtype=int), np.array([], dtype=int)
        
        # è®¡ç®—Top-k
        cand_ids = np.array(all_candidates, dtype=int)
        dists = np.linalg.norm(self.data[cand_ids] - np.array(query_vector), axis=1)
        topk = cand_ids[np.argsort(dists)[:k]]
        
        return cand_ids, topk
    
    def _query_single_table(self, query_vec, table_idx):
        """æŸ¥è¯¢å•å¼ å“ˆå¸Œè¡¨ï¼Œè¿”å›å€™é€‰ç‚¹IDé›†åˆï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
        hash_key = self._hash(query_vec, self.random_planes_list[table_idx])
        return set(self.hash_tables[table_idx].get(hash_key, []))
    
    def _compute_topk_from_candidates(self, query_vec, candidate_ids, k):
        """ä»å€™é€‰é›†ä¸­è®¡ç®—Top-kæœ€è¿‘é‚»ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
        if len(candidate_ids) == 0:
            return np.array([], dtype=int)
        dists = np.linalg.norm(self.data[candidate_ids] - query_vec, axis=1)
        return candidate_ids[np.argsort(dists)[:k]]
    
    def compute_matches(self, query_vec):
        """
        è®¡ç®—æ‰€æœ‰æ•°æ®ç‚¹ä¸æŸ¥è¯¢ç‚¹çš„å“ˆå¸ŒåŒ¹é…æƒ…å†µï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        
        è¿”å›:
            bits: æ•°æ®ç‚¹å“ˆå¸Œç¼–ç  (N, L, Bits)
            q_bits: æŸ¥è¯¢ç‚¹å“ˆå¸Œç¼–ç  (L, Bits)
            matches: æ¯ä¸ªç‚¹åœ¨æ¯å¼ è¡¨æ˜¯å¦åŒ¹é… (N, L)
            hit_counts: æ¯ä¸ªç‚¹å‘½ä¸­çš„è¡¨æ•° (N,)
            candidates: è‡³å°‘å‘½ä¸­ä¸€å¼ è¡¨çš„ç‚¹ç´¢å¼•
        """
        if self.data is None:
            raise ValueError("è¯·å…ˆä½¿ç”¨indexæ–¹æ³•æ’å…¥æ•°æ®")
        
        # å°†random_planes_listè½¬æ¢ä¸º(n_tables, hash_size, dimension)æ ¼å¼
        planes = np.array(self.random_planes_list)  # (num_tables, hash_size, dimension)
        
        # è®¡ç®—æŠ•å½±: (N, num_tables, hash_size)
        proj = np.dot(self.data, planes.transpose(0, 2, 1))
        q_proj = np.dot(query_vec, planes.transpose(0, 2, 1))
        
        bits = proj > 0
        q_bits = q_proj > 0
        matches = np.all(bits == q_bits, axis=2)
        hit_counts = matches.sum(axis=1)
        return bits, q_bits, matches, hit_counts, np.where(hit_counts > 0)[0]
    
    @property
    def planes(self):
        """è¿”å›è¶…å¹³é¢æ•°ç»„ï¼Œæ ¼å¼ä¸º (num_tables, hash_size, dimension)ï¼ˆç”¨äºå¯è§†åŒ–å…¼å®¹æ€§ï¼‰"""
        if len(self.random_planes_list) == 0:
            return None
        return np.array(self.random_planes_list)
    
    @property
    def num_bits(self):
        """è¿”å›å“ˆå¸Œä½æ•°ï¼ˆç”¨äºå¯è§†åŒ–å…¼å®¹æ€§ï¼‰"""
        return self.hash_size


# ç¤ºä¾‹ä½¿ç”¨å’Œæµ‹è¯•
if __name__ == "__main__":
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    np.random.seed(42)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°
    data_vectors = np.random.randn(100, 10)  # 100ä¸ª10ç»´å‘é‡
    
    # åˆ›å»ºLSHç´¢å¼•
    print("æ­£åœ¨æ„å»ºLSHç´¢å¼•...")
    lsh = CosineLSH(hash_size=8, num_tables=3)
    lsh.index(data_vectors)
    
    # æ˜¾ç¤ºå“ˆå¸Œè¡¨ç»Ÿè®¡ä¿¡æ¯
    info = lsh.get_hash_tables_info()
    print(f"\nå“ˆå¸Œè¡¨ç»Ÿè®¡ä¿¡æ¯:")
    print(f"å“ˆå¸Œè¡¨æ•°é‡: {info['num_tables']}")
    print(f"æ€»æ¡¶æ•°: {info['total_buckets']}")
    print(f"å¹³å‡æ¯ä¸ªæ¡¶çš„å‘é‡æ•°: {info['average_bucket_size']:.2f}")
    
    # æŸ¥è¯¢ç¤ºä¾‹
    query_vec = data_vectors[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå‘é‡ä½œä¸ºæŸ¥è¯¢
    print(f"\næŸ¥è¯¢å‘é‡ç´¢å¼•: 0")
    
    similar_indices = lsh.query(query_vec, max_results=5)
    print(f"æ‰¾åˆ°çš„ç›¸ä¼¼å‘é‡ç´¢å¼•: {similar_indices}")
    
    # éªŒè¯ç»“æœï¼šè®¡ç®—å®é™…ä½™å¼¦ç›¸ä¼¼åº¦
    from sklearn.metrics.pairwise import cosine_similarity
    
    print("\nç›¸ä¼¼åº¦éªŒè¯:")
    for idx in similar_indices:
        similarity = cosine_similarity([query_vec], [data_vectors[idx]])[0][0]
        print(f"å‘é‡ {idx} ä¸æŸ¥è¯¢å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦: {similarity:.4f}")
    
    # å¯¹æ¯”çº¿æ€§æœç´¢ç»“æœ
    print("\n=== ä¸çº¿æ€§æœç´¢å¯¹æ¯” ===")
    all_similarities = cosine_similarity([query_vec], data_vectors)[0]
    top_linear = np.argsort(all_similarities)[::-1][1:6]  # æ’é™¤è‡ªèº«ï¼Œå–å‰5ä¸ª
    print(f"çº¿æ€§æœç´¢Top-5ç»“æœ: {top_linear}")
    
    # è®¡ç®—å¬å›ç‡
    lsh_recall = len(set(similar_indices) & set(top_linear)) / len(top_linear)
    print(f"LSHå¬å›ç‡ï¼ˆä¸çœŸå®Top-5ç›¸æ¯”ï¼‰: {lsh_recall:.2%}")
```

è¿è¡Œæ¼”ç¤ºï¼š
```
æ­£åœ¨æ„å»ºLSHç´¢å¼•...

å“ˆå¸Œè¡¨ç»Ÿè®¡ä¿¡æ¯:
å“ˆå¸Œè¡¨æ•°é‡: 3
æ€»æ¡¶æ•°: 189
å¹³å‡æ¯ä¸ªæ¡¶çš„å‘é‡æ•°: 1.59

æŸ¥è¯¢å‘é‡ç´¢å¼•: 0
æ‰¾åˆ°çš„ç›¸ä¼¼å‘é‡ç´¢å¼•: [0, 48, 20, 54, 86]

ç›¸ä¼¼åº¦éªŒè¯:
å‘é‡ 0 ä¸æŸ¥è¯¢å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦: 1.0000
å‘é‡ 48 ä¸æŸ¥è¯¢å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦: -0.2653
å‘é‡ 20 ä¸æŸ¥è¯¢å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦: 0.5041
å‘é‡ 54 ä¸æŸ¥è¯¢å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦: 0.4609
å‘é‡ 86 ä¸æŸ¥è¯¢å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦: 0.6143

=== ä¸çº¿æ€§æœç´¢å¯¹æ¯” ===
çº¿æ€§æœç´¢Top-5ç»“æœ: [91 32 15 86 20]
LSHå¬å›ç‡ï¼ˆä¸çœŸå®Top-5ç›¸æ¯”ï¼‰: 40.00%
```

## 3.LSHç®—æ³•å¯è§†åŒ–
```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import gridspec
from matplotlib.patches import Rectangle
from pathlib import Path

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

# ä¸ºäº†åç»­å¯è§†åŒ–æ–¹ä¾¿ï¼Œè¿™é‡Œç»Ÿä¸€é…ç½®é¢œè‰²å’Œç»˜å›¾é…ç½®ã€‚
# é¢œè‰²é…ç½®
COLORS = {
    "data": "#E0E0E0",      # æ•°æ®ç‚¹é¢œè‰²ï¼ˆæµ…ç°è‰²ï¼‰
    "query": "#FFD93D",     # æŸ¥è¯¢ç‚¹é¢œè‰²ï¼ˆäº®é»„è‰²ï¼‰
    "candidates": "#777777", # å€™é€‰ç‚¹é¢œè‰²ï¼ˆä¸­ç°è‰²ï¼‰
    "tables": ["#E74C3C", "#3498DB", "#9B59B6"],  # ä¸åŒå“ˆå¸Œè¡¨çš„é¢œè‰²æ ‡è¯†
    "hits": ["#A8DADC", "#76C893", "#4A7C59"],    # å‘½ä¸­æ¬¡æ•°å¯¹åº”çš„é¢œè‰²æ¸å˜
    "planes": ["#A8DADC", "#3498DB", "#9B59B6", "#2ECC71"],  # è¶…å¹³é¢é¢œè‰²å¾ªç¯ä½¿ç”¨
    "hash_table": {
        "match_bg": "#8FBC8F",      # å“ˆå¸Œç åŒ¹é…çš„èƒŒæ™¯è‰²
        "no_match_bg": "#FAFAFA",  # å“ˆå¸Œç ä¸åŒ¹é…çš„èƒŒæ™¯è‰²
        "match_border": "#43A047", # å“ˆå¸Œç åŒ¹é…çš„è¾¹æ¡†è‰²
        "no_match_border": "#E0E0E0", # å“ˆå¸Œç ä¸åŒ¹é…çš„è¾¹æ¡†è‰²
        "no_hit_text": "#999",     # æœªå‘½ä¸­æ—¶çš„æ–‡å­—é¢œè‰²
    },
}

# ç»˜å›¾é…ç½®
PLOT_CONFIG = {
    "figsize": (16, 10),
    "fontsize": {"title": 11, "legend": 8, "text": 10, "suptitle": 16, "panel_title": 12},
    "alpha": {
        "data": 0.4,    # æ•°æ®ç‚¹é€æ˜åº¦
        "candidates": 0.9,     # å€™é€‰ç‚¹é€æ˜åº¦ï¼ˆè¾ƒä¸é€æ˜ï¼Œçªå‡ºæ˜¾ç¤ºï¼‰
        "hits": 0.8,           # å‘½ä¸­ç‚¹é€æ˜åº¦ï¼ˆä¸­ç­‰é€æ˜åº¦ï¼‰
        "planes": 0.8,         # è¶…å¹³é¢é€æ˜åº¦ï¼ˆæ¸…æ™°å¯è§ä½†ä¸æŠ¢é•œï¼‰
        "bbox": 0.9,           # æ–‡æœ¬æ¡†èƒŒæ™¯é€æ˜åº¦
        "grid": 0.2            # ç½‘æ ¼çº¿é€æ˜åº¦ï¼ˆå¾ˆæ·¡ï¼Œåªåšå‚è€ƒï¼‰
    },
    "sizes": {"data": 20, "query": 120, "candidates": 60, "hit_points": 50},
    "ground_truth": {
        "face": "none",        # Ground truthç‚¹å¡«å……è‰²ï¼ˆç©ºå¿ƒï¼‰
        "edge": "#FF8C00",     # Ground truthç‚¹è¾¹æ¡†è‰²ï¼ˆæ·±æ©™è‰²ï¼‰
        "text": "#FF8C00",     # Ground truthæ–‡æœ¬é¢œè‰²ï¼ˆæ·±æ©™è‰²ï¼‰
        "marker": "s",         # Ground truthç‚¹å½¢çŠ¶ï¼ˆæ–¹æ¡†ï¼‰
        "alpha": 0.95,         # Ground truthç‚¹é€æ˜åº¦
        "size": 100,        # ç»Ÿä¸€çš„ground truthç‚¹å¤§å°
        "linewidth": 1,   # ç»Ÿä¸€çš„çº¿æ¡ç²—ç»†
        "zorder": 8,     # ç»Ÿä¸€çš„å›¾å±‚å±‚çº§
    },
    "grid": {
        "hspace": 0.3,    # å­å›¾å‚ç›´é—´è·
        "wspace": 0.25    # å­å›¾æ°´å¹³é—´è·
    },
    "table_wspace": 0.15,  # å¤šè¡¨å“ˆå¸Œå­å›¾é—´è·
    "contour_resolution": 200,  # èƒŒæ™¯ç½‘æ ¼åˆ†è¾¨ç‡
    "save": {"dpi": 150},
    "planes": {
        "linewidth": 2.5,
        "arrow": {          # è¶…å¹³é¢æ³•å‘é‡ç®­å¤´å®šä½å‚æ•°
            "scale": 0.12,   # ç®­å¤´å¤§å°ç¼©æ”¾å› å­
            "t_min": 0.05,   # ç®­å¤´ä½ç½®æœ€å°åç§»
            "t_max": 0.33,   # ç®­å¤´ä½ç½®æœ€å¤§åç§»
            "t_base": 0.25,  # ç®­å¤´ä½ç½®åŸºç¡€åç§»
            "t_step": 0.04   # å¤šç®­å¤´é—´çš„åç§»æ­¥é•¿
        }
    },
    "layout": {
        "subplots_adjust": {  # å­å›¾æ•´ä½“ä½ç½®è°ƒæ•´
            "top": 0.92, "bottom": 0.06, "left": 0.05, "right": 0.98
        }
    }
}




def _line_in_box(w, xlim, ylim):
    """è®¡ç®—è¶…å¹³é¢ wÂ·x=0 ä¸ç»˜å›¾è¾¹ç•Œæ¡†çš„äº¤ç‚¹ï¼Œè¿”å›çº¿æ®µä¸¤ç«¯ç‚¹"""
    pts = []
    eps = 1e-12
    # ä¸å·¦å³è¾¹ç•Œ (x=å¸¸æ•°) æ±‚äº¤
    if abs(w[1]) > eps:
        for x in xlim:
            y = -w[0] * x / w[1]
            if ylim[0] - 1e-9 <= y <= ylim[1] + 1e-9:
                pts.append([x, y])
    # ä¸ä¸Šä¸‹è¾¹ç•Œ (y=å¸¸æ•°) æ±‚äº¤
    if abs(w[0]) > eps:
        for y in ylim:
            x = -w[1] * y / w[0]
            if xlim[0] - 1e-9 <= x <= xlim[1] + 1e-9:
                pts.append([x, y])
    if len(pts) < 2:
        return None
    # å»é‡ï¼šä¿ç•™ç¬¬ä¸€ä¸ªç‚¹ï¼Œç„¶åæ·»åŠ ä¸ç¬¬ä¸€ä¸ªç‚¹ä¸æ¥è¿‘çš„ç‚¹
    unique = [pts[0]]
    for p in pts[1:]:
        if not np.allclose(p, unique[0]):
            unique.append(p)
            if len(unique) >= 2:
                break
    return (np.array(unique[0]), np.array(unique[1])) if len(unique) >= 2 else None

def _draw_hyperplanes(ax, planes, xlim, ylim, query, span, colors, table_idx=0, show_arrows=True):
    """ç»˜åˆ¶è¶…å¹³é¢åŠå…¶æ ‡æ³¨"""
    for i, p in enumerate(planes):
        seg = _line_in_box(p, xlim, ylim)
        if not seg:
            continue
        p1, p2 = seg

        # Panel 1: å…³æ³¨ä¸åŒè¶…å¹³é¢åˆ‡åˆ†ï¼Œæ¯ä¸ªè¶…å¹³é¢ç”¨ä¸åŒé¢œè‰²ï¼ŒPanel 2: å…³æ³¨ä¸åŒçš„åˆ‡åˆ†æ•ˆæœï¼Œæ¯ä¸ªè¡¨ç”¨ä¸€ç§é¢œè‰²
        color = colors["planes"][i] if show_arrows else colors["tables"][table_idx]
        label = f"è¶…å¹³é¢ {i+1}" if show_arrows else (f"T{table_idx+1} è¶…å¹³é¢" if i == 0 else None)

        ax.plot([p1[0], p2[0]], [p1[1], p2[1]], c=color, lw=PLOT_CONFIG["planes"]["linewidth"], alpha=PLOT_CONFIG["alpha"]["planes"], label=label)

        if show_arrows and table_idx == 0:
            # ç»˜åˆ¶æ³•å‘é‡ç®­å¤´ï¼ˆåªåœ¨Panel 1æ˜¾ç¤ºï¼‰
            low, high = (p1, p2) if p1[1] <= p2[1] else (p2, p1)
            n_hat = p / (np.linalg.norm(p) + 1e-12)
            side = 1.0 if np.dot(query, p) >= 0 else -1.0
            arrow_config = PLOT_CONFIG["planes"]["arrow"]
            t = np.clip(arrow_config["t_base"] + (i - (len(planes) - 1) / 2) * arrow_config["t_step"], arrow_config["t_min"], arrow_config["t_max"])
            base = low + (high - low) * t
            arrow = side * n_hat * arrow_config["scale"] * span
            ax.annotate("", xy=base + arrow, xytext=base,
                       arrowprops=dict(arrowstyle="-|>", color=color, lw=2.5), zorder=6)
            ax.text(*(base + arrow * 1.15), f"n{i+1}={'1' if side >= 0 else '0'}",
                   fontsize=9, fontweight="bold", c=color, ha="center",
                   bbox=dict(boxstyle="round,pad=0.15", fc="w", ec="none", alpha=PLOT_CONFIG["alpha"]["bbox"]), zorder=7)

def setup_plot(ax, xlim, ylim, data, query, title="", data_alpha=None, data_color=None, data_size=None, query_label=True):
    """ç»Ÿä¸€çš„ç»˜å›¾è®¾ç½®å‡½æ•°ï¼šåˆå§‹åŒ–å­å›¾å¹¶ç»˜åˆ¶æ•°æ®ç‚¹å’ŒæŸ¥è¯¢ç‚¹"""
    ax.set(xlim=xlim, ylim=ylim, aspect="equal")
    if title:
        ax.set_title(title, fontsize=PLOT_CONFIG["fontsize"]["title"], fontweight="bold")
    
    # ç»˜åˆ¶æ•°æ®ç‚¹
    ax.scatter(data[:, 0], data[:, 1], 
              c=data_color or COLORS["data"],
              s=data_size or PLOT_CONFIG["sizes"]["data"],
              alpha=data_alpha or PLOT_CONFIG["alpha"]["data"],
              zorder=1)
    
    # ç»˜åˆ¶æŸ¥è¯¢ç‚¹
    ax.scatter(*query, c=COLORS["query"], marker="*", 
              s=PLOT_CONFIG["sizes"]["query"],
              ec="k", lw=1.5, zorder=10,
              label="æŸ¥è¯¢ç‚¹" if query_label else None)

def draw_candidates(ax, data, matches_or_hits, table_idx=None, lsh=None, size=None, alpha=None, show_prefix=True):
    """ç»˜åˆ¶å€™é€‰ç‚¹ï¼štable_idxæŒ‡å®šæ—¶æŒ‰è¡¨ç€è‰²ï¼Œå¦åˆ™æŒ‰å‘½ä¸­æ¬¡æ•°ç€è‰²"""
    size = size or PLOT_CONFIG["sizes"]["candidates"]
    alpha = alpha or PLOT_CONFIG["alpha"]["candidates"]
    
    if table_idx is not None:
        # æŒ‰è¡¨ç€è‰²
        matches = matches_or_hits
        if matches[:, table_idx].any():
            pts = data[matches[:, table_idx]]
            prefix = f"T{table_idx+1} " if show_prefix else ""
            ax.scatter(pts[:, 0], pts[:, 1], c=COLORS["candidates"], s=size, alpha=alpha,
                      ec="w", lw=1, zorder=5, label=f"{prefix}å€™é€‰ ({len(pts)})")
    else:
        # æŒ‰å‘½ä¸­æ¬¡æ•°ç€è‰²
        if lsh is None:
            raise ValueError("å½“table_idx=Noneæ—¶ï¼Œå¿…é¡»æä¾›lshå‚æ•°")
        hits = matches_or_hits
        for h in range(1, lsh.num_tables + 1):
            idx = np.where(hits == h)[0]
            if len(idx):
                ax.scatter(data[idx, 0], data[idx, 1], c=COLORS["hits"][h-1], s=size,
                          alpha=min(PLOT_CONFIG["alpha"]["hits"] + h * 0.05, 1.0),
                          ec="w", lw=1, zorder=h+2, 
                          label=f"å‘½ä¸­{h}/{lsh.num_tables} ({len(idx)}ç‚¹)")

def _setup_legend(ax, fontsize=None, loc="upper left"):
    """ç»Ÿä¸€çš„å›¾ä¾‹è®¾ç½®å‡½æ•°"""
    fontsize = fontsize or PLOT_CONFIG["fontsize"]["legend"]
    ax.legend(fontsize=fontsize, loc=loc)

def draw_ground_truth(ax, data, gt_indices, recall=None, size_scale=1.0):
    """ground Truthç»˜åˆ¶å‡½æ•°"""
    if gt_indices is None or len(gt_indices) == 0:
        return
    
    gt_config = PLOT_CONFIG["ground_truth"]
    label = f"Ground Truth (å¬å›ç‡: {recall:.1%})" if recall is not None else "Ground Truth"
    ax.scatter(data[gt_indices, 0], data[gt_indices, 1],
              c=gt_config["face"], marker=gt_config["marker"],
              s=gt_config["size"] * size_scale,
              ec=gt_config["edge"], lw=gt_config["linewidth"],
              alpha=gt_config["alpha"], label=label,
              zorder=gt_config["zorder"])


def print_lsh_statistics(lsh, data):
    """æ‰“å°LSHç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\nLSHç´¢å¼•ç»Ÿè®¡:")
    print(f"å‘é‡æ€»æ•°: {len(data)}")
    print(f"å“ˆå¸Œè¡¨æ•°é‡: {lsh.num_tables}")
    print(f"æ¯è¡¨å“ˆå¸Œä½æ•°: {lsh.hash_size}")

    # è®¡ç®—æ€»æ¡¶æ•°
    total_buckets = sum(len(table) for table in lsh.hash_tables)
    print(f"æ€»æ¡¶æ•°: {total_buckets}")

    # æ‰“å°æ¯ä¸ªè¡¨çš„è¯¦ç»†ä¿¡æ¯
    for ti, table in enumerate(lsh.hash_tables):
        avg_bucket_size = np.mean([len(bucket) for bucket in table.values()]) if table else 0
        print(f"è¡¨{ti+1}: {len(table)}ä¸ªæ¡¶, å¹³å‡æ¯ä¸ªæ¡¶{avg_bucket_size:.2f}ä¸ªå‘é‡")

def _compute_single_table_recall(lsh, query, data, gt, k, table_idx):
    """è®¡ç®—å•è¡¨çš„å¬å›ç‡"""
    single_candidates = lsh._query_single_table(query, table_idx)
    if not single_candidates:
        return 0.0
    cand_ids = np.array(list(single_candidates))
    single_topk = lsh._compute_topk_from_candidates(query, cand_ids, k)
    return len(set(single_topk) & set(gt)) / k if k else 0.0


def visualize_lsh(lsh, query_vec, k=5):
    """å¯è§†åŒ– LSH å®Œæ•´æµç¨‹"""
    if lsh.data is None:
        print("æ²¡æœ‰æ•°æ®")
        return

    data = lsh.data
    query = np.asarray(query_vec)
    n = len(data)
    bits, q_bits, matches, hits, cands = lsh.compute_matches(query)

    xlim = (data[:, 0].min() - 1, data[:, 0].max() + 1)
    ylim = (data[:, 1].min() - 1, data[:, 1].max() + 1)
    span = min(xlim[1] - xlim[0], ylim[1] - ylim[0])

    # é¢„å…ˆè®¡ç®—å¬å›ç‡ç›¸å…³æ•°æ®
    gt = np.argsort(np.linalg.norm(data - query, axis=1))[:k]  # çœŸå® Top-k
    _, lsh_topk = lsh.query_with_topk(query, k)  # LSH Top-k

    fig = plt.figure(figsize=PLOT_CONFIG["figsize"])
    gs = gridspec.GridSpec(2, 6, **PLOT_CONFIG["grid"]) 
    
    # Panel 1: ç©ºé—´åˆ’åˆ†
    ax1 = fig.add_subplot(gs[0, :2])
    setup_plot(ax1, xlim, ylim, data, query, "1. è¶…å¹³é¢ç©ºé—´åˆ’åˆ† (Table 1)")

    # ç”¨ç½‘æ ¼ç€è‰²å±•ç¤ºç©ºé—´åˆ’åˆ†
    xx, yy = np.meshgrid(np.linspace(*xlim, PLOT_CONFIG["contour_resolution"]), np.linspace(*ylim, PLOT_CONFIG["contour_resolution"]))
    gp = np.c_[xx.ravel(), yy.ravel()]
    planes = lsh.planes
    hv = np.sum((np.dot(gp, planes[0].T) > 0) * (2 ** np.arange(lsh.num_bits)), axis=1)
    ax1.contourf(xx, yy, hv.reshape(xx.shape), levels=2**lsh.num_bits, cmap="tab20", alpha=0.1)

    # ä½¿ç”¨ç»Ÿä¸€çš„è¶…å¹³é¢ç»˜åˆ¶å‡½æ•°
    _draw_hyperplanes(ax1, planes[0], xlim, ylim, query, span, COLORS, table_idx=0, show_arrows=True)

    # ç»˜åˆ¶å€™é€‰ç‚¹å’Œground truthç‚¹
    draw_candidates(ax1, data, matches, table_idx=0, show_prefix=False)
    draw_ground_truth(ax1, data, gt)

    # Hashæ¡†æ˜¾ç¤ºåœ¨å›¾å±‚æœ€ä¸Šå±‚
    ax1.annotate(f"Hash: [{''.join(q_bits[0].astype(int).astype(str))}]", xy=query, 
                 xytext=(query[0]+0.8, query[1]+0.8),
                 fontsize=10, fontweight="bold", bbox=dict(boxstyle="round,pad=0.3", fc="w", alpha=0.9),
                 arrowprops=dict(arrowstyle="->", color="gray"), zorder=20)
    _setup_legend(ax1)
    ax1.grid(True, alpha=0.2)

    # Panel 2: å¤šè¡¨ç­–ç•¥ (æ˜¾ç¤ºå•è¡¨å¬å›ç‡)
    gs2 = gridspec.GridSpecFromSubplotSpec(1, lsh.num_tables, subplot_spec=gs[0, 2:6], wspace=PLOT_CONFIG["table_wspace"])

    # è®¡ç®—æ¯ä¸ªå•è¡¨çš„å¬å›ç‡
    table_recalls = [_compute_single_table_recall(lsh, query, data, gt, k, ti) for ti in range(lsh.num_tables)]

    for ti in range(lsh.num_tables):
        ax = fig.add_subplot(gs2[0, ti])
        setup_plot(ax, xlim, ylim, data, query, f"Table {ti+1}")
        planes = lsh.planes
        _draw_hyperplanes(ax, planes[ti], xlim, ylim, query, span, COLORS, table_idx=ti, show_arrows=False)
        draw_candidates(ax, data, matches, table_idx=ti, size=PLOT_CONFIG["sizes"]["candidates"]*0.6)
        draw_ground_truth(ax, data, gt, recall=table_recalls[ti], size_scale=0.6)

        _setup_legend(ax, fontsize=PLOT_CONFIG["fontsize"]["legend"]-1)

    fig.text(0.67, 0.92, f"2. å¤šè¡¨ç­–ç•¥ (L={lsh.num_tables})", fontsize=PLOT_CONFIG["fontsize"]["panel_title"], fontweight="bold", ha="center")
    
    # Panel 3: è”åˆå¬å› (æŒ‰å‘½ä¸­æ¬¡æ•°ç€è‰²)
    ax3 = fig.add_subplot(gs[1, :2])
    setup_plot(ax3, xlim, ylim, data, query, "3. è”åˆå¬å› (æŒ‰å‘½ä¸­æ¬¡æ•°ç€è‰²)",
               data_color="lightgray", data_size=PLOT_CONFIG["sizes"]["data"]*0.5,
               data_alpha=0.3, query_label=False)
    draw_candidates(ax3, data, hits, lsh=lsh)
    # ç»˜åˆ¶ground truthç‚¹
    draw_ground_truth(ax3, data, gt)

    ax3.text(0.5, 0.02, f"å€™é€‰é›†: {len(cands)}ç‚¹ ({len(cands)/n:.0%})",
             transform=ax3.transAxes, ha="center", fontsize=10, fontweight="bold",
             bbox=dict(boxstyle="round", fc="w", alpha=PLOT_CONFIG["alpha"]["bbox"], ec="gray"))
    _setup_legend(ax3)
    
    # Panel 4: å“ˆå¸Œç¼–ç å¯¹æ¯”
    ax4 = fig.add_subplot(gs[1, 2:4])
    ax4.axis("off")
    ax4.set_title("4. å“ˆå¸Œç¼–ç å¯¹æ¯”", fontsize=PLOT_CONFIG["fontsize"]["title"], fontweight="bold")
    
    # é€‰æ‹©ä»£è¡¨æ€§çš„ç‚¹å±•ç¤º: ground truthç‚¹ + æ¯ä¸ªå‘½ä¸­è¡¨æ•°è‡³å°‘ä¸€ä¸ªç‚¹ï¼ˆä¼˜å…ˆéground truthï¼‰
    show_idx, seen_patterns, gt_set = [], set(), set(gt)
    
    def add(idx):
        pattern = tuple(tuple(bits[int(idx), ti].astype(int)) for ti in range(lsh.num_tables))
        if pattern not in seen_patterns:
            show_idx.append(int(idx))
            seen_patterns.add(pattern)
            return True
    
    # æ·»åŠ ground truthç‚¹
    for idx in gt:
        add(idx)
    
    # ä¸ºæ¯ä¸ªå‘½ä¸­è¡¨æ•°è‡³å°‘é€‰ä¸€ä¸ªç‚¹ï¼ˆä¼˜å…ˆéground truthï¼‰
    for h in range(lsh.num_tables, -1, -1):
        candidates = np.where(hits == h)[0]
        if len(candidates) == 0:
            continue
        for idx in sorted(candidates, key=lambda x: int(x) in gt_set):
            if add(idx):
                break
    
    if show_idx:
        xs = [1.8 * i for i in range(lsh.num_tables + 2)]
        ax4.set_xlim(xs[0] - 1, xs[-1] + 1)
        ax4.set_ylim(-(len(show_idx) + 2.5) * 0.9, 1)
        
        def cell(x, y, txt, bg=None, ec=None, lw=0, **kw):
            if bg:
                ax4.add_patch(Rectangle((x-0.8, y-0.35), 1.6, 0.7, fc=bg, ec=ec, lw=lw))
            ax4.text(x, y, txt, ha="center", va="center", **kw)
        
        headers = ["ID"] + [f"T{j+1}" for j in range(lsh.num_tables)] + ["å‘½ä¸­"]
        for i, (h, x) in enumerate(zip(headers, xs)):
            c = COLORS["tables"][i-1] if 1 <= i <= lsh.num_tables else "k"
            cell(x, 0.55, h, fontsize=9, fontweight="bold", color=c)
            if 1 <= i <= lsh.num_tables:
                ax4.add_patch(Rectangle((x-0.85, 0.25), 1.7, 0.6,
                              fc=["#FFEBEE", "#E3F2FD", "#F3E5F5"][(i-1)%3], ec=c, lw=2, zorder=-1))
        
        ax4.add_patch(Rectangle((xs[0]-0.5, -0.9), xs[-1]-xs[0]+1, 0.8, fc="#FFF9C4", ec=COLORS["query"], lw=2))
        cell(xs[0], -0.5, "Query", fontsize=9, fontweight="bold", color="#F57F17")
        for ti in range(lsh.num_tables):
            cell(xs[ti+1], -0.5, ''.join(q_bits[ti].astype(int).astype(str)), 
                 fontsize=9, family="monospace", fontweight="bold")

        for i, idx in enumerate(show_idx):
            y = -(i + 1.5) * 0.9 - 0.3  # å“ˆå¸Œè¡¨å¸ƒå±€å‚æ•°
            hc = int(hits[idx])
            # å¦‚æœæ˜¯ ground truth ç‚¹ï¼Œç”¨ç‰¹æ®Šæ ‡è®°
            point_label = f"V{idx}â—†" if idx in gt else f"V{idx}"
            point_color = PLOT_CONFIG["ground_truth"]["text"] if idx in gt else "black"
            cell(xs[0], y, point_label, fontsize=9, color=point_color, fontweight="bold" if idx in gt else "normal")
            for ti in range(lsh.num_tables):
                m = matches[idx, ti]
                cell(xs[ti+1], y, ''.join(bits[idx, ti].astype(int).astype(str)),
                     bg=COLORS["hash_table"]["match_bg"] if m else COLORS["hash_table"]["no_match_bg"],
                     ec=COLORS["hash_table"]["match_border"] if m else COLORS["hash_table"]["no_match_border"],
                     lw=2 if m else 1, fontsize=8, family="monospace")
            cell(xs[-1], y, f"{hc}/{lsh.num_tables}", fontsize=10, fontweight="bold",
                 color=COLORS["hits"][hc-1] if hc else COLORS["hash_table"]["no_hit_text"])
        ax4.text((xs[0]+xs[-1])/2, y-1.5, "ç»¿æ¡† = å“ˆå¸Œç åŒ¹é… = è¢«å¬å›å€™é€‰é›†\nâ—† = Ground Truth",
                 ha="center", fontsize=8, color=COLORS["hash_table"]["match_border"])
    
    # Panel 5: æœ€ç»ˆç»“æœå¯¹æ¯”
    recall = len(set(lsh_topk) & set(gt)) / k if k else 0
    
    ax5 = fig.add_subplot(gs[1, 4:6])
    setup_plot(ax5, xlim, ylim, data, query, "5. ç»“æœå¯¹æ¯”")
    ax5.collections[0].set_alpha(0.3)
    ax5.collections[0].set_facecolor("lightgray")
    draw_ground_truth(ax5, data, gt, recall=recall)
    if len(lsh_topk):
        ax5.scatter(data[lsh_topk, 0], data[lsh_topk, 1], c="red", marker="o", s=40, alpha=0.8, label="LSHç»“æœ")
    for i, idx in enumerate(gt[:5]):
        ax5.annotate(f"{i+1}", data[idx], xytext=(3, 3), textcoords="offset points",
                     fontsize=8, color="w", fontweight="bold")
    _setup_legend(ax5)
    ax5.grid(True, alpha=PLOT_CONFIG["alpha"]["grid"])

    # ä¿å­˜å’Œæ˜¾ç¤º
    fig.suptitle(f"LSHç®—æ³•å¯è§†åŒ–  |  L={lsh.num_tables}è¡¨, å“ˆå¸Œä½={lsh.hash_size}, N={n}ç‚¹",
                 fontsize=PLOT_CONFIG["fontsize"]["suptitle"], fontweight="bold", y=0.98)
    plt.subplots_adjust(**PLOT_CONFIG["layout"]["subplots_adjust"])
    plt.show()
    
    speedup = n / len(cands) if len(cands) else float("inf")
    print(f"\nLSH ç»“æœ: å¬å›ç‡={recall:.0%}, åŠ é€Ÿ={speedup:.1f}Ã—\n")
    return recall


def demonstrate_lsh():
    """æ¼”ç¤ºLSHç®—æ³•çš„å®Œæ•´æµç¨‹"""
    print("=" * 60)
    print("LSHç®—æ³•å®Œæ•´æ¼”ç¤º")
    print("=" * 60)

    # 1. åˆ›å»ºç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    n_samples = 20
    dim = 2

    # ç”Ÿæˆå…·æœ‰èšç±»ç»“æ„çš„æ•°æ®
    data = np.vstack([np.random.normal(c, 0.8, (66, 2)) for c in [(2, 2), (-2, -2), (2, -2)]])

    print(f"ç”Ÿæˆ{len(data)}ä¸ª{dim}ç»´æ•°æ®ç‚¹")

    # 2. åˆ›å»ºå¹¶åˆå§‹åŒ–LSHç´¢å¼•
    lsh = CosineLSH(hash_size=4, num_tables=3)

    # 3. å‘LSHç´¢å¼•ä¸­æ·»åŠ æ•°æ®
    lsh.index(data)

    print("LSHç´¢å¼•æ„å»ºå®Œæˆ!")

    # 4. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print_lsh_statistics(lsh, data)

    # 5. åˆ›å»ºæŸ¥è¯¢ç‚¹
    query_point = np.array([1.5, 1.5])
    print(f"\næŸ¥è¯¢ç‚¹: {query_point}")

    # 6. æ‰§è¡ŒæŸ¥è¯¢
    candidate_ids, topk_ids = lsh.query_with_topk(query_point, k=5)

    print(f"æ‰¾åˆ°{len(candidate_ids)}ä¸ªå€™é€‰å‘é‡:")
    candidate_dists = np.linalg.norm(data[candidate_ids] - query_point, axis=1)
    for i, (vec_id, dist) in enumerate(zip(candidate_ids, candidate_dists)):
        print(f"å€™é€‰å‘é‡{vec_id}: è·ç¦»={dist:.4f}")
        if i == 4:
            print("...")
            break
        
    if len(topk_ids) > 0:
        print(f"\nTop-5 æœ€è¿‘é‚»ç»“æœ:")
        topk_dists = np.linalg.norm(data[topk_ids] - query_point, axis=1)
        for i, (vec_id, dist) in enumerate(zip(topk_ids, topk_dists)):
            print(f"Top{i+1}: å‘é‡{vec_id}, è·ç¦»={dist:.4f}")

    # 7. å¯è§†åŒ–
    print("\nç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    visualize_lsh(lsh, query_point, k=5)

    return lsh, data, query_point, candidate_ids

# è¿è¡Œæ¼”ç¤º
lsh, data, query, candidates = demonstrate_lsh()
```
è¾“å‡ºç»“æœï¼š

```
============================================================
LSHç®—æ³•å®Œæ•´æ¼”ç¤º
============================================================
ç”Ÿæˆ198ä¸ª2ç»´æ•°æ®ç‚¹
LSHç´¢å¼•æ„å»ºå®Œæˆ!

LSHç´¢å¼•ç»Ÿè®¡:
å‘é‡æ€»æ•°: 198
å“ˆå¸Œè¡¨æ•°é‡: 3
æ¯è¡¨å“ˆå¸Œä½æ•°: 4
æ€»æ¡¶æ•°: 21
è¡¨1: 7ä¸ªæ¡¶, å¹³å‡æ¯ä¸ªæ¡¶28.29ä¸ªå‘é‡
è¡¨2: 8ä¸ªæ¡¶, å¹³å‡æ¯ä¸ªæ¡¶24.75ä¸ªå‘é‡
è¡¨3: 6ä¸ªæ¡¶, å¹³å‡æ¯ä¸ªæ¡¶33.00ä¸ªå‘é‡

æŸ¥è¯¢ç‚¹: [1.5 1.5]
æ‰¾åˆ°66ä¸ªå€™é€‰å‘é‡:
å€™é€‰å‘é‡0: è·ç¦»=0.9782
å€™é€‰å‘é‡1: è·ç¦»=1.9974
å€™é€‰å‘é‡2: è·ç¦»=0.4422
å€™é€‰å‘é‡3: è·ç¦»=2.0858
å€™é€‰å‘é‡4: è·ç¦»=0.9423
...

Top-5 æœ€è¿‘é‚»ç»“æœ:
Top1: å‘é‡42, è·ç¦»=0.1768
Top2: å‘é‡5, è·ç¦»=0.1815
Top3: å‘é‡46, è·ç¦»=0.2457
Top4: å‘é‡51, è·ç¦»=0.2667
Top5: å‘é‡14, è·ç¦»=0.2674

ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...
LSH ç»“æœ: å¬å›ç‡=100%, åŠ é€Ÿ=3.0Ã—
```
![alt text](/images/LSHç®—æ³•ç»“æœ.svg)

**å›¾ 1ï¼šç©ºé—´åˆ†å‰²åŸºç¡€**
å±•ç¤ºéšæœºè¶…å¹³é¢å¦‚ä½•å°†å‘é‡ç©ºé—´åˆ’åˆ†ä¸ºå“ˆå¸Œæ¡¶ï¼Œç›¸ä¼¼çš„å‘é‡åœ¨æ¦‚ç‡ä¸Šè¢«æ˜ å°„åˆ°ç›¸åŒåŒºåŸŸï¼Œä½“ç°å±€éƒ¨æ•æ„Ÿå“ˆå¸Œçš„æ ¸å¿ƒæœºåˆ¶ã€‚

**å›¾ 2ï¼šå¤šè¡¨ç­–ç•¥**
3 ä¸ªå“ˆå¸Œè¡¨ä½¿ç”¨ä¸åŒè¶…å¹³é¢å¹¶è¡Œå·¥ä½œï¼Œå³ä½¿å•è¡¨ï¼ˆå¦‚è¡¨3ï¼‰é—æ¼ç›¸ä¼¼å‘é‡ï¼Œå¤šè¡¨åä½œä¹Ÿèƒ½æé«˜å¬å›ç‡ã€‚

**å›¾ 3ï¼šå¤šè¡¨å…±è¯†**
é¢œè‰²æ·±åº¦è¡¨ç¤ºå‘é‡è¢«å¤šå°‘ä¸ªå“ˆå¸Œè¡¨åŒæ—¶é€‰ä¸­çš„é¢‘ç‡ï¼Œå…±è¯†åº¦æ›´é«˜çš„å‘é‡ä¸æŸ¥è¯¢ç‚¹æ›´ç›¸ä¼¼ã€‚

**å›¾ 4ï¼šå“ˆå¸Œç åˆ†æ**
å±•ç¤ºå‘é‡å¦‚ä½•è½¬æ¢ä¸ºäºŒè¿›åˆ¶å“ˆå¸Œç ï¼Œç©ºé—´ç›¸è¿‘çš„å‘é‡äº§ç”Ÿç›¸ä¼¼çš„ç¼–ç æ¨¡å¼ï¼ŒéªŒè¯å“ˆå¸Œå‡½æ•°çš„ç›¸ä¼¼æ€§ä¿æŒç‰¹æ€§ã€‚

**å›¾ 5ï¼šæ€§èƒ½å¯¹æ¯”**
LSH è¿‘ä¼¼æœç´¢ç»“æœä¸ç²¾ç¡®æœç´¢å¯¹æ¯”ï¼Œå±•ç¤ºåœ¨ä¿æŒé«˜å¬å›ç‡çš„åŒæ—¶å®ç°æ˜¾è‘—çš„æœç´¢åŠ é€Ÿã€‚

ç†è§£LSHç®—æ³•çš„å‚æ•°å¯¹æŒæ¡å…¶å·¥ä½œåŸç†è‡³å…³é‡è¦ï¼š
- hash_sizeï¼ˆå“ˆå¸Œå¤§å°ï¼‰ï¼š
> ä½œç”¨ï¼šå†³å®šæ¯ä¸ªå“ˆå¸Œè¡¨çš„å“ˆå¸Œç é•¿åº¦ï¼ˆä½æ•°ï¼‰
> å½±å“ï¼šå€¼è¶Šå¤§ï¼Œå“ˆå¸Œæ¡¶åˆ’åˆ†è¶Šç²¾ç»†ï¼Œç›¸ä¼¼åº¦åˆ¤æ–­è¶Šå‡†ç¡®ï¼Œä½†æ¯ä¸ªæ¡¶å†…çš„å‘é‡å¯èƒ½è¶Šå°‘

- num_tablesï¼ˆå“ˆå¸Œè¡¨æ•°é‡ï¼‰ï¼š
> ä½œç”¨ï¼šæ§åˆ¶ä½¿ç”¨çš„ç‹¬ç«‹å“ˆå¸Œè¡¨æ•°é‡
>å½±å“ï¼šå€¼è¶Šå¤§ï¼Œæ‰¾åˆ°çœŸæ­£è¿‘é‚»çš„æ¦‚ç‡è¶Šé«˜ï¼Œä½†å†…å­˜æ¶ˆè€—ä¹Ÿä¼šå¢åŠ 