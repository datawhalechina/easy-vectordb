import{_ as l,o as e,c as t,ag as n}from"./chunks/framework.CzE6cJJL.js";const m=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"more/milvus 数据切分总结.md","filePath":"more/milvus 数据切分总结.md","lastUpdated":1767493283000}'),a={name:"more/milvus 数据切分总结.md"};function p(r,i,o,u,s,_){return e(),t("div",null,[...i[0]||(i[0]=[n('<p>文本切分确实是整个流程里最基础也最关键的环节，尤其当面对PDF、技术文档、多模态资料这些结构复杂的材料时，切分效果直接影响后续的向量表达和检索质量。</p><p>首先：我们结合场景来看，你可以先看看下面的场景中，是否存在你正在面对的。</p><ol><li>中文/技术文档：技术手册、法律合同等强逻辑文档。</li><li>高逻辑连贯性要求：学术论文、产品说明书等结构化内容。</li><li>多模态/扫描文档：医疗报告、技术白皮书、扫描版图文文档。</li></ol><hr><p>一、语义切分：以逻辑单元为最小单位，确保信息完整</p><p>这是处理复杂文档最根本的原则，核心是避免在句子或段落中间生硬切断语义：</p><ol><li>递归分割法：按层级切分（段落→句子→单词），配合重叠机制（20%-30%重叠）保留上下文。例如，用 RecursiveCharacterTextSplitter 工具，设置 chunk_size=512、chunk_overlap=150，兼顾效率与语义连续。</li><li>语义边界检测：用NLP工具识别逻辑转折点： <ul><li>BERT-NSP模型：判断相邻段落是否语义衔接，低于阈值则切分；</li><li>OpenNLP句子解析：适合英文文档，避免因缩写/小数点误切；</li><li>中文专用工具（如HanLP/jieba）：解决中文无空格分词问题。</li></ul></li></ol><hr><p>二、动态分块技术：根据内容结构自适应调整粒度</p><p>固定分块在面对标题层级复杂或图文混排文档时容易失效：</p><ol><li>标题引导分块：识别PDF中的多级标题，将同一子标题下的段落合并为一个语义块；</li><li>相似性聚类分块：计算句子间余弦相似度，低于阈值时断开（如 SemanticSplitterNodeParser 工具）；</li><li>混合分块策略： <ul><li>正文按语义段切分；</li><li>表格/代码块整块保留，避免碎片化。</li></ul></li></ol><hr><p>三、专业文档处理：针对领域特性设计切分规则</p><p>领域术语、特殊符号容易导致误分割：</p><ul><li>医疗/法律文档：建立领域缩略词库（如 “q.d.” 不视为句尾），保护条款编号完整性；</li><li>含代码/公式的文档：用正则隔离非自然语言片段，独立嵌入；</li><li>多模态文档（VisRAG方案）： <ul><li>文本与图像协同切分：将关联的图文段落绑定为同一块；</li><li>三种召回策略：页面拼接、加权选择、多图像VLM，保留视觉信息。</li></ul></li></ul><hr><p>四、智能切分方法：基于大模型的新兴方案（适合高阶优化）</p><p>适合对效果有极致要求的场景，依赖LLM推理能力：</p><ol><li>Meta-Chunking（论文《Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception》）<br> 通过两种策略识别深层逻辑关系： <ul><li>Margin Sampling Chunking：LLM判断连续句子是否应分割，按概率差动态阈值切分；</li><li>Perplexity Chunking：低困惑度句子视为分块边界（因模型更“确定”此处语义完整）。</li></ul></li><li>LumberChunker：迭代调用LLM定位语义转折点，资源消耗较大但更精准。</li></ol><hr><p>五、向量检索协同优化：从分块到检索的端到端设计</p><p>切分最终服务于检索，需全局优化：</p><ol><li>关键信息索引：构建二级索引，仅对摘要性“关键信息”做向量化（如标题/实体词），原始文本作为附加内容，减少噪声；</li><li>多粒度向量存储：同步存储句子级、段落级向量，应对粗细粒度查询需求；</li><li>检索后重排序：先召回Top-K块，再用Cross-Encoder重排，提升精度。</li></ol><p>效果：在ChatPDF类应用中广泛验证，回答准确率提升30%+。</p><p>若希望深入前沿方法，可重点阅读：</p><ol><li>《Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception》（2024）</li><li>《VisRAG: Vision-based Retrieval-augmented Generation》（多模态文档处理）</li></ol><p>如果你觉得论文看起来太枯燥，可以看看：<a href="./../chapter4/Meta-Chunking：一种新的文本切分策略.html">Meta-Chunking：一种新的文本切分策略</a></p>',27)])])}const h=l(a,[["render",p]]);export{m as __pageData,h as default};
